{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Google Drive Documents Question and Answering**"
      ],
      "metadata": {
        "id": "r7KPUL_25tBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies\n"
      ],
      "metadata": {
        "id": "jH-CQjAKCL-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "!pip install PyMuPDF\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install --upgrade langchain openai  -q\n",
        "!pip install tiktoken -q\n",
        "!pip install pinecone-client -q\n",
        "!apt-get install poppler-utils\n",
        "!pip install unstructured -q\n",
        "!pip install unstructured[local-inference] -q\n",
        "!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2 -q"
      ],
      "metadata": {
        "id": "jF9IXX2ixqa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec0c9fe-74ee-4b20-f6ab-4c70a7371852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.6/239.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.22-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.22 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.22 PyMuPDFb-1.23.22\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (11.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.4/207.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.3 [186 kB]\n",
            "Fetched 186 kB in 0s (675 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121796 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate with Google Drive in Colab\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tPzjEa-jCoa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "bneLb2unOqTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive File Processing Script\n",
        "\n",
        " [This Python script interacts with the Google Drive API to retrieve and process various types of files from Google Drive. It exports content from Google Docs, extracts text from PDFs (or performs OCR if necessary), processes plain text files, extracts text from DOCX files, and retrieves and processes Python files.]\n"
      ],
      "metadata": {
        "id": "8x76mOMBC2Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from docx import Document\n",
        "\n",
        "def get_folder_hierarchy(drive_service, folder_id):\n",
        "    folder_hierarchy = []\n",
        "    while folder_id:\n",
        "        folder_info = drive_service.files().get(fileId=folder_id, fields=\"name, parents\").execute()\n",
        "        folder_name = folder_info[\"name\"]\n",
        "        folder_hierarchy.insert(0, folder_name)\n",
        "        folder_id = folder_info.get(\"parents\", [])[0] if \"parents\" in folder_info else None\n",
        "    return folder_hierarchy\n",
        "\n",
        "# Authenticate with Google Colab\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# Build the Drive API service\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Retrieve a list of all files and folders without any filtering\n",
        "response = drive_service.files().list(\n",
        "    pageSize=1000,\n",
        "    fields=\"files(id, name, mimeType, parents)\"\n",
        ").execute()\n",
        "\n",
        "files = response.get('files', [])\n",
        "original_text_file_names = set()\n",
        "all_text_content = \"\"\n",
        "\n",
        "# Initialize parent_folder_id outside of the loop\n",
        "parent_folder_id = None\n",
        "\n",
        "if not files:\n",
        "    print(\"No files found in Google Drive.\")\n",
        "else:\n",
        "    for file in files:\n",
        "        file_name = file['name']\n",
        "        file_id = file['id']\n",
        "        mime_type = file.get('mimeType', '')\n",
        "        parents = file.get('parents', [])\n",
        "\n",
        "        # Update parent_folder_id if there are parents\n",
        "        if parents:\n",
        "            parent_folder_id = parents[0]\n",
        "\n",
        "        # Initialize folder_name as None\n",
        "        folder_name = None\n",
        "\n",
        "        if parent_folder_id:\n",
        "            # Fetch the name of the parent folder\n",
        "            parent_folder_response = drive_service.files().get(fileId=parent_folder_id, fields=\"name\")\n",
        "            folder_name = parent_folder_response.execute().get(\"name\", \"\")\n",
        "\n",
        "            # Create a link to the parent folder\n",
        "            parent_folder_link = f\"https://drive.google.com/drive/folders/{parent_folder_id}\"\n",
        "        else:\n",
        "            # If there are no parent folders, set link to None\n",
        "            parent_folder_link = None\n",
        "\n",
        "        # Get the folder hierarchy for the current file\n",
        "        folder_hierarchy = get_folder_hierarchy(drive_service, parent_folder_id)\n",
        "        folder_path = \" > \".join(folder_hierarchy)\n",
        "\n",
        "        # Initialize the text content variable\n",
        "        text_content = \"\"\n",
        "\n",
        "        if mime_type == 'application/vnd.google-apps.document':\n",
        "            # Export Google Docs content as plain text\n",
        "            request = drive_service.files().export_media(fileId=file_id, mimeType='text/plain')\n",
        "            text_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(text_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            text_content = text_fh.getvalue().decode('utf-8')\n",
        "\n",
        "            # Add folder path to each line of the Google Docs content\n",
        "            text_lines = text_content.split('\\n')\n",
        "            text_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in text_lines])\n",
        "            all_text_content += f\"Folder Name: {folder_name} {parent_folder_link}\\n\"\n",
        "            all_text_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "            all_text_content += \"Google Docs Content:\\n\"\n",
        "            all_text_content += text_content_with_path + \"\\n\"\n",
        "            all_text_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        elif mime_type == 'application/pdf':\n",
        "            # Download the PDF content\n",
        "            request = drive_service.files().get_media(fileId=file_id)\n",
        "            pdf_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(pdf_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            # Check if the PDF contains text (use PyMuPDF for this)\n",
        "            pdf_content = pdf_fh.getvalue()\n",
        "            pdf_document = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
        "\n",
        "            # Initialize a variable to store the extracted text\n",
        "            extracted_text = \"\"\n",
        "\n",
        "            for page_num in range(pdf_document.page_count):\n",
        "                page = pdf_document.load_page(page_num)\n",
        "                page_text = page.get_text()\n",
        "                extracted_text += page_text\n",
        "\n",
        "            if extracted_text.strip():\n",
        "                # Append the extracted text for the PDF file\n",
        "                pdf_text_lines = extracted_text.split('\\n')\n",
        "                pdf_text_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in pdf_text_lines])\n",
        "                all_text_content += f\"Folder Name: {folder_name} {parent_folder_link}\\n\"\n",
        "                all_text_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "                all_text_content += \"PDF Text Content:\\n\"\n",
        "                all_text_content += pdf_text_content_with_path + \"\\n\"\n",
        "                all_text_content += \"=\" * 40 + \"\\n\"\n",
        "            else:\n",
        "                # If the PDF does not contain text, attempt OCR\n",
        "                all_text_content += f\"Folder Name: {folder_name} {parent_folder_link}\\n\"\n",
        "                all_text_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "                all_text_content += \"Performing OCR on scanned PDF...\\n\"\n",
        "\n",
        "                # Initialize a variable to store the OCR result\n",
        "                ocr_result = \"\"\n",
        "\n",
        "                for page_num in range(pdf_document.page_count):\n",
        "                    page = pdf_document.load_page(page_num)\n",
        "                    img = page.get_pixmap()\n",
        "                    img_bytes = img.samples\n",
        "                    img_text = pytesseract.image_to_string(Image.frombytes(\"RGB\", [img.width, img.height], img_bytes))\n",
        "                    ocr_result += img_text\n",
        "\n",
        "                ocr_text_lines = ocr_result.split('\\n')\n",
        "                ocr_text_content_with_path = \"\\n\".join([f\"{folder_path} > {line}\" for line in ocr_text_lines])\n",
        "                all_text_content += f\"OCR Result:\\n\"\n",
        "                all_text_content += ocr_text_content_with_path + \"\\n\"\n",
        "                all_text_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        elif mime_type == 'text/plain':\n",
        "            # Check if it's a text file and not processed before\n",
        "            if file_name.endswith('.txt') and file_name not in original_text_file_names:\n",
        "                # Download and append plain text content\n",
        "                request = drive_service.files().get_media(fileId=file['id'])\n",
        "                text_fh = io.BytesIO()\n",
        "                downloader = MediaIoBaseDownload(text_fh, request)\n",
        "                done = False\n",
        "                while done is False:\n",
        "                    status, done = downloader.next_chunk()\n",
        "\n",
        "                text_content = text_fh.getvalue().decode('utf-8')\n",
        "                text_lines = text_content.split('\\n')\n",
        "                text_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in text_lines])\n",
        "\n",
        "                all_text_content += f\"Folder Name: {folder_name} {parent_folder_link}\\n\"\n",
        "                all_text_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "                all_text_content += \"Text File Content:\\n\"\n",
        "                all_text_content += text_content_with_path + \"\\n\"\n",
        "                all_text_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "                # Add the file name (without .txt extension) to the set of original text file names\n",
        "                original_text_file_names.add(file_name)\n",
        "\n",
        "        elif mime_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':\n",
        "            # Download the .docx content\n",
        "            request = drive_service.files().get_media(fileId=file['id'])\n",
        "            docx_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(docx_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            docx_content = docx_fh.getvalue()\n",
        "            document = Document(io.BytesIO(docx_content))\n",
        "\n",
        "            extracted_text = []\n",
        "\n",
        "            for paragraph in document.paragraphs:\n",
        "                extracted_text.append(paragraph.text)\n",
        "\n",
        "            all_text_content += f\"Folder Name: {folder_name} {parent_folder_link}\\n\"\n",
        "            all_text_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "            all_text_content += \"DOCX Text Content:\\n\"\n",
        "            all_text_content += \"\\n\".join(extracted_text) + \"\\n\"\n",
        "            all_text_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        elif file_name.endswith('.py'):\n",
        "            # Download and process Python file content\n",
        "            request = drive_service.files().get_media(fileId=file['id'])\n",
        "            python_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(python_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            python_content = python_fh.getvalue().decode('utf-8')\n",
        "            python_lines = python_content.split('\\n')\n",
        "            python_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in python_lines])\n",
        "            all_text_content += f\"Folder Name: {folder_name} {parent_folder_link}\\n\"\n",
        "            all_text_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "            all_text_content += \"Python File Content:\\n\"\n",
        "            all_text_content += python_content_with_path + \"\\n\"\n",
        "            all_text_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "\n",
        "        # Add more MIME type processing here\n",
        "\n",
        "# Print the accumulated text content for all files in Google Drive\n",
        "print(all_text_content)\n",
        "print(len(all_text_content))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODbrE2l6GLyW",
        "outputId": "4bfae384-ea66-426b-d696-3fe0673af726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder Name: Colab Notebooks https://drive.google.com/drive/folders/1PMTCq-RbU4U7dQ0uT-QxX3C6Fkn5RZ9Q\n",
            "File Name: Food Menu Charcoal Surat (10J).pdf https://drive.google.com/file/d/1NtPt9J09_L5O5SC4exKMYkSK417f6KPs\n",
            "PDF Text Content:\n",
            "Folder name : My Drive > Colab Notebooks > 550\n",
            "Folder name : My Drive > Colab Notebooks > 575\n",
            "Folder name : My Drive > Colab Notebooks > K's Cheese Tortellini\n",
            "Folder name : My Drive > Colab Notebooks > 550\n",
            "Folder name : My Drive > Colab Notebooks > 550\n",
            "Folder name : My Drive > Colab Notebooks > 550\n",
            "Folder name : My Drive > Colab Notebooks > 550\n",
            "Folder name : My Drive > Colab Notebooks > 550\n",
            "Folder name : My Drive > Colab Notebooks > 550\n",
            "Folder name : My Drive > Colab Notebooks > (Available in pomodoro, Basil Pesto, Alfredo,\n",
            "Folder name : My Drive > Colab Notebooks > Lemon Butter Garlic)\n",
            "Folder name : My Drive > Colab Notebooks > R I S O T T O\n",
            "Folder name : My Drive > Colab Notebooks > Porcini Mushroom Risotto\n",
            "Folder name : My Drive > Colab Notebooks > Risotto\n",
            "Folder name : My Drive > Colab Notebooks > Available in Pomodoro, Basil Pesto  & Alfredo \n",
            "Folder name : My Drive > Colab Notebooks > 650 /-\n",
            "Folder name : My Drive > Colab Notebooks > \n",
            "========================================\n",
            "Folder Name: PDF https://drive.google.com/drive/folders/1Yqa_3374NYDX7DCKbzhlhEXzzqRn5XRC\n",
            "File Name: snetimental.pdf https://drive.google.com/file/d/15EDgXUtIOrMNQgIq763tCLCY_6bWyLm1\n",
            "PDF Text Content:\n",
            "Folder name : My Drive > PDF > Deep Learning for Sentiment Analysis: A Survey \n",
            "Folder name : My Drive > PDF > Lei Zhang, LinkedIn Corporation, lzhang32@gmail.com \n",
            "Folder name : My Drive > PDF > Shuai Wang, University of Illinois at Chicago, shuaiwanghk@gmail.com \n",
            "Folder name : My Drive > PDF > Bing Liu, University of Illinois at Chicago, liub@uic.edu \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Abstract \n",
            "Folder name : My Drive > PDF > Deep learning has emerged as a powerful machine learning technique that learns multiple layers of \n",
            "Folder name : My Drive > PDF > representations or features of the data and produces state-of-the-art prediction results. Along with \n",
            "Folder name : My Drive > PDF > the success of deep learning in many other application domains, deep learning is also popularly used \n",
            "Folder name : My Drive > PDF > in sentiment analysis in recent years. This paper first gives an overview of deep learning and then \n",
            "Folder name : My Drive > PDF > provides a comprehensive survey of its current applications in sentiment analysis.  \n",
            "Folder name : My Drive > PDF > INTRODUCTION \n",
            "Folder name : My Drive > PDF > Sentiment analysis or opinion mining is the computational study of peopleâ€™s opinions, sentiments, \n",
            "Folder name : My Drive > PDF > emotions, appraisals, and attitudes towards entities such as products, services, organizations, \n",
            "Folder name : My Drive > PDF > individuals, issues, events, topics, and their attributes.1 The inception and rapid growth of the field \n",
            "Folder name : My Drive > PDF > coincide with those of the social media on the Web, for example, reviews, forum discussions, blogs, \n",
            "Folder name : My Drive > PDF > micro-blogs, Twitter, and social networks, because for the first time in human history, we have a \n",
            "Folder name : My Drive > PDF > huge volume of opinionated data recorded in digital forms. Since early 2000, sentiment analysis has \n",
            "Folder name : My Drive > PDF > grown to be one of the most active research areas in natural language processing (NLP). It is also \n",
            "Folder name : My Drive > PDF > widely studied in data mining, Web mining, text mining, and information retrieval. In fact, it has \n",
            "Folder name : My Drive > PDF > spread from computer science to management sciences and social sciences such as marketing, \n",
            "Folder name : My Drive > PDF > finance, political science, communications, health science, and even history, due to its importance to \n",
            "Folder name : My Drive > PDF > business and society as a whole. This proliferation is due to the fact that opinions are central to \n",
            "Folder name : My Drive > PDF > almost all human activities and are key influencers of our behaviours. Our beliefs and perceptions of \n",
            "Folder name : My Drive > PDF > reality, and the choices we make, are, to a considerable degree, conditioned upon how others see \n",
            "Folder name : My Drive > PDF > and evaluate the world. For this reason, whenever we need to make a decision we often seek out \n",
            "Folder name : My Drive > PDF > the opinions of others. This is not only true for individuals but also true for organizations.  \n",
            "Folder name : My Drive > PDF > Nowadays, if one wants to buy a consumer product, one is no longer limited to asking oneâ€™s friends \n",
            "Folder name : My Drive > PDF > and family for opinions because there are many user reviews and discussions about the product in \n",
            "Folder name : My Drive > PDF > public forums on the Web. For an organization, it may no longer be necessary to conduct surveys, \n",
            "Folder name : My Drive > PDF > opinion polls, and focus groups in order to gather public opinions because there is an abundance of \n",
            "Folder name : My Drive > PDF > such information publicly available. In recent years, we have witnessed that opinionated postings in \n",
            "Folder name : My Drive > PDF > social media have helped reshape businesses, and sway public sentiments and emotions, which have \n",
            "Folder name : My Drive > PDF > profoundly impacted on our social and political systems. Such postings have also mobilized masses \n",
            "Folder name : My Drive > PDF > for political changes such as those happened in some Arab countries in 2011. It has thus become a \n",
            "Folder name : My Drive > PDF > necessity to collect and study opinions1. \n",
            "Folder name : My Drive > PDF > However, finding and monitoring opinion sites on the Web and distilling the information contained \n",
            "Folder name : My Drive > PDF > in them remains a formidable task because of the proliferation of diverse sites. Each site typically \n",
            "Folder name : My Drive > PDF > contains a huge volume of opinion text that is not always easily deciphered in long blogs and forum \n",
            "Folder name : My Drive > PDF > postings. The average human reader will have difficulty identifying relevant sites and extracting and \n",
            "Folder name : My Drive > PDF > summarizing the opinions in them. Automated sentiment analysis systems are thus needed. Because \n",
            "Folder name : My Drive > PDF > of this, there are many start-ups focusing on providing sentiment analysis services. Many big \n",
            "Folder name : My Drive > PDF > corporations have also built their own in-house capabilities. These practical applications and \n",
            "Folder name : My Drive > PDF > industrial interests have provided strong motivations for research in sentiment analysis. \n",
            "Folder name : My Drive > PDF > Existing research has produced numerous techniques for various tasks of sentiment analysis, which \n",
            "Folder name : My Drive > PDF > include both supervised and unsupervised methods. In the supervised setting, early papers used all \n",
            "Folder name : My Drive > PDF > types of supervised machine learning methods (such as Support Vector Machines (SVM), Maximum \n",
            "Folder name : My Drive > PDF > Entropy, NaÃ¯ve Bayes, etc.) and feature combinations. Unsupervised methods include various \n",
            "Folder name : My Drive > PDF > methods that exploit sentiment lexicons, grammatical analysis, and syntactic patterns. Several \n",
            "Folder name : My Drive > PDF > survey books and papers have been published, which cover those early methods and applications \n",
            "Folder name : My Drive > PDF > extensively.1,2,3  \n",
            "Folder name : My Drive > PDF > Since about a decade ago, deep learning has emerged as a powerful machine learning technique4 \n",
            "Folder name : My Drive > PDF > and produced state-of-the-art results in many application domains, ranging from computer vision \n",
            "Folder name : My Drive > PDF > and speech recognition to NLP. Applying deep learning to sentiment analysis has also become very \n",
            "Folder name : My Drive > PDF > popular recently. This paper first gives an overview of deep learning and then provides a \n",
            "Folder name : My Drive > PDF > comprehensive survey of the sentiment analysis research based on deep learning. \n",
            "Folder name : My Drive > PDF > NEURAL NETWORKS  \n",
            "Folder name : My Drive > PDF > Deep learning is the application of artificial neural networks (neural networks for short) to learning \n",
            "Folder name : My Drive > PDF > tasks using networks of multiple layers. It can exploit much more learning (representation) power of \n",
            "Folder name : My Drive > PDF > neural networks, which once were deemed to be practical only with one or two layers and a small \n",
            "Folder name : My Drive > PDF > amount of data.  \n",
            "Folder name : My Drive > PDF > Inspired by the structure of the biological brain, neural networks consist of a large number of \n",
            "Folder name : My Drive > PDF > information processing units (called neurons) organized in layers, which work in unison. It can learn \n",
            "Folder name : My Drive > PDF > to perform tasks (e.g., classification) by adjusting the connection weights between neurons, \n",
            "Folder name : My Drive > PDF > resembling the learning process of a biological brain. \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 1:  Feedforward neural network \n",
            "Folder name : My Drive > PDF > Based on network topologies, neural networks can generally be categorized into feedforward neural \n",
            "Folder name : My Drive > PDF > networks and recurrent/recursive neural networks, which can also be mixed and matched. We will \n",
            "Folder name : My Drive > PDF > describe recurrent/recursive neural networks later. A simple example of a feedforward neural \n",
            "Folder name : My Drive > PDF > network is given in Figure 1, which consists of three layers ğ¿!, ğ¿! and ğ¿!. ğ¿! is the input layer, which \n",
            "Folder name : My Drive > PDF > corresponds to the input vector (ğ‘¥!, ğ‘¥!, ğ‘¥!) and intercept term +1. ğ¿! is the output layer, which \n",
            "Folder name : My Drive > PDF > corresponds to the output vector (ğ‘ !). ğ¿! is the hidden layer, whose output is not visible as a \n",
            "Folder name : My Drive > PDF > network output. A circle in ğ¿! represents an element in the input vector, while a circle in ğ¿! or ğ¿! \n",
            "Folder name : My Drive > PDF > represents a neuron, the basic computation element of a neural network. We also call it an \n",
            "Folder name : My Drive > PDF > activation function. A line between two neurons represents a connection for the flow of information. \n",
            "Folder name : My Drive > PDF > Each connection is associated with a weight, a value controlling the signal between two neurons. \n",
            "Folder name : My Drive > PDF > The learning of a neural network is achieved by adjusting the weights between neurons with the \n",
            "Folder name : My Drive > PDF > information flowing through them. Neurons read output from neurons in the previous layer, process \n",
            "Folder name : My Drive > PDF > the information, and then generate output to neurons in the next layer. As in Figure 1, the neutral \n",
            "Folder name : My Drive > PDF > network alters weights based on training examples (ğ‘¥(!), ğ‘¦(!)). After the training process, it will \n",
            "Folder name : My Drive > PDF > obtain a complex form of hypotheses â„!,!(ğ‘¥) that fits the data.  \n",
            "Folder name : My Drive > PDF > Diving into the hidden layer, we can see that each neuron in ğ¿! takes input ğ‘¥!, ğ‘¥!, ğ‘¥! and intercept \n",
            "Folder name : My Drive > PDF > +1 from ğ¿!, and outputs a value ğ‘“(ğ‘Š!ğ‘¥) = ğ‘“(\n",
            "Folder name : My Drive > PDF > ğ‘Š!ğ‘¥! + ğ‘)\n",
            "Folder name : My Drive > PDF > !\n",
            "Folder name : My Drive > PDF > !!!\n",
            "Folder name : My Drive > PDF >  by the activation function ğ‘“. ğ‘Š! are \n",
            "Folder name : My Drive > PDF > weights of the connections; ğ‘ is the intercept or bias; ğ‘“ is normally non-linear. The common choices \n",
            "Folder name : My Drive > PDF > of ğ‘“ are sigmoid function, hyperbolic tangent function (tanh), or rectified linear function (ReLU). \n",
            "Folder name : My Drive > PDF > Their equations are as follows. \n",
            "Folder name : My Drive > PDF >                                                  ğ‘“ ğ‘Š!ğ‘¥ = ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ ğ‘Š!ğ‘¥ =  \n",
            "Folder name : My Drive > PDF > !\n",
            "Folder name : My Drive > PDF > !!!\"# !!!!                         (1) \n",
            "Folder name : My Drive > PDF >                                                   ğ‘“ ğ‘Š!ğ‘¥ = tanh ğ‘Š!ğ‘¥ =  \n",
            "Folder name : My Drive > PDF > !!!!!!!!!!\n",
            "Folder name : My Drive > PDF > !!!!!!!!!!                                  (2)                                           \n",
            "Folder name : My Drive > PDF >                                                 ğ‘“ ğ‘Š!ğ‘¥ = ğ‘…ğ‘’ğ¿ğ‘ˆ ğ‘Š!ğ‘¥ = max 0, ğ‘Š!ğ‘¥                              (3)                                           \n",
            "Folder name : My Drive > PDF > The sigmoid function takes a real-valued number and squashes it to a value in the range between 0 \n",
            "Folder name : My Drive > PDF > and 1. The function has been in frequent use historically due to its nice interpretation as the firing \n",
            "Folder name : My Drive > PDF > rate of a neuron: 0 for not firing or 1 for firing. But the non-linearity of the sigmoid has recently \n",
            "Folder name : My Drive > PDF > fallen out of favour because its activations can easily saturate at either tail of 0 or 1, where gradients \n",
            "Folder name : My Drive > PDF > are almost zero and the information flow would be cut. What is more is that its output is not zero-\n",
            "Folder name : My Drive > PDF > centered, which could introduce undesirable zig-zagging dynamics in the gradient updates for the \n",
            "Folder name : My Drive > PDF > connection weights in training. Thus, the tanh function is often more preferred in practice as its \n",
            "Folder name : My Drive > PDF > output range is zero-centered, [-1, 1] instead of [0, 1]. The ReLU function has also become popular \n",
            "Folder name : My Drive > PDF > lately. Its activation is simply thresholded at zero when the input is less than 0. Compared with the \n",
            "Folder name : My Drive > PDF > sigmoid function and the tanh function, ReLU is easy to compute, fast to converge in training and \n",
            "Folder name : My Drive > PDF > yields equal or better performance in neural networks.5 \n",
            "Folder name : My Drive > PDF > In ğ¿!, we can use the softmax function as the output neuron, which is a generalization of the logistic \n",
            "Folder name : My Drive > PDF > function that squashes a K-dimensional vector ğ‘‹ of arbitrary real values to a K-dimensional vector \n",
            "Folder name : My Drive > PDF > ğœ(ğ‘‹) of real values in the range (0, 1) that add up to 1. The function definition is as follows.  \n",
            "Folder name : My Drive > PDF >                                                  ğœ ğ‘‹ ! =\n",
            "Folder name : My Drive > PDF > !!!\n",
            "Folder name : My Drive > PDF > !!!\n",
            "Folder name : My Drive > PDF > !\n",
            "Folder name : My Drive > PDF > !!!\n",
            "Folder name : My Drive > PDF >              ğ‘“ğ‘œğ‘Ÿ ğ‘— = 1, â€¦ , ğ‘˜                              (4)                                           \n",
            "Folder name : My Drive > PDF > Generally, softmax is used in the final layer of neural networks for final classification in feedforward \n",
            "Folder name : My Drive > PDF > neural networks.  \n",
            "Folder name : My Drive > PDF > By connecting together all neurons, the neural network in Figure 1 has parameters (ğ‘Š, ğ‘) =\n",
            "Folder name : My Drive > PDF >  (ğ‘Š ! , ğ‘ ! , ğ‘Š ! , ğ‘(!)), where ğ‘Š!\"\n",
            "Folder name : My Drive > PDF > (!) denotes the weight associated with the connection between \n",
            "Folder name : My Drive > PDF > neuron ğ‘— in layer ğ‘™, and neuron ğ‘– in layer ğ‘™ + 1. ğ‘!\n",
            "Folder name : My Drive > PDF > (!) is the bias associated with neuron ğ‘– in layer ğ‘™ + 1.  \n",
            "Folder name : My Drive > PDF > To train a neural network, stochastic gradient descent via backpropagation6 is usually employed to \n",
            "Folder name : My Drive > PDF > minimize the cross-entropy loss, which is a loss function for softmax output. Gradients of the loss \n",
            "Folder name : My Drive > PDF > function with respect to weights from the last hidden layer to the output layer are first calculated, \n",
            "Folder name : My Drive > PDF > and then gradients of the expressions with respect to weights between upper network layers are \n",
            "Folder name : My Drive > PDF > calculated recursively by applying the chain rule in a backward manner. With those gradients, the \n",
            "Folder name : My Drive > PDF > weights between layers are adjusted accordingly. It is an iterative refinement process until certain \n",
            "Folder name : My Drive > PDF > stopping criteria are met. The pseudo code for training the neural network in Figure 1 is as follows. \n",
            "Folder name : My Drive > PDF >           Training algorithm: stochastic gradient descent via backpropagation \n",
            "Folder name : My Drive > PDF >          Initialize weights ğ‘Š and biases ğ‘ of the neural network ğ‘ with random values \n",
            "Folder name : My Drive > PDF >            do                 \n",
            "Folder name : My Drive > PDF >                for each training example (ğ‘¥! , ğ‘¦!)   \n",
            "Folder name : My Drive > PDF >                      ğ‘!  = neural-network-prediction (ğ‘, ğ‘¥! )       \n",
            "Folder name : My Drive > PDF >                      calculate gradients of loss function ( ğ‘! , ğ‘¦! )  with respect to ğ‘¤!  at  layer  ğ¿!    \n",
            "Folder name : My Drive > PDF >                      get âˆ†ğ‘¤! for all weights from hidden layer ğ¿! to output layer ğ¿!    \n",
            "Folder name : My Drive > PDF >                      calculate gradient with respect to ğ‘¤! by chain rule at layer ğ¿! \n",
            "Folder name : My Drive > PDF > get âˆ†ğ‘¤! for all weights from input layer ğ¿!  to hidden layer ğ¿!        \n",
            "Folder name : My Drive > PDF >                      update ( ğ‘¤!, ğ‘¤! )   \n",
            "Folder name : My Drive > PDF >             until all training examples are classified correctly or other stopping criteria are met \n",
            "Folder name : My Drive > PDF >             return the trained neural network                              \n",
            "Folder name : My Drive > PDF > Table 1: Training the neural network in Figure 1. \n",
            "Folder name : My Drive > PDF > The above algorithm can be extended to generic feedforward neural network training with multiple \n",
            "Folder name : My Drive > PDF > hidden layers. Note that stochastic gradient descent estimates the parameters for every training \n",
            "Folder name : My Drive > PDF > example as opposed to the whole set of training examples in batch gradient descent. Therefore, the \n",
            "Folder name : My Drive > PDF > parameter updates have a high variance and cause the loss function to fluctuate to different \n",
            "Folder name : My Drive > PDF > intensities, which helps discover new and possibly better local minima.  \n",
            "Folder name : My Drive > PDF > DEEP LEARNING  \n",
            "Folder name : My Drive > PDF > The research community lost interests in neural networks in late 1990s mainly because they were \n",
            "Folder name : My Drive > PDF > regarded as only practical for â€œshallowâ€ neural networks (neural networks with one or two layers) as \n",
            "Folder name : My Drive > PDF > training a â€œdeepâ€ neural network (neural networks with more layers) is complicated and \n",
            "Folder name : My Drive > PDF > computationally very expensive. However, in the past 10 years, deep learning made breakthrough \n",
            "Folder name : My Drive > PDF > and produced state-of-the-art results in many application domains, starting from computer vision, \n",
            "Folder name : My Drive > PDF > then speech recognition, and more recently, NLP.7,8 The renaissance of neural networks can be \n",
            "Folder name : My Drive > PDF > attributed to many factors. Most important ones include: (1) the availability of computing power \n",
            "Folder name : My Drive > PDF > due to the advances in hardware (e.g., GPUs), (2) the availability of huge amounts of training data, \n",
            "Folder name : My Drive > PDF > and (3) the power and flexibility of learning intermediate representations.9  \n",
            "Folder name : My Drive > PDF > In a nutshell, deep learning uses a cascade of multiple layers of nonlinear processing units for \n",
            "Folder name : My Drive > PDF > feature extraction and transformation. The lower layers close to the data input learn simple features, \n",
            "Folder name : My Drive > PDF > while higher layers learn more complex features derived from lower layer features. The architecture \n",
            "Folder name : My Drive > PDF > forms a hierarchical and powerful feature representation. Figure 2 shows the feature hierarchy from \n",
            "Folder name : My Drive > PDF > the left (a lower layer) to the right (a higher layer) learned by deep learning in face image \n",
            "Folder name : My Drive > PDF > classification.10 We can see that the learned image features grow in complexity, starting from \n",
            "Folder name : My Drive > PDF > blobs/edges, then noses/eyes/cheeks, to faces. \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF >                                                    Figure 2:  Feature hierarchy by deep learning \n",
            "Folder name : My Drive > PDF > In recent years, deep learning models have been extensively applied in the field of NLP and show \n",
            "Folder name : My Drive > PDF > great potentials. In the following several sections, we briefly describe the main deep learning \n",
            "Folder name : My Drive > PDF > architectures and related techniques that have been applied to NLP tasks. \n",
            "Folder name : My Drive > PDF > WORD EMBEDDING  \n",
            "Folder name : My Drive > PDF > Many deep learning models in NLP need word embedding results as input features.7 Word \n",
            "Folder name : My Drive > PDF > embedding is a technique for language modelling and feature learning, which transforms words in a \n",
            "Folder name : My Drive > PDF > vocabulary \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > vectors \n",
            "Folder name : My Drive > PDF > of \n",
            "Folder name : My Drive > PDF > continuous \n",
            "Folder name : My Drive > PDF > real \n",
            "Folder name : My Drive > PDF > numbers \n",
            "Folder name : My Drive > PDF > (e.g., \n",
            "Folder name : My Drive > PDF > ğ‘¤ğ‘œğ‘Ÿğ‘‘ \"â„ğ‘ğ‘¡\" â†’ (â€¦ , 0.15, â€¦ , 0.23, â€¦ , 0.41, â€¦ ) ). The technique normally involves a mathematic \n",
            "Folder name : My Drive > PDF > embedding from a high-dimensional sparse vector space (e.g., one-hot encoding vector space, in \n",
            "Folder name : My Drive > PDF > which each word takes a dimension) to a lower-dimensional dense vector space. Each dimension of \n",
            "Folder name : My Drive > PDF > the embedding vector represents a latent feature of a word. The vectors may encode linguistic \n",
            "Folder name : My Drive > PDF > regularities and patterns.  \n",
            "Folder name : My Drive > PDF > The learning of word embeddings can be done using neural networks11-15 or matrix factorization.16,17 \n",
            "Folder name : My Drive > PDF > One commonly used word embedding system is Word2Veci, which is essentially a computationally-\n",
            "Folder name : My Drive > PDF > efficient neural network prediction model that learns word embeddings from text. It contains \n",
            "Folder name : My Drive > PDF > Continuous Bag-of-Words model (CBOW)13, and Skip-Gram model (SG)14. The CBOW model predicts \n",
            "Folder name : My Drive > PDF > the target word (e.g., â€œwearingâ€) from its context words (â€œthe boy is _ a hatâ€, where â€œ_â€ denotes the \n",
            "Folder name : My Drive > PDF > target word), while the SG model does the inverse, predicting the context words given the target \n",
            "Folder name : My Drive > PDF > word. Statistically, the CBOW model smoothens over a great deal of distributional information by \n",
            "Folder name : My Drive > PDF > treating the entire context as one observation. It is effective for smaller datasets. However, the SG \n",
            "Folder name : My Drive > PDF > model treats each context-target pair as a new observation and is better for larger datasets.  \n",
            "Folder name : My Drive > PDF > Another frequently used learning approach is Global Vectorii (GloVe)17, which is trained on the non-\n",
            "Folder name : My Drive > PDF > zero entries of a global word-word co-occurrence matrix. \n",
            "Folder name : My Drive > PDF > AUTOENCODER AND DENOISING AUTOENCODER  \n",
            "Folder name : My Drive > PDF > Autoencoder Neural Network is a three-layer neural network, which sets the target values to be \n",
            "Folder name : My Drive > PDF > equal to the input values. Figure 3 shows an example of an autoencoder architecture.  \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 3:  Autoencoder neural network \n",
            "Folder name : My Drive > PDF >                                                              \n",
            "Folder name : My Drive > PDF > i Source code: https://code.google.com/archive/p/word2vec/ \n",
            "Folder name : My Drive > PDF > ii Source code: https://github.com/stanfordnlp/GloVe \n",
            "Folder name : My Drive > PDF > Given the input vector ğ‘¥ âˆˆ  [0,1]! , the autoencoder first maps it to a hidden representation \n",
            "Folder name : My Drive > PDF > ğ‘¦ âˆˆ [0,1]!! by an encoder function â„(âˆ™) (e.g., the sigmoid function). The latent representation ğ‘¦ is \n",
            "Folder name : My Drive > PDF > then mapped back by a decoder function ğ‘”(âˆ™)  into a reconstruction ğ‘Ÿ ğ‘¥ = ğ‘”(â„ ğ‘¥ ) . The \n",
            "Folder name : My Drive > PDF > autoencoder is typically trained to minimize a form of reconstruction error ğ‘™ğ‘œğ‘ ğ‘ (ğ‘¥, ğ‘Ÿ ğ‘¥ ). The \n",
            "Folder name : My Drive > PDF > objective of the autoencoder is to learn a representation of the input, which is the activation of the \n",
            "Folder name : My Drive > PDF > hidden layer. Due to the nonlinear function â„(âˆ™) and ğ‘”(âˆ™), the autoencoder is able to learn non-\n",
            "Folder name : My Drive > PDF > linear representations, which give it much more expressive power than its linear counterparts, such \n",
            "Folder name : My Drive > PDF > as Principal Component Analysis (PCA) or Latent Semantic Analysis (LSA). \n",
            "Folder name : My Drive > PDF > One often stacks autoencoders into layers. A higher level autoencoder uses the output of the lower \n",
            "Folder name : My Drive > PDF > one as its training data. The stacked autoencoders18 along with Restricted Boltzmann Machines \n",
            "Folder name : My Drive > PDF > (RBMs)19 are earliest approaches to building deep neural networks. Once a stack of autoencoders \n",
            "Folder name : My Drive > PDF > has been trained in an unsupervised fashion, their parameters describing multiple levels of \n",
            "Folder name : My Drive > PDF > representations for ğ‘¥ (intermediate representations) can be used to initialize a supervised deep \n",
            "Folder name : My Drive > PDF > neural network, which has been shown empirically better than random parameter initialization.  \n",
            "Folder name : My Drive > PDF > The Denoising Autoencoder (DAE)20 is an extension of autoencoder, in which the input vector ğ‘¥ is \n",
            "Folder name : My Drive > PDF > stochastically corrupted into a vector ğ‘¥. And the model is trained to denoise it, that is, to minimize a \n",
            "Folder name : My Drive > PDF > denoising reconstruction error ğ‘™ğ‘œğ‘ ğ‘ (ğ‘¥, ğ‘Ÿ ğ‘¥ ). The idea behind DAE is to force the hidden layer to \n",
            "Folder name : My Drive > PDF > discover more robust features and prevent it from simply learning the identity. A robust model \n",
            "Folder name : My Drive > PDF > should be able to reconstruct the input well even in the presence of noises. For example, deleting or \n",
            "Folder name : My Drive > PDF > adding a few of words from or to a document should not change the semantic of the document.  \n",
            "Folder name : My Drive > PDF > CONVOLUTIONAL NEURAL NETWORK   \n",
            "Folder name : My Drive > PDF > Convolutional Neural Network (CNN) is a special type of feedforward neural network originally \n",
            "Folder name : My Drive > PDF > employed in the field of computer vision. Its design is inspired by the human visual cortex, a visual \n",
            "Folder name : My Drive > PDF > mechanism in animal brain. The visual cortex contains a lot of cells that are responsible for detecting \n",
            "Folder name : My Drive > PDF > light in small and overlapping sub-regions of the visual fields, which are called receptive fields. These \n",
            "Folder name : My Drive > PDF > cells act as local filters over the input space. CNN consists of multiple convolutional layers, each of \n",
            "Folder name : My Drive > PDF > which performs the function that is processed by the cells in the visual cortex.  \n",
            "Folder name : My Drive > PDF > Figure 4 shows a CNN for recognizing traffic signs.21 The input is a 32x32x1 pixel image (32 x 32 \n",
            "Folder name : My Drive > PDF > represents image width x height; 1 represents input channel). In this first stage, the filter (size 5x5x1) \n",
            "Folder name : My Drive > PDF > is used to scan the image. Each region in the input image that the filter projects on is a receptive \n",
            "Folder name : My Drive > PDF > field. The filter is actually an array of numbers (called weights or parameters). As the filter is sliding \n",
            "Folder name : My Drive > PDF > (or convolving), it is multiplying its weight values with the original pixel values of the image (element \n",
            "Folder name : My Drive > PDF > wise multiplications). The multiplications are all summed up to a single number, which is a \n",
            "Folder name : My Drive > PDF > representative of the receptive field. Every receptive field produces a number. After the filter \n",
            "Folder name : My Drive > PDF > finishes scanning over the image, we can get an array (size 28x28x1), which is called the activation \n",
            "Folder name : My Drive > PDF > map or feature map. In CNN, we need to use different filters to scan the input. In Figure 4, we apply \n",
            "Folder name : My Drive > PDF > 108 kinds of filters and thus have 108 stacked feature maps in the first stage, which consists of the \n",
            "Folder name : My Drive > PDF > first convolutional layer. Following the convolutional layer, a subsampling (or pooling) layer is \n",
            "Folder name : My Drive > PDF > usually used to progressively reduce the spatial size of the representation, thus to reduce the \n",
            "Folder name : My Drive > PDF > number of features and the computational complexity of the network. For example, after \n",
            "Folder name : My Drive > PDF > subsampling in the first stage, the convolutional layer reduces its dimensions to (14x14x108). Note \n",
            "Folder name : My Drive > PDF > that while the dimensionality of each feature map is reduced, the subsampling step retains the most \n",
            "Folder name : My Drive > PDF > important information, with a commonly used subsampling operation being the max pooling. \n",
            "Folder name : My Drive > PDF > Afterwards, the output from the first stage becomes input to the second stage and the new filters \n",
            "Folder name : My Drive > PDF > are employed. The new filter size is 5x5x108, where 108 is the feature map size of the last layer. \n",
            "Folder name : My Drive > PDF > After the second stage, CNN uses a fully connected layer and then a softmax readout layer with \n",
            "Folder name : My Drive > PDF > output classes for classification.  \n",
            "Folder name : My Drive > PDF > Convolutional layers in CNN play the role of feature extractor, which extracts local features as they \n",
            "Folder name : My Drive > PDF > restrict the receptive fields of the hidden layers to be local. It means that CNN has a special spatially-\n",
            "Folder name : My Drive > PDF > local correlation by enforcing a local connectivity pattern between neurons of adjacent layers. Such \n",
            "Folder name : My Drive > PDF > a characteristic is useful for classification in NLP, in which we expect to find strong local clues \n",
            "Folder name : My Drive > PDF > regarding class membership, but these clues can appear in different places in the input. For example, \n",
            "Folder name : My Drive > PDF > in a document classification task, a single key phrase (or an n-gram) can help in determining the \n",
            "Folder name : My Drive > PDF > topic of the document. We would like to learn that certain sequences of words are good indicators \n",
            "Folder name : My Drive > PDF > of the topic, and do not necessarily care where they appear in the document. Convolutional and \n",
            "Folder name : My Drive > PDF > pooling layers allow the CNN to learn to find such local indicators, regardless of their positions.8  \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 4:  Convolutional neural network \n",
            "Folder name : My Drive > PDF > RECURRENT NEURAL NETWORK \n",
            "Folder name : My Drive > PDF > Recurrent Neural Network (RNN)22 is a class of neural networks whose connections between \n",
            "Folder name : My Drive > PDF > neurons form a directed cycle. Unlike feedforward neural networks, RNN can use its internal \n",
            "Folder name : My Drive > PDF > â€œmemoryâ€ to process a sequence of inputs, which makes it popular for processing sequential \n",
            "Folder name : My Drive > PDF > information. The â€œmemoryâ€ means that RNN performs the same task for every element of a \n",
            "Folder name : My Drive > PDF > sequence with each output being dependent on all previous computations, which is like \n",
            "Folder name : My Drive > PDF > â€œrememberingâ€ information about what has been processed so far.  \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 5:  Recurrent neural network \n",
            "Folder name : My Drive > PDF > Figure 5 shows an example of a RNN. The left graph is an unfolded network with cycles, while the \n",
            "Folder name : My Drive > PDF > right graph is a folded sequence network with three time steps. The length of time steps is \n",
            "Folder name : My Drive > PDF > determined by the length of input. For example, if the word sequence to be processed is a sentence \n",
            "Folder name : My Drive > PDF > of six words, the RNN would be unfolded into a neural network with six time steps or layers. One \n",
            "Folder name : My Drive > PDF > layer corresponds to a word.  \n",
            "Folder name : My Drive > PDF > In Figure 5, ğ‘¥! is the input vector at time step ğ‘¡. â„! is the hidden state at time step ğ‘¡, which is \n",
            "Folder name : My Drive > PDF > calculated based on the previous hidden state and the input at the current time step. \n",
            "Folder name : My Drive > PDF >                                                         â„! = ğ‘“ ğ‘¤!!â„!!! + ğ‘¤!!ğ‘¥!                                              (5) \n",
            "Folder name : My Drive > PDF > In Equation (5), the activation function ğ‘“ is usually the tanh function or the ReLU function. ğ‘¤!! is the \n",
            "Folder name : My Drive > PDF > weight matrix used to condition the input ğ‘¥!. ğ‘¤!! is the weight matrix used to condition the \n",
            "Folder name : My Drive > PDF > previous hidden state â„!!!. \n",
            "Folder name : My Drive > PDF > ğ‘¦! is the output probability distribution over the vocabulary at step t. For example, if we want to \n",
            "Folder name : My Drive > PDF > predict the next word in a sentence, it would be a vector of probabilities across the word vocabulary. \n",
            "Folder name : My Drive > PDF >                                                         ğ‘¦! = ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ ğ‘¤!!â„!                                                     (6)  \n",
            "Folder name : My Drive > PDF > The hidden state â„! is regarded as the memory of the network. It captures information about what \n",
            "Folder name : My Drive > PDF > happened in all previous time steps. ğ‘¦! is calculated solely based on the memory â„! at time ğ‘¡ and the \n",
            "Folder name : My Drive > PDF > corresponding weight matrix ğ‘¤!!. \n",
            "Folder name : My Drive > PDF > Unlike a feedforward neural network, which uses different parameters at each layer, RNN shares the \n",
            "Folder name : My Drive > PDF > same parameters (ğ‘Š!!, ğ‘Š!!, ğ‘Š!!) across all steps. This means that it performs the same task at \n",
            "Folder name : My Drive > PDF > each step, just with different inputs. This greatly reduces the total number of parameters needed to \n",
            "Folder name : My Drive > PDF > learn.  \n",
            "Folder name : My Drive > PDF > Theoretically, RNN can make use of the information in arbitrarily long sequences, but in practice, the \n",
            "Folder name : My Drive > PDF > standard RNN is limited to looking back only a few steps due to the vanishing gradient or exploding \n",
            "Folder name : My Drive > PDF > gradient problem.23  \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 6:  Bidirectional RNN (left) and deep bidirectional RNN (right) \n",
            "Folder name : My Drive > PDF > Researchers have developed more sophisticated types of RNN to deal with the shortcomings of the \n",
            "Folder name : My Drive > PDF > standard RNN model: Bidirectional RNN, Deep Bidirectional RNN and Long Short Term Memory \n",
            "Folder name : My Drive > PDF > network. Bidirectional RNN is based on the idea that the output at each time may not only depend \n",
            "Folder name : My Drive > PDF > on the previous elements in the sequence, but also depend on the next elements in the sequence. \n",
            "Folder name : My Drive > PDF > For instance, to predict a missing word in a sequence, we may need to look at both the left and the \n",
            "Folder name : My Drive > PDF > right context. A bidirectional RNN24 consists of two RNNs, which are stacked on the top of each other. \n",
            "Folder name : My Drive > PDF > The one that processes the input in its original order and the one that processes the reversed input \n",
            "Folder name : My Drive > PDF > sequence. The output is then computed based on the hidden state of both RNNs. Deep bidirectional \n",
            "Folder name : My Drive > PDF > RNN is similar to bidirectional RNN. The only difference is that it has multiple layers per time step, \n",
            "Folder name : My Drive > PDF > which provides higher learning capacity but needs a lot of training data. Figure 6 shows examples of \n",
            "Folder name : My Drive > PDF > bidirectional RNN and deep bidirectional RNN (with two layers) respectively. \n",
            "Folder name : My Drive > PDF > LSTM NETWORK \n",
            "Folder name : My Drive > PDF > Long Short Term Memory network (LSTM)25 is a special type of RNN, which is capable of learning \n",
            "Folder name : My Drive > PDF > long-term dependencies.  \n",
            "Folder name : My Drive > PDF > All RNNs have the form of a chain of repeating modules. In standard RNNs, this repeating module \n",
            "Folder name : My Drive > PDF > normally has a simple structure. However, the repeating module for LSTM is more complicated. \n",
            "Folder name : My Drive > PDF > Instead of having a single neural network layer, there are four layers interacting in a special way. \n",
            "Folder name : My Drive > PDF > Besides, it has two states: hidden state and cell state.          \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 7:  Long Short Term Memory network \n",
            "Folder name : My Drive > PDF > Figure 7 shows an example of LSTM. At time step ğ‘¡, LSTM first decides what information to dump \n",
            "Folder name : My Drive > PDF > from the cell state. This decision is made by a sigmoid function/layer ğœ, called the â€œforget gateâ€.  The \n",
            "Folder name : My Drive > PDF > function takes â„!!! (output from the previous hidden layer) and ğ‘¥! (current input), and outputs a \n",
            "Folder name : My Drive > PDF > number in [0, 1], where 1 means â€œcompletely keepâ€ and 0 means â€œcompletely dumpâ€ in Equation (7).  \n",
            "Folder name : My Drive > PDF >                                    ğ‘“! = ğœ ğ‘Š!ğ‘¥! + ğ‘ˆ!â„!!!                                                                      (7) \n",
            "Folder name : My Drive > PDF > Then LSTM decides what new information to store in the cell state. This has two steps. First, a \n",
            "Folder name : My Drive > PDF > sigmoid function/layer, called the â€œinput gateâ€ as Equation (8), decides which values LSTM will \n",
            "Folder name : My Drive > PDF > update. Next, a tanh function/layer creates a vector of new candidate values ğ¶! , which will be \n",
            "Folder name : My Drive > PDF > added to the cell state. LSTM combines these two to create an update to the state. \n",
            "Folder name : My Drive > PDF >                                    ğ‘–!  =  ğœ ğ‘Š!ğ‘¥! + ğ‘ˆ!â„!!!                                                                     (8) \n",
            "Folder name : My Drive > PDF >                                   ğ¶!  = tanh ğ‘Š!ğ‘¥! + ğ‘ˆ!â„!!!                                                                 (9) \n",
            "Folder name : My Drive > PDF > It is now time to update the old cell state ğ¶!!! into new cell state ğ¶! as Equation (10). Note that \n",
            "Folder name : My Drive > PDF > forget gate ğ‘“! can control the gradient passes through it and allow for explicit â€œmemoryâ€ deletes and \n",
            "Folder name : My Drive > PDF > updates, which helps alleviate vanishing gradient or exploding gradient problem in standard RNN.   \n",
            "Folder name : My Drive > PDF >                                    ğ¶! =  ğ‘“!  âˆ— ğ¶!!!  + ğ‘–!  âˆ— ğ¶!                                                                 (10) \n",
            "Folder name : My Drive > PDF > Finally, LSTM decides the output, which is based on the cell state.  LSTM first runs a sigmoid layer, \n",
            "Folder name : My Drive > PDF > which decides which parts of the cell state to output in Equation (11), called â€œoutput gateâ€. Then, \n",
            "Folder name : My Drive > PDF > LSTM puts the cell state through the tanh function and multiplies it by the output of the sigmoid \n",
            "Folder name : My Drive > PDF > gate, so that LSTM only outputs the parts it decides to as Equation (12).  \n",
            "Folder name : My Drive > PDF >                                    ğ‘œ!  =  ğœ ğ‘Š!ğ‘¥! + ğ‘ˆ!â„!!!                                                                      (11) \n",
            "Folder name : My Drive > PDF >                                    â„! =  ğ‘œ!  âˆ— tanh ğ¶!                                                                                 (12) \n",
            "Folder name : My Drive > PDF > LSTM is commonly applied to sequential data but can also be used for tree-structured data. Tai et \n",
            "Folder name : My Drive > PDF > al.26 introduced a generalization of the standard LSTM to Tree-structured LSTM (Tree-LSTM) and \n",
            "Folder name : My Drive > PDF > showed better performances for representing sentence meaning than a sequential LSTM.  \n",
            "Folder name : My Drive > PDF > A slight variation of LSTM is the Gated Recurrent Unit (GRU).27,28 It combines the â€œforgetâ€ and â€œinputâ€ \n",
            "Folder name : My Drive > PDF > gates into a single update gate. It also merges the cell state and hidden state, and makes some other \n",
            "Folder name : My Drive > PDF > changes. The resulting model is simpler than the standard LSTM model, and has been growing in \n",
            "Folder name : My Drive > PDF > popularity. \n",
            "Folder name : My Drive > PDF > ATTENTION MECHANISM WITH RECURRENT NEURAL NETWORK \n",
            "Folder name : My Drive > PDF > Supposedly, bidirectional RNN and LSTM should be able to deal with long-range dependencies in \n",
            "Folder name : My Drive > PDF > data. But in practice, the long-range dependencies are still problematic to handle. Thus, a technique \n",
            "Folder name : My Drive > PDF > called the Attention Mechanism was proposed.   \n",
            "Folder name : My Drive > PDF > The attention mechanism in neural networks is inspired by the visual attention mechanism found in \n",
            "Folder name : My Drive > PDF > humans. That is, the human visual attention is able to focus on a certain region of an image with \n",
            "Folder name : My Drive > PDF > â€œhigh resolutionâ€ while perceiving the surrounding image in â€œlow resolutionâ€ and then adjusting the \n",
            "Folder name : My Drive > PDF > focal point over time. In NLP, the attention mechanism allows the model to learn what to attend to \n",
            "Folder name : My Drive > PDF > based on the input text and what it has produced so far, rather than encoding the full source text \n",
            "Folder name : My Drive > PDF > into a fixed-length vector like standard RNN and LSTM. \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 8:  Attention mechanism in bidirectional recurrent neural network \n",
            "Folder name : My Drive > PDF > Bahdanau et al.29 first utilized the attention mechanism for machine translation in NLP. They \n",
            "Folder name : My Drive > PDF > proposed an encoder-decoder framework where an attention mechanism is used to select reference \n",
            "Folder name : My Drive > PDF > words in the original language for words in the target language before translation. Figure 8 \n",
            "Folder name : My Drive > PDF > illustrates the use of the attention mechanism in their bidirectional RNN. Note that each decoder \n",
            "Folder name : My Drive > PDF > output word ğ‘¦! depends on a weighted combination of all the input states, not just the last state as \n",
            "Folder name : My Drive > PDF > in the normal case. ğ‘!,!  are weights that define in how much of each input state should be weighted \n",
            "Folder name : My Drive > PDF > for each output. For example, if ğ‘!,! has a big value, it means that the decoder pays a lot of \n",
            "Folder name : My Drive > PDF > attention to the second state in the source sentence while producing the second word of the target \n",
            "Folder name : My Drive > PDF > sentence. The weights of ğ‘!,! sum to 1 normally.  \n",
            "Folder name : My Drive > PDF > MEMORY NETWORK \n",
            "Folder name : My Drive > PDF > Weston et al.30 introduced the concept of Memory Networks (MemNN) for the question answering \n",
            "Folder name : My Drive > PDF > problem. It works with several inference components combined with a large long-term memory. The \n",
            "Folder name : My Drive > PDF > components can be neural networks. The memory acts as a dynamic knowledge base. The four \n",
            "Folder name : My Drive > PDF > learnable/inference components function as follows: I component coverts the incoming input to the \n",
            "Folder name : My Drive > PDF > internal feature representation; G component updates old memories given the new input; O \n",
            "Folder name : My Drive > PDF > component generates output (also in the feature representation space); R component converts the \n",
            "Folder name : My Drive > PDF > output into a response format. For instance, given a list of sentences and a question for question \n",
            "Folder name : My Drive > PDF > answering, MemNN finds evidences from those sentences and generates an answer. During \n",
            "Folder name : My Drive > PDF > inference, the I component reads one sentence at a time and encodes it into a vector representation. \n",
            "Folder name : My Drive > PDF > Then the G component updates a piece of memory based on the current sentence representation. \n",
            "Folder name : My Drive > PDF > After all sentences are processed, a memory matrix (each row representing a sentence) is generated, \n",
            "Folder name : My Drive > PDF > which stores the semantics of the sentences. For a question, MemNN encodes it into a vector \n",
            "Folder name : My Drive > PDF > representation, then the O component uses the vector to select some related evidences from the \n",
            "Folder name : My Drive > PDF > memory and generates an output vector. Finally, the R component takes the output vector as the \n",
            "Folder name : My Drive > PDF > input and outputs a final response.  \n",
            "Folder name : My Drive > PDF > Based on MemNN, Sukhbaatar et al.31 proposed an End-to-End Memory Network (MemN2N), which \n",
            "Folder name : My Drive > PDF > is a neural network architecture with a recurrent attention mechanism over the long-term memory \n",
            "Folder name : My Drive > PDF > component and it can be trained in an End-to-End manner through standard backpropagation. It \n",
            "Folder name : My Drive > PDF > demonstrates that multiple computational layers (hops) in the O component can uncover more \n",
            "Folder name : My Drive > PDF > abstractive evidences than a single layer and yield improved results for question answering and \n",
            "Folder name : My Drive > PDF > language modelling. It is worth noting that each computational layer can be a content-based \n",
            "Folder name : My Drive > PDF > attention model. Thus, MemN2N refines the attention mechanism to some extent. Note also a \n",
            "Folder name : My Drive > PDF > similar idea is the Neural Turing Machines reported by Graves et al.32 \n",
            "Folder name : My Drive > PDF > RECURSIVE NEURAL NETWORK \n",
            "Folder name : My Drive > PDF > Recursive Neural Network (RecNN) is a type of neural network that is usually used to learn a \n",
            "Folder name : My Drive > PDF > directed acyclic graph structure (e.g., tree structure) from data. A recursive neural network can be \n",
            "Folder name : My Drive > PDF > seen as a generalization of the recurrent neural network. Given the structural representation of a \n",
            "Folder name : My Drive > PDF > sentence (e.g., a parse tree), RecNN recursively generates parent representations in a bottom-up \n",
            "Folder name : My Drive > PDF > fashion, by combining tokens to produce representations for phrases, eventually the whole sentence. \n",
            "Folder name : My Drive > PDF > The sentence level representation can then be used to make a final classification (e.g., sentiment \n",
            "Folder name : My Drive > PDF > classification) for a given input sentence. An example process of vector composition in RecNN is \n",
            "Folder name : My Drive > PDF > shown in Figure 9 33. The vector of node â€œvery interestingâ€ is composed from the vectors of the node \n",
            "Folder name : My Drive > PDF > â€œveryâ€ and the node â€œinterestingâ€. Similarly, the node â€œis very interestingâ€ is composed from the \n",
            "Folder name : My Drive > PDF > phrase node â€œvery interestingâ€ and the word node â€œisâ€. \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Figure 9:  Recursive Neural network \n",
            "Folder name : My Drive > PDF > SENTIMENT ANALYSIS TASKS \n",
            "Folder name : My Drive > PDF > We are now ready to survey deep learning applications in sentiment analysis. But before doing that, \n",
            "Folder name : My Drive > PDF > we first briefly introduce the main sentiment analysis tasks in this section. For additional details, \n",
            "Folder name : My Drive > PDF > please refer to Liuâ€™s book1 on sentiment analysis.  \n",
            "Folder name : My Drive > PDF > Researchers have mainly studied sentiment analysis at three levels of granularity: document level, \n",
            "Folder name : My Drive > PDF > sentence level, and aspect level. Document level sentiment classification classifies an opinionated \n",
            "Folder name : My Drive > PDF > document (e.g., a product review) as expressing an overall positive or negative opinion. It considers \n",
            "Folder name : My Drive > PDF > the whole document as the basic information unit and assumes that the document is known to be \n",
            "Folder name : My Drive > PDF > opinionated and contain opinions about a single entity (e.g., a particular phone). Sentence level \n",
            "Folder name : My Drive > PDF > sentiment classification classifies individual sentences in a document. However, each sentence \n",
            "Folder name : My Drive > PDF > cannot be assumed to be opinionated. Traditionally, one often first classifies a sentence as \n",
            "Folder name : My Drive > PDF > opinionated or not opinionated, which is called subjectivity classification. Then the resulting \n",
            "Folder name : My Drive > PDF > opinionated sentences are classified as expressing positive or negative opinions. Sentence level \n",
            "Folder name : My Drive > PDF > sentiment classification can also be formulated as a three-class classification problem, that is, to \n",
            "Folder name : My Drive > PDF > classify a sentence as neutral, positive or negative. Compared with document level and sentence \n",
            "Folder name : My Drive > PDF > level sentiment analysis, aspect level sentiment analysis or aspect-based sentiment analysis is more \n",
            "Folder name : My Drive > PDF > fine-grained. Its task is to extract and summarize peopleâ€™s opinions expressed on entities and \n",
            "Folder name : My Drive > PDF > aspects/features of entities, which are also called targets. For example, in a product review, it aims \n",
            "Folder name : My Drive > PDF > to summarize positive and negative opinions on different aspects of the product respectively, \n",
            "Folder name : My Drive > PDF > although the general sentiment on the product could be positive or negative. The whole task of \n",
            "Folder name : My Drive > PDF > aspect-based sentiment analysis consists of several subtasks such as aspect extraction, entity \n",
            "Folder name : My Drive > PDF > extraction, and aspect sentiment classification. For example, from the sentence, â€œthe voice quality \n",
            "Folder name : My Drive > PDF > of iPhone is great, but its battery sucksâ€, entity extraction should identify â€œiPhoneâ€ as the entity, and \n",
            "Folder name : My Drive > PDF > aspect extraction should identify that â€œvoice qualityâ€ and â€œbatteryâ€ are two aspects. Aspect \n",
            "Folder name : My Drive > PDF > sentiment classification should classify the sentiment expressed on the voice quality of the iPhone as \n",
            "Folder name : My Drive > PDF > positive and on the battery of the iPhone as negative. Note that for simplicity, in most algorithms \n",
            "Folder name : My Drive > PDF > aspect extraction and entity extraction are combined and are called aspect extraction or \n",
            "Folder name : My Drive > PDF > sentiment/opinion target extraction.  \n",
            "Folder name : My Drive > PDF > Apart from these core tasks, sentiment analysis also studies emotion analysis, sarcasm detection, \n",
            "Folder name : My Drive > PDF > multilingual sentiment analysis, etc. See Liuâ€™s book1 for more details. In the following sections, we \n",
            "Folder name : My Drive > PDF > survey the deep learning applications in all these sentiment analysis tasks.  \n",
            "Folder name : My Drive > PDF > DOCUMENT LEVEL SENTIMENT CLASSIFICATION \n",
            "Folder name : My Drive > PDF > Sentiment classification at the document level is to assign an overall sentiment orientation/polarity \n",
            "Folder name : My Drive > PDF > to an opinion document, i.e., to determine whether the document (e.g., a full online review) conveys \n",
            "Folder name : My Drive > PDF > an overall positive or negative opinion. In this setting, it is a binary classification task. It can also be \n",
            "Folder name : My Drive > PDF > formulated as a regression task, for example, to infer an overall rating score from 1 to 5 stars for the \n",
            "Folder name : My Drive > PDF > review. Some researchers also treat this as a 5-class classification task.  \n",
            "Folder name : My Drive > PDF > Sentiment classification is commonly regarded as a special case of document classification. In such a \n",
            "Folder name : My Drive > PDF > classification, document representation plays an important role, which should reflect the original \n",
            "Folder name : My Drive > PDF > information conveyed by words or sentences in a document. Traditionally, the bag-of-words model \n",
            "Folder name : My Drive > PDF > (BoW) is used to generate text representations in NLP and text mining, by which a document is \n",
            "Folder name : My Drive > PDF > regarded as a bag of its words. Based on BoW, a document is transformed to a numeric feature \n",
            "Folder name : My Drive > PDF > vector with a fixed length, each element of which can be the word occurrence (absence or presence), \n",
            "Folder name : My Drive > PDF > word frequency, or TF-IDF score. Its dimension equals to the size of the vocabulary. A document \n",
            "Folder name : My Drive > PDF > vector from BoW is normally very sparse since a single document only contains a small number of \n",
            "Folder name : My Drive > PDF > words in a vocabulary. Early neural networks adopted such feature settings.  \n",
            "Folder name : My Drive > PDF > Despite its popularity, BoW has some disadvantages. Firstly, the word order is ignored, which means \n",
            "Folder name : My Drive > PDF > that two documents can have exactly the same representation as long as they share the same words. \n",
            "Folder name : My Drive > PDF > Bag-of-N-Grams, an extension for BoW, can consider the word order in a short context (n-gram), but \n",
            "Folder name : My Drive > PDF > it also suffers from data sparsity and high dimensionality. Secondly, BoW can barely encode the \n",
            "Folder name : My Drive > PDF > semantics of words. For example, the words â€œsmartâ€, â€œcleverâ€ and â€œbookâ€ are of equal distance \n",
            "Folder name : My Drive > PDF > between them in BoW, but â€œsmartâ€ should be closer to â€œcleverâ€ than â€œbookâ€ semantically.  \n",
            "Folder name : My Drive > PDF > To tackle the shortcomings of BoW, word embedding techniques based on neural networks \n",
            "Folder name : My Drive > PDF > (introduced in the aforementioned section) were proposed to generate dense vectors (or low-\n",
            "Folder name : My Drive > PDF > dimensional vectors) for word representation, which are, to some extent, able to encode some \n",
            "Folder name : My Drive > PDF > semantic and syntactic properties of words. With word embeddings as input of words, document \n",
            "Folder name : My Drive > PDF > representation as a dense vector (or called dense document vector) can be derived using neural \n",
            "Folder name : My Drive > PDF > networks. \n",
            "Folder name : My Drive > PDF > Notice that in addition to the above two approaches, i.e., using BoW and learning dense vectors for \n",
            "Folder name : My Drive > PDF > documents through word embeddings, one can also learn a dense document vector directly from \n",
            "Folder name : My Drive > PDF > BoW. We distinguish the different approaches used in related studies in Table 2. \n",
            "Folder name : My Drive > PDF > When documents are properly represented, sentiment classification can be conducted using a \n",
            "Folder name : My Drive > PDF > variety of neural network models following the traditional supervised learning setting. In some cases, \n",
            "Folder name : My Drive > PDF > neural networks may only be used to extract text features/text representations, and these features \n",
            "Folder name : My Drive > PDF > are fed into some other non-neural classifiers (e.g., SVM) to obtain a final global optimum classifier. \n",
            "Folder name : My Drive > PDF > The properties of neural networks and SVM complement each other in such a way that their \n",
            "Folder name : My Drive > PDF > advantages are combined.    \n",
            "Folder name : My Drive > PDF > Besides sophisticated document/text representations, researchers also leveraged the characteristics \n",
            "Folder name : My Drive > PDF > of the data â€“ product reviews, for sentiment classification. For product reviews, several researchers \n",
            "Folder name : My Drive > PDF > found it beneficial to jointly model sentiment and some additional information (e.g., user \n",
            "Folder name : My Drive > PDF > information and product information) for classification. Additionally, since a document often \n",
            "Folder name : My Drive > PDF > contains long dependency relations, the attention mechanism is also frequently used in document \n",
            "Folder name : My Drive > PDF > level sentiment classification. We summarize the existing techniques in Table 2.  \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Research \n",
            "Folder name : My Drive > PDF > Work \n",
            "Folder name : My Drive > PDF > Document/Text \n",
            "Folder name : My Drive > PDF > Representation \n",
            "Folder name : My Drive > PDF > Neural \n",
            "Folder name : My Drive > PDF > Networks \n",
            "Folder name : My Drive > PDF > Model \n",
            "Folder name : My Drive > PDF > Use Attention \n",
            "Folder name : My Drive > PDF > Mechanism \n",
            "Folder name : My Drive > PDF > Joint Modelling \n",
            "Folder name : My Drive > PDF > with Sentiment \n",
            "Folder name : My Drive > PDF > Moraes et al.34 \n",
            "Folder name : My Drive > PDF > BoW \n",
            "Folder name : My Drive > PDF > ANN \n",
            "Folder name : My Drive > PDF > (Artificial \n",
            "Folder name : My Drive > PDF > Neural \n",
            "Folder name : My Drive > PDF > Network) \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > - \n",
            "Folder name : My Drive > PDF > Le \n",
            "Folder name : My Drive > PDF > and \n",
            "Folder name : My Drive > PDF > Mikolov35 \n",
            "Folder name : My Drive > PDF > Learning dense vector at \n",
            "Folder name : My Drive > PDF > sentence, \n",
            "Folder name : My Drive > PDF > paragraph, \n",
            "Folder name : My Drive > PDF > document level  \n",
            "Folder name : My Drive > PDF > Paragraph Vector \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > - \n",
            "Folder name : My Drive > PDF > Glorot et al.36 \n",
            "Folder name : My Drive > PDF > BoW to dense document \n",
            "Folder name : My Drive > PDF > vector  \n",
            "Folder name : My Drive > PDF > SDA \n",
            "Folder name : My Drive > PDF > (Stacked \n",
            "Folder name : My Drive > PDF > Denoising \n",
            "Folder name : My Drive > PDF > Autoencoder) \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > Unsupervised \n",
            "Folder name : My Drive > PDF > data \n",
            "Folder name : My Drive > PDF > representation from \n",
            "Folder name : My Drive > PDF > target domains (in \n",
            "Folder name : My Drive > PDF > transfer \n",
            "Folder name : My Drive > PDF > learning \n",
            "Folder name : My Drive > PDF > settings) \n",
            "Folder name : My Drive > PDF > Zhai \n",
            "Folder name : My Drive > PDF > and \n",
            "Folder name : My Drive > PDF > Zhang37 \n",
            "Folder name : My Drive > PDF > BoW to dense document \n",
            "Folder name : My Drive > PDF > vector  \n",
            "Folder name : My Drive > PDF > DAE \n",
            "Folder name : My Drive > PDF > (Denoising \n",
            "Folder name : My Drive > PDF > Autoencoder) \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > - \n",
            "Folder name : My Drive > PDF > Johnson \n",
            "Folder name : My Drive > PDF > and \n",
            "Folder name : My Drive > PDF > Zhang38 \n",
            "Folder name : My Drive > PDF > BoW to dense document \n",
            "Folder name : My Drive > PDF > vector \n",
            "Folder name : My Drive > PDF > BoW-CNN and Seq-CNN \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > - \n",
            "Folder name : My Drive > PDF > Tang et al.39 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector  \n",
            "Folder name : My Drive > PDF > CNN/LSTM \n",
            "Folder name : My Drive > PDF > (to \n",
            "Folder name : My Drive > PDF > learn \n",
            "Folder name : My Drive > PDF > sentence representation) + \n",
            "Folder name : My Drive > PDF > GRU (to learn document \n",
            "Folder name : My Drive > PDF > representation) \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > - \n",
            "Folder name : My Drive > PDF > Tang et al.40 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector  \n",
            "Folder name : My Drive > PDF > UPNN (User Product Neutral \n",
            "Folder name : My Drive > PDF > Network) based on CNN \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > User information and \n",
            "Folder name : My Drive > PDF > product information \n",
            "Folder name : My Drive > PDF > Chen et al.41 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector  \n",
            "Folder name : My Drive > PDF > UPA \n",
            "Folder name : My Drive > PDF > (User \n",
            "Folder name : My Drive > PDF > Product \n",
            "Folder name : My Drive > PDF > Attention) based on LSTM \n",
            "Folder name : My Drive > PDF > Yes \n",
            "Folder name : My Drive > PDF > User information and \n",
            "Folder name : My Drive > PDF > product Information \n",
            "Folder name : My Drive > PDF > Dou42 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector \n",
            "Folder name : My Drive > PDF > Memory Network \n",
            "Folder name : My Drive > PDF > Yes \n",
            "Folder name : My Drive > PDF > User information and \n",
            "Folder name : My Drive > PDF > product Information \n",
            "Folder name : My Drive > PDF > Xu et al.43 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector \n",
            "Folder name : My Drive > PDF > LSTM \n",
            "Folder name : My Drive > PDF > No \n",
            "Folder name : My Drive > PDF > - \n",
            "Folder name : My Drive > PDF > Yang et al.44 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector \n",
            "Folder name : My Drive > PDF > GRU-based \n",
            "Folder name : My Drive > PDF > sequence \n",
            "Folder name : My Drive > PDF > encoder \n",
            "Folder name : My Drive > PDF > Hierarchical \n",
            "Folder name : My Drive > PDF > attention \n",
            "Folder name : My Drive > PDF > - \n",
            "Folder name : My Drive > PDF > Yin et al.45 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector \n",
            "Folder name : My Drive > PDF > Input encoder and LSTM \n",
            "Folder name : My Drive > PDF > Hierarchical \n",
            "Folder name : My Drive > PDF > attention \n",
            "Folder name : My Drive > PDF > Aspect/target \n",
            "Folder name : My Drive > PDF > information \n",
            "Folder name : My Drive > PDF > Zhou et al.46 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector \n",
            "Folder name : My Drive > PDF > LSTM \n",
            "Folder name : My Drive > PDF > Hierarchical \n",
            "Folder name : My Drive > PDF > attention \n",
            "Folder name : My Drive > PDF > Cross-lingual \n",
            "Folder name : My Drive > PDF > information \n",
            "Folder name : My Drive > PDF > Li et al.47 \n",
            "Folder name : My Drive > PDF > Word \n",
            "Folder name : My Drive > PDF > embeddings \n",
            "Folder name : My Drive > PDF > to \n",
            "Folder name : My Drive > PDF > dense document vector \n",
            "Folder name : My Drive > PDF > Memory Network \n",
            "Folder name : My Drive > PDF > Yes \n",
            "Folder name : My Drive > PDF > Cross-domain \n",
            "Folder name : My Drive > PDF > information \n",
            "Folder name : My Drive > PDF > Table 2: Deep learning methods for document level sentiment classification \n",
            "Folder name : My Drive > PDF > Below, we also give a brief description of these existing representative works.  \n",
            "Folder name : My Drive > PDF > Moraes et al.34 made an empirical comparison between Support Vector Machines (SVM) and \n",
            "Folder name : My Drive > PDF > Artificial Neural Networks (ANN) for document level sentiment classification, which demonstrated \n",
            "Folder name : My Drive > PDF > that ANN produced competitive results to SVMâ€™s in most cases. \n",
            "Folder name : My Drive > PDF > To overcome the weakness of BoW, Le and Mikolov35 proposed Paragraph Vector, an unsupervised \n",
            "Folder name : My Drive > PDF > learning algorithm that learns vector representations for variable-length texts such as sentences, \n",
            "Folder name : My Drive > PDF > paragraphs and documents. The vector representations are learned by predicting the surrounding \n",
            "Folder name : My Drive > PDF > words in contexts sampled from the paragraph. \n",
            "Folder name : My Drive > PDF > Glorot et al.36 studied domain adaptation problem for sentiment classification. They proposed a \n",
            "Folder name : My Drive > PDF > deep learning system based on Stacked Denoising Autoencoder with sparse rectifier units, which can \n",
            "Folder name : My Drive > PDF > perform an unsupervised text feature/representation extraction using both labeled and unlabeled \n",
            "Folder name : My Drive > PDF > data. The features are highly beneficial for domain adaption of sentiment classifiers. \n",
            "Folder name : My Drive > PDF > Zhai and Zhang37 introduced a semi-supervised autoencoder, which further considers the sentiment \n",
            "Folder name : My Drive > PDF > information in its learning stage in order to obtain better document vectors, for sentiment \n",
            "Folder name : My Drive > PDF > classification. More specifically, the model learns a task-specific representation of the textual data \n",
            "Folder name : My Drive > PDF > by relaxing the loss function in the autoencoder to the Bregman Divergence and also deriving a \n",
            "Folder name : My Drive > PDF > discriminative loss function from the label information. \n",
            "Folder name : My Drive > PDF > Johnson and Zhang38 proposed a CNN variant named BoW-CNN that employs bag-of-word \n",
            "Folder name : My Drive > PDF > conversion in the convolution layer. They also designed a new model, called Seq-CNN, which keeps \n",
            "Folder name : My Drive > PDF > the sequential information of words by concatenating the one-hot vector of multiple words. \n",
            "Folder name : My Drive > PDF > Tang et al.39 proposed a neural network to learn document representation, with the consideration of \n",
            "Folder name : My Drive > PDF > sentence relationships. It first learns the sentence representation with CNN or LSTM from word \n",
            "Folder name : My Drive > PDF > embeddings. Then a GRU is utilized to adaptively encode semantics of sentences and their inherent \n",
            "Folder name : My Drive > PDF > relations in document representations for sentiment classification.  \n",
            "Folder name : My Drive > PDF > Tang et al.40 applied user representations and product representations in review classification. The \n",
            "Folder name : My Drive > PDF > idea is that those representations can capture important global clues such as individual preferences \n",
            "Folder name : My Drive > PDF > of users and overall qualities of products, which can provide better text representations.  \n",
            "Folder name : My Drive > PDF > Chen et al.41 also incorporated user information and product information for classification but via \n",
            "Folder name : My Drive > PDF > word and sentence level attentions, which can take into account of the global user preference and \n",
            "Folder name : My Drive > PDF > product characteristics at both the word level and the semantic level. Likewise, Dou42 used a deep \n",
            "Folder name : My Drive > PDF > memory network to capture user and product information. The proposed model can be divided into \n",
            "Folder name : My Drive > PDF > two separate parts. In the first part, LSTM is applied to learn a document representation. In the \n",
            "Folder name : My Drive > PDF > second part, a deep memory network consisting of multiple computational layers (hops) is used to \n",
            "Folder name : My Drive > PDF > predict the review rating for each document.  \n",
            "Folder name : My Drive > PDF > Xu et al.43 proposed a cached LSTM model to capture the overall semantic information in a long text. \n",
            "Folder name : My Drive > PDF > The memory in the model is divided into several groups with different forgetting rates. The intuition \n",
            "Folder name : My Drive > PDF > is to enable the memory groups with low forgetting rates to capture global semantic features and \n",
            "Folder name : My Drive > PDF > the ones with high forgetting rates to learn local semantic features. \n",
            "Folder name : My Drive > PDF > Yang et al.44 proposed a hierarchical attention network for document level sentiment rating \n",
            "Folder name : My Drive > PDF > prediction of reviews. The model includes two levels of attention mechanisms: one at the word level \n",
            "Folder name : My Drive > PDF > and the other at the sentence level, which allow the model to pay more or less attention to \n",
            "Folder name : My Drive > PDF > individual words or sentences in constructing the representation of a document.  \n",
            "Folder name : My Drive > PDF > Yin et al.45 formulated the document-level aspect-sentiment rating prediction task as a machine \n",
            "Folder name : My Drive > PDF > comprehension problem and proposed a hierarchical interactive attention-based model. Specifically, \n",
            "Folder name : My Drive > PDF > documents and pseudo aspect-questions are interleaved to learn aspect-aware document \n",
            "Folder name : My Drive > PDF > representation.  \n",
            "Folder name : My Drive > PDF > Zhou et al.46 designed an attention-based LSTM network for cross-lingual sentiment classification at \n",
            "Folder name : My Drive > PDF > the document level. The model consists of two attention-based LSTMs for bilingual representation, \n",
            "Folder name : My Drive > PDF > and each LSTM is also hierarchically structured. In this setting, it effectively adapts the sentiment \n",
            "Folder name : My Drive > PDF > information from a resource-rich language (English) to a resource-poor language (Chinese) and helps \n",
            "Folder name : My Drive > PDF > improve the sentiment classification performance.  \n",
            "Folder name : My Drive > PDF > Li et al.47 proposed an adversarial memory network for cross-domain sentiment classification in a \n",
            "Folder name : My Drive > PDF > transfer learning setting, where the data from the source and the target domain are modelled \n",
            "Folder name : My Drive > PDF > together. It jointly trains two networks for sentiment classification and domain classification (i.e., \n",
            "Folder name : My Drive > PDF > whether a document is from the source or target domain). \n",
            "Folder name : My Drive > PDF > SENTENCE LEVEL SENTIMENT CLASSIFICATION \n",
            "Folder name : My Drive > PDF > Sentence level sentiment classification is to determine the sentiment expressed in a single given \n",
            "Folder name : My Drive > PDF > sentence. As discussed earlier, the sentiment of a sentence can be inferred with subjectivity \n",
            "Folder name : My Drive > PDF > classification48 and polarity classification, where the former classifies whether a sentence is \n",
            "Folder name : My Drive > PDF > subjective or objective and the latter decides whether a subjective sentence expresses a negative or \n",
            "Folder name : My Drive > PDF > positive sentiment. In existing deep learning models, sentence sentiment classification is usually \n",
            "Folder name : My Drive > PDF > formulated as a joint three-way classification problem, namely, to predict a sentence as positive, \n",
            "Folder name : My Drive > PDF > neural, and negative.  \n",
            "Folder name : My Drive > PDF > Same as document level sentiment classification, sentence representation produced by neural \n",
            "Folder name : My Drive > PDF > networks is also important for sentence level sentiment classification. Additionally, since a sentence \n",
            "Folder name : My Drive > PDF > is usually short compared to a document, some syntactic and semantic information (e.g., parse \n",
            "Folder name : My Drive > PDF > trees, opinion lexicons, and part-of-speech tags) may be used to help. Additional information such as \n",
            "Folder name : My Drive > PDF > review ratings, social relationship, and cross-domain information can be considered too. For \n",
            "Folder name : My Drive > PDF > example, social relationships have been exploited in discovering sentiments in social media data \n",
            "Folder name : My Drive > PDF > such as tweets. \n",
            "Folder name : My Drive > PDF > In early research, parse trees (which provide some semantic and syntactic information) were used \n",
            "Folder name : My Drive > PDF > together with the original words as the input to neural models, so that the sentiment composition \n",
            "Folder name : My Drive > PDF > can be better inferred. But lately, CNN and RNN become more popular, and they do not need parse \n",
            "Folder name : My Drive > PDF > trees to extract features from sentences. Instead, CNN and RNN use word embeddings as input, \n",
            "Folder name : My Drive > PDF > which already encode some semantic and syntactic information. Moreover, the model architecture \n",
            "Folder name : My Drive > PDF > of CNN or RNN can help learn intrinsic relationships between words in a sentence too. The related \n",
            "Folder name : My Drive > PDF > works are introduced in detail below.     \n",
            "Folder name : My Drive > PDF > Socher et al.49 first proposed a semi-supervised Recursive Autoencoders Network (RAE) for \n",
            "Folder name : My Drive > PDF > sentence level sentiment classification, which obtains a reduced dimensional vector representation \n",
            "Folder name : My Drive > PDF > for a sentence. Later on, Socher et al.50 proposed a Matrix-vector Recursive Neural Network (MV-\n",
            "Folder name : My Drive > PDF > RNN), in which each word is additionally associated with a matrix representation (besides a vector \n",
            "Folder name : My Drive > PDF > representation) in a tree structure. The tree structure is obtained from an external parser. In Socher \n",
            "Folder name : My Drive > PDF > et al.51, the authors further introduced the Recursive Neural Tensor Network (RNTN), where tensor-\n",
            "Folder name : My Drive > PDF > based compositional functions are used to better capture the interactions between elements. Qian \n",
            "Folder name : My Drive > PDF > et al.33 proposed two more advanced models, Tag-guided Recursive Neural Network (TG-RNN), \n",
            "Folder name : My Drive > PDF > which chooses a composition function according to the part-of-speech tags of a phrase, and Tag-\n",
            "Folder name : My Drive > PDF > embedded Recursive Neural Network / Recursive Neural Tenser Network (TE-RNN/RNTN), which \n",
            "Folder name : My Drive > PDF > learns tag embeddings and then combines tag and word embeddings together.  \n",
            "Folder name : My Drive > PDF > Kalchbrenner et al.52 proposed a Dynamic CNN (called DCNN) for semantic modelling of sentences. \n",
            "Folder name : My Drive > PDF > DCNN uses the dynamic K-Max pooling operator as a non-linear subsampling function. The feature \n",
            "Folder name : My Drive > PDF > graph induced by the network is able to capture word relations. Kim53 also proposed to use CNN for \n",
            "Folder name : My Drive > PDF > sentence-level sentiment classification and experimented with several variants, namely CNN-rand \n",
            "Folder name : My Drive > PDF > (where word embeddings are randomly initialized), CNN-static (where word embeddings are pre-\n",
            "Folder name : My Drive > PDF > trained and fixed), CNN-non-static (where word embeddings are pre-trained and fine-tuned) and \n",
            "Folder name : My Drive > PDF > CNN-multichannel (where multiple sets of word embeddings are used).  \n",
            "Folder name : My Drive > PDF > dos Santos and Gatti54 proposed a Character to Sentence CNN (CharSCNN) model. CharSCNN uses \n",
            "Folder name : My Drive > PDF > two convolutional layers to extract relevant features from words and sentences of any size to \n",
            "Folder name : My Drive > PDF > perform sentiment analysis of short texts. Wang et al.55 utilized LSTM for Twitter sentiment \n",
            "Folder name : My Drive > PDF > classification by simulating the interactions of words during the compositional process. \n",
            "Folder name : My Drive > PDF > Multiplicative operations between word embeddings through gate structures are used to provide \n",
            "Folder name : My Drive > PDF > more flexibility and to produce better compositional results compared to the additive ones in simple \n",
            "Folder name : My Drive > PDF > recurrent neural network. Similar to bidirectional RNN, the unidirectional LSTM can be extended to a \n",
            "Folder name : My Drive > PDF > bidirectional LSTM56 by allowing bidirectional connections in the hidden layer.  \n",
            "Folder name : My Drive > PDF > Wang et al.57 proposed a regional CNN-LSTM model, which consists of two parts: regional CNN and \n",
            "Folder name : My Drive > PDF > LSTM, to predict the valence arousal ratings of text.  \n",
            "Folder name : My Drive > PDF > Wang et al.58 described a joint CNN and RNN architecture for sentiment classification of short texts, \n",
            "Folder name : My Drive > PDF > which takes advantage of the coarse-grained local features generated by CNN and long-distance \n",
            "Folder name : My Drive > PDF > dependencies learned via RNN. \n",
            "Folder name : My Drive > PDF > Guggilla et al.59 presented a LSTM- and CNN-based deep neural network model, which utilizes \n",
            "Folder name : My Drive > PDF > word2vec and linguistic embeddings for claim classification (classifying sentences to be factual or \n",
            "Folder name : My Drive > PDF > feeling). \n",
            "Folder name : My Drive > PDF > Huang et al.60 proposed to encode the syntactic knowledge (e.g., part-of-speech tags) in a tree-\n",
            "Folder name : My Drive > PDF > structured LSTM to enhance phrase and sentence representation. \n",
            "Folder name : My Drive > PDF > Akhtar et al.61 proposed several multi-layer perceptron based ensemble models for fine-gained \n",
            "Folder name : My Drive > PDF > sentiment classification of financial microblogs and news. \n",
            "Folder name : My Drive > PDF > Guan et al.62 employed a weakly-supervised CNN for sentence (and also aspect) level sentiment \n",
            "Folder name : My Drive > PDF > classification. It contains a two-step learning process: it first learns a sentence representation weakly \n",
            "Folder name : My Drive > PDF > supervised by overall review ratings and then uses the sentence (and aspect) level labels for fine-\n",
            "Folder name : My Drive > PDF > tuning.  \n",
            "Folder name : My Drive > PDF > Teng et al.63 proposed a context-sensitive lexicon-based method for sentiment classification based \n",
            "Folder name : My Drive > PDF > on a simple weighted-sum model, using bidirectional LSTM to learn the sentiment strength, \n",
            "Folder name : My Drive > PDF > intensification and negation of lexicon sentiments in composing the sentiment value of a sentence.  \n",
            "Folder name : My Drive > PDF > Yu and Jiang64 studied the problem of learning generalized sentence embeddings for cross-domain \n",
            "Folder name : My Drive > PDF > sentence sentiment classification and designed a neural network model containing two separated \n",
            "Folder name : My Drive > PDF > CNNs that jointly learn two hidden feature representations from both the labeled and unlabeled \n",
            "Folder name : My Drive > PDF > data.  \n",
            "Folder name : My Drive > PDF > Zhao et al.65 introduced a recurrent random walk network learning approach for sentiment \n",
            "Folder name : My Drive > PDF > classification of opinionated tweets by exploiting the deep semantic representation of both user \n",
            "Folder name : My Drive > PDF > posted tweets and their social relationships.  \n",
            "Folder name : My Drive > PDF > Mishra et al.66 utilized CNN to automatically extract cognitive features from the eye-movement (or \n",
            "Folder name : My Drive > PDF > gaze) data of human readers reading the text and used them as enriched features along with textual \n",
            "Folder name : My Drive > PDF > features for sentiment classification.  \n",
            "Folder name : My Drive > PDF > Qian et al.67 presented a linguistically regularized LSTM for the task. The proposed model \n",
            "Folder name : My Drive > PDF > incorporates linguistic resources such as sentiment lexicon, negation words and intensity words into \n",
            "Folder name : My Drive > PDF > the LSTM so as to capture the sentiment effect in sentences more accurately. \n",
            "Folder name : My Drive > PDF > ASPECT LEVEL SENTIMENT CLASSIFICATION \n",
            "Folder name : My Drive > PDF > Different from the document level and the sentence level sentiment classification, aspect level \n",
            "Folder name : My Drive > PDF > sentiment classification considers both the sentiment and the target information, as a sentiment \n",
            "Folder name : My Drive > PDF > always has a target. As mentioned earlier, a target is usually an entity or an entity aspect. For \n",
            "Folder name : My Drive > PDF > simplicity, both entity and aspect are usually just called aspect. Given a sentence and a target aspect, \n",
            "Folder name : My Drive > PDF > aspect level sentiment classification aims to infer the sentiment polarity/orientation of the sentence \n",
            "Folder name : My Drive > PDF > toward the target aspect. For example, in the sentence â€œthe screen is very clear but the battery life is \n",
            "Folder name : My Drive > PDF > too short.â€ the sentiment is positive if the target aspect is â€œscreenâ€ but negative if the target aspect \n",
            "Folder name : My Drive > PDF > is â€œbattery lifeâ€. We will discuss automated aspect or target extraction in the next section.  \n",
            "Folder name : My Drive > PDF > Aspect level sentiment classification is challenging because modelling the semantic relatedness of a \n",
            "Folder name : My Drive > PDF > target with its surrounding context words is difficult. Different context words have different \n",
            "Folder name : My Drive > PDF > influences on the sentiment polarity of a sentence towards the target. Therefore, it is necessary \n",
            "Folder name : My Drive > PDF > capture semantic connections between the target word and the context words when building \n",
            "Folder name : My Drive > PDF > learning models using neural networks.  \n",
            "Folder name : My Drive > PDF > There are three important tasks in aspect level sentiment classification using neural networks. The \n",
            "Folder name : My Drive > PDF > first task is to represent the context of a target, where the context means the contextual words in a \n",
            "Folder name : My Drive > PDF > sentence or document. This issue can be similarly addressed using the text representation \n",
            "Folder name : My Drive > PDF > approaches mentioned in the above two sections. The second task is to generate a target \n",
            "Folder name : My Drive > PDF > representation, which can properly interact with its context. A general solution is to learn a target \n",
            "Folder name : My Drive > PDF > embedding, which is similar to word embedding. The third task is to identify the important \n",
            "Folder name : My Drive > PDF > sentiment context (words) for the specified target. For example, in the sentence â€œthe screen of \n",
            "Folder name : My Drive > PDF > iPhone is clear but batter life is shortâ€, â€œclearâ€ is the important context word for â€œscreenâ€ and â€œshortâ€ \n",
            "Folder name : My Drive > PDF > is the important context for â€œbattery lifeâ€. This task is recently addressed by the attention \n",
            "Folder name : My Drive > PDF > mechanism. Although many deep learning techniques have been proposed to deal with aspect level \n",
            "Folder name : My Drive > PDF > sentiment classification, to our knowledge, there are still no dominating techniques in the literature. \n",
            "Folder name : My Drive > PDF > Related works and their main focuses are introduced below. \n",
            "Folder name : My Drive > PDF > Dong et al.68 proposed an Adaptive Recursive Neural Network (AdaRNN) for target-dependent \n",
            "Folder name : My Drive > PDF > twitter sentiment classification, which learns to propagate the sentiments of words towards the \n",
            "Folder name : My Drive > PDF > target depending on the context and syntactic structure. It uses the representation of the root node \n",
            "Folder name : My Drive > PDF > as the features, and feeds them into the softmax classifier to predict the distribution over classes.    \n",
            "Folder name : My Drive > PDF > Vo and Zhang69 studied aspect-based Twitter sentiment classification by making use of rich \n",
            "Folder name : My Drive > PDF > automatic features, which are additional features obtained using unsupervised learning methods. \n",
            "Folder name : My Drive > PDF > The paper showed that multiple embeddings, multiple pooling functions, and sentiment lexicons can \n",
            "Folder name : My Drive > PDF > offer rich sources of feature information and help achieve performance gains. \n",
            "Folder name : My Drive > PDF > Since LSTM can capture semantic relations between the target and its context words in a more \n",
            "Folder name : My Drive > PDF > flexible way, Tang et al.70 proposed Target-dependent LSTM (TD-LSTM) and Target-connection LSTM \n",
            "Folder name : My Drive > PDF > (TC-LSTM) to extend LSTM by taking the target into consideration. They regarded the given target as \n",
            "Folder name : My Drive > PDF > a feature and concatenated it with the context features for aspect sentiment classification.  \n",
            "Folder name : My Drive > PDF > Ruder et al.71 proposed to use a hierarchical and bidirectional LSTM model for aspect level sentiment \n",
            "Folder name : My Drive > PDF > classification, which is able to leverage both intra- and inter-sentence relations. The sole \n",
            "Folder name : My Drive > PDF > dependence on sentences and their structures within a review renders the proposed model \n",
            "Folder name : My Drive > PDF > language-independent. Word embeddings are fed into a sentence-level bidirectional LSTM. Final \n",
            "Folder name : My Drive > PDF > states of the forward and backward LSTM are concatenated together with the target embedding and \n",
            "Folder name : My Drive > PDF > fed into a bidirectional review-level LSTM. At every time step, the output of the forward and \n",
            "Folder name : My Drive > PDF > backward LSTM is concatenated and fed into a final layer, which outputs a probability distribution \n",
            "Folder name : My Drive > PDF > over sentiments. \n",
            "Folder name : My Drive > PDF > Considering the limitation of work by Dong et al.68 and Vo and Zhang69, Zhang et al.72 proposed a \n",
            "Folder name : My Drive > PDF > sentence level neural model to address the weakness of pooling functions, which do not explicitly \n",
            "Folder name : My Drive > PDF > model tweet-level semantics. To achieve that, two gated neural networks are presented. First, a bi-\n",
            "Folder name : My Drive > PDF > directional gated neural network is used to connect the words in a tweet so that pooling functions \n",
            "Folder name : My Drive > PDF > can be applied over the hidden layer instead of words for better representing the target and its \n",
            "Folder name : My Drive > PDF > contexts. Second, a three-way gated neural network structure is used to model the interaction \n",
            "Folder name : My Drive > PDF > between the target mention and its surrounding contexts, addressing the limitations by using gated \n",
            "Folder name : My Drive > PDF > neural network structures to model the syntax and semantics of the enclosing tweet, and the \n",
            "Folder name : My Drive > PDF > interaction between the surrounding contexts and the target respectively. Gated neural networks \n",
            "Folder name : My Drive > PDF > have been shown to reduce the bias of standard recurrent neural networks towards the ends of a \n",
            "Folder name : My Drive > PDF > sequence by better propagation of gradients.  \n",
            "Folder name : My Drive > PDF > Wang et al.73 proposed an attention-based LSTM method with target embedding, which was proven \n",
            "Folder name : My Drive > PDF > to be an effective way to enforce the neural model to attend to the related part of a sentence. The \n",
            "Folder name : My Drive > PDF > attention mechanism is used to enforce the model to attend to the important part of a sentence, in \n",
            "Folder name : My Drive > PDF > response to a specific aspect. Likewise, Yang et al.74 proposed two attention-based bidirectional \n",
            "Folder name : My Drive > PDF > LSTMs to improve the classification performance. Liu and Zhang75 extended the attention modelling \n",
            "Folder name : My Drive > PDF > by differentiating the attention obtained from the left context and the right context of a given \n",
            "Folder name : My Drive > PDF > target/aspect. They further controlled their attention contribution by adding multiple gates.  \n",
            "Folder name : My Drive > PDF > Tang et al.76 introduced an end-to-end memory network for aspect level sentiment classification, \n",
            "Folder name : My Drive > PDF > which employs an attention mechanism with an external memory to capture the importance of each \n",
            "Folder name : My Drive > PDF > context word with respect to the given target aspect. This approach explicitly captures the \n",
            "Folder name : My Drive > PDF > importance of each context word when inferring the sentiment polarity of the aspect. Such \n",
            "Folder name : My Drive > PDF > importance degree and text representation are calculated with multiple computational layers, each \n",
            "Folder name : My Drive > PDF > of which is a neural attention model over an external memory.    \n",
            "Folder name : My Drive > PDF > Lei et al.77 proposed to use a neural network approach to extract pieces of input text as rationales \n",
            "Folder name : My Drive > PDF > (reasons) for review ratings. The model consists of a generator and a decoder. The generator \n",
            "Folder name : My Drive > PDF > specifies a distribution over possible rationales (extracted text) and the encoder maps any such text \n",
            "Folder name : My Drive > PDF > to a task-specific target vector. For multi-aspect sentiment analysis, each coordinate of the target \n",
            "Folder name : My Drive > PDF > vector represents the response or rating pertaining to the associated aspect.    \n",
            "Folder name : My Drive > PDF > Li et al.78 integrated the target identification task into sentiment classification task to better model \n",
            "Folder name : My Drive > PDF > aspect-sentiment interaction. They showed that sentiment identification can be solved with an end-\n",
            "Folder name : My Drive > PDF > to-end machine learning architecture, in which the two sub-tasks are interleaved by a deep memory \n",
            "Folder name : My Drive > PDF > network. In this way, signals produced in target detection provide clues for polarity classification, \n",
            "Folder name : My Drive > PDF > and reversely, the predicted polarity provides feedback to the identification of targets.   \n",
            "Folder name : My Drive > PDF > Ma et al.79 proposed an Interactive Attention Network (IAN) that considers both attentions on \n",
            "Folder name : My Drive > PDF > target and context. That is, it uses two attention networks to interactively detect the important \n",
            "Folder name : My Drive > PDF > words of the target expression/description and the important words of its full context.  \n",
            "Folder name : My Drive > PDF > Chen et al.80 proposed to utilize a recurrent attention network to better capture the sentiment of \n",
            "Folder name : My Drive > PDF > complicated contexts. To achieve that, their proposed model uses a recurrent/dynamic attention \n",
            "Folder name : My Drive > PDF > structure and learns non-linear combination of the attention in GRUs.  \n",
            "Folder name : My Drive > PDF > Tay et al.81 designed a Dyadic Memory Network (DyMemNN) that models dyadic interactions \n",
            "Folder name : My Drive > PDF > between aspect and context, by using either neural tensor compositions or holographic \n",
            "Folder name : My Drive > PDF > compositions for memory selection operation. \n",
            "Folder name : My Drive > PDF > ASPECT EXTRACTION AND CATEGORIZATION \n",
            "Folder name : My Drive > PDF > To perform aspect level sentiment classification, one needs to have aspects (or targets), which can \n",
            "Folder name : My Drive > PDF > be manually given or automatically extracted. In this section, we discuss existing work for automated \n",
            "Folder name : My Drive > PDF > aspect extraction (or aspect term extraction) from a sentence or document using deep learning \n",
            "Folder name : My Drive > PDF > models. Let us use an example to state the problem. For example, in the sentence â€œthe image is very \n",
            "Folder name : My Drive > PDF > clearâ€ the word â€œimageâ€ is an aspect term (or sentiment target). The associated problem of aspect \n",
            "Folder name : My Drive > PDF > categorization is to group the same aspect expressions into a category. For instance, the aspect \n",
            "Folder name : My Drive > PDF > terms â€œimageâ€, â€œphotoâ€ and â€œpictureâ€ can be grouped into one aspect category named Image. In the \n",
            "Folder name : My Drive > PDF > review below, we include the extraction of both aspect and entity that are associated with opinions.  \n",
            "Folder name : My Drive > PDF > One reason why deep learning models can be helpful for this task is that, deep learning is essentially \n",
            "Folder name : My Drive > PDF > good at learning (complicated) feature representations. When an aspect is properly characterized in \n",
            "Folder name : My Drive > PDF > some feature space, for example, in one or some hidden layer(s), the semantics or correlation \n",
            "Folder name : My Drive > PDF > between an aspect and its context can be captured with the interplay between their corresponding \n",
            "Folder name : My Drive > PDF > feature representations. In other words, deep learning provides a possible approach to automated \n",
            "Folder name : My Drive > PDF > feature engineering without human involvement.  \n",
            "Folder name : My Drive > PDF > Katiyar and Cardie82 investigated the use of deep bidirectional LSTMs for joint extraction of opinion \n",
            "Folder name : My Drive > PDF > entities and the IS-FORM and IS-ABOUT relationships that connect the entities. Wang et al.83 further \n",
            "Folder name : My Drive > PDF > proposed a joint model integrating RNN and Conditional Random Fields (CRF) to co-extract aspects \n",
            "Folder name : My Drive > PDF > and opinion terms or expressions. The proposed model can learn high-level discriminative features \n",
            "Folder name : My Drive > PDF > and double-propagate information between aspect and opinion terms simultaneously. Wang et al.84 \n",
            "Folder name : My Drive > PDF > further proposed a Coupled Multi-Layer Attention Model (CMLA) for co-extracting of aspect and \n",
            "Folder name : My Drive > PDF > opinion terms. The model consists of an aspect attention and an opinion attention using GRU units. \n",
            "Folder name : My Drive > PDF > An improved LSTM-based approach was reported by Li and Lam85, specifically for aspect term \n",
            "Folder name : My Drive > PDF > extraction. It consists of three LSTMs, of which two LSTMs are for capturing aspect and sentiment \n",
            "Folder name : My Drive > PDF > interactions. The third LSTM is to use the sentiment polarity information as an additional guidance.  \n",
            "Folder name : My Drive > PDF > He et al.86 proposed an attention-based model for unsupervised aspect extraction. The main \n",
            "Folder name : My Drive > PDF > intuition is to utilize the attention mechanism to focus more on aspect-related words while de-\n",
            "Folder name : My Drive > PDF > emphasizing aspect-irrelevant words during the learning of aspect embeddings, similar to the \n",
            "Folder name : My Drive > PDF > autoencoder framework. \n",
            "Folder name : My Drive > PDF > Zhang et al.87 extended a CRF model using a neural network to jointly extract aspects and \n",
            "Folder name : My Drive > PDF > corresponding sentiments. The proposed CRF variant replaces the original discrete features in CRF \n",
            "Folder name : My Drive > PDF > with continuous word embeddings, and adds a neural layer between the input and output nodes.  \n",
            "Folder name : My Drive > PDF > Zhou et al.88 proposed a semi-supervised word embedding learning method to obtain continuous \n",
            "Folder name : My Drive > PDF > word representations on a large set of reviews with noisy labels. With the word vectors learned, \n",
            "Folder name : My Drive > PDF > deeper and hybrid features are learned by stacking on the word vectors through a neural network. \n",
            "Folder name : My Drive > PDF > Finally, a logistic regression classifier trained with the hybrid features is used to predict the aspect \n",
            "Folder name : My Drive > PDF > category. \n",
            "Folder name : My Drive > PDF > Yin et al.89 first learned word embedding by considering the dependency path connecting words. \n",
            "Folder name : My Drive > PDF > Then they designed some embedding features that consider the linear context and dependency \n",
            "Folder name : My Drive > PDF > context information for CRF-based aspect term extraction. \n",
            "Folder name : My Drive > PDF > Xiong et al.90 proposed an attention-based deep distance metric learning model to group aspect \n",
            "Folder name : My Drive > PDF > phrases. The attention-based model is to learn feature representation of contexts. Both aspect \n",
            "Folder name : My Drive > PDF > phrase embedding and context embedding are used to learn a deep feature subspace metric for K-\n",
            "Folder name : My Drive > PDF > means clustering. \n",
            "Folder name : My Drive > PDF > Poria et al.91 proposed to use CNN for aspect extraction. They developed a seven-layer deep \n",
            "Folder name : My Drive > PDF > convolutional neural network to tag each word in opinionated sentences as either aspect or non-\n",
            "Folder name : My Drive > PDF > aspect word. Some linguistic patterns are also integrated into the model for further improvement. \n",
            "Folder name : My Drive > PDF > Ying et al.92 proposed two RNN-based models for cross-domain aspect extraction. They first used \n",
            "Folder name : My Drive > PDF > rule-based methods to generate an auxiliary label sequence for each sentence. They then trained \n",
            "Folder name : My Drive > PDF > the models using both the true labels and auxiliary labels, which shows promising results.   \n",
            "Folder name : My Drive > PDF > OPINION EXPRESSION EXTRACTION \n",
            "Folder name : My Drive > PDF > In this and the next few sections, we discuss deep learning applications to some other sentiment \n",
            "Folder name : My Drive > PDF > analysis related tasks. This section focuses on the problem of opinion expression extraction (or \n",
            "Folder name : My Drive > PDF > opinion term extraction, or opinion identification), which aims to identify the expressions of \n",
            "Folder name : My Drive > PDF > sentiment in a sentence or a document.  \n",
            "Folder name : My Drive > PDF > Similar to the aspect extraction, opinion expression extraction using deep learning models is \n",
            "Folder name : My Drive > PDF > workable because their characteristics could be identified in some feature space as well. \n",
            "Folder name : My Drive > PDF > Irsoy and Cardie93 explored the application of deep bidirectional RNN for the task, which \n",
            "Folder name : My Drive > PDF > outperforms traditional shallow RNNs with the same number of parameters and also previous CRF \n",
            "Folder name : My Drive > PDF > methods.94  \n",
            "Folder name : My Drive > PDF > Liu et al.95 presented a general class of discriminative models based on the RNN architecture and \n",
            "Folder name : My Drive > PDF > word embedding. The authors used pre-trained word embeddings from three external sources in \n",
            "Folder name : My Drive > PDF > different RNN architectures including Elman-type, Jordan-type, LSTM and their variations.  \n",
            "Folder name : My Drive > PDF > Wang et al.83 proposed a model integrating recursive neural networks and CRF to co-extract aspect \n",
            "Folder name : My Drive > PDF > and opinion terms. The aforementioned CMLA is also proposed for co-extraction of aspect and \n",
            "Folder name : My Drive > PDF > opinion terms.84  \n",
            "Folder name : My Drive > PDF > SENTIMENT COMPOSITION  \n",
            "Folder name : My Drive > PDF > Sentiment composition claims that the sentiment orientation of an opinion expression is determined \n",
            "Folder name : My Drive > PDF > by the meaning of its constituents as well as the grammatical structure. Due to their particular tree-\n",
            "Folder name : My Drive > PDF > structure design, RecNN is naturally suitable for this task.51 Irsoy and Cardie96 reported that the \n",
            "Folder name : My Drive > PDF > RecNN with a deep architecture can more accurately capture different aspects of compositionality in \n",
            "Folder name : My Drive > PDF > language, which benefits sentiment compositionality. Zhu et al.97 proposed a neural network for \n",
            "Folder name : My Drive > PDF > integrating the compositional and non-compositional sentiment in the process of sentiment \n",
            "Folder name : My Drive > PDF > composition. \n",
            "Folder name : My Drive > PDF > OPINION HOLDER EXTRACTION \n",
            "Folder name : My Drive > PDF > Opinion holder (or source) extraction is the task of recognizing who holds the opinion (or \n",
            "Folder name : My Drive > PDF > whom/where the opinion is from).1 For example, in the sentence â€œJohn hates his carâ€, the opinion \n",
            "Folder name : My Drive > PDF > holder is â€œjohnâ€. This problem is commonly formulated as a sequence labelling problem like opinion \n",
            "Folder name : My Drive > PDF > expression extraction or aspect extraction. Notice that opinion holder can be either explicit (from a \n",
            "Folder name : My Drive > PDF > noun phrase in the sentence) or implicit (from the writer) as shown by Yang and Cardie98. Deng and \n",
            "Folder name : My Drive > PDF > Wiebe99 proposed to use word embeddings of opinion expressions as features for recognizing \n",
            "Folder name : My Drive > PDF > sources of participant opinions and non-participant opinions, where a source can be the noun \n",
            "Folder name : My Drive > PDF > phrase or writer.  \n",
            "Folder name : My Drive > PDF > TEMPORAL OPINION MINING \n",
            "Folder name : My Drive > PDF > Time is also an important dimension in problem definition of sentiments analysis (see Liuâ€™s book1). \n",
            "Folder name : My Drive > PDF > As time passes by, people may maintain or change their mind, or even give new viewpoints. \n",
            "Folder name : My Drive > PDF > Therefore, predicting future opinion is important in sentiment analysis. Some research using neural \n",
            "Folder name : My Drive > PDF > networks has been reported recently to tackle this problem. \n",
            "Folder name : My Drive > PDF > Chen et al.100 proposed a Content-based Social Influence Model (CIM) to make opinion behaviour \n",
            "Folder name : My Drive > PDF > predictions of twitter users. That is, it uses the past tweets to predict usersâ€™ future opinions. It is \n",
            "Folder name : My Drive > PDF > based on a neural network framework to encode both the user content and social relation factor \n",
            "Folder name : My Drive > PDF > (oneâ€™s opinion about a target is influenced by oneâ€™s friends).   \n",
            "Folder name : My Drive > PDF > Rashkin et al.101 used LSTMs for targeted sentiment forecast in the social media context. They \n",
            "Folder name : My Drive > PDF > introduced multilingual connotation frames, which aim at forecasting implied sentiments among \n",
            "Folder name : My Drive > PDF > world event participants engaged in a frame. \n",
            "Folder name : My Drive > PDF > SENTIMENT ANALYSIS WITH WORD EMBEDDING \n",
            "Folder name : My Drive > PDF > It is clear that word embeddings played an important role in deep learning based sentiment analysis \n",
            "Folder name : My Drive > PDF > models. It is also shown that even without the use of deep learning models, word embeddings can \n",
            "Folder name : My Drive > PDF > be used as features for non-neural learning models for various tasks. The section thus specifically \n",
            "Folder name : My Drive > PDF > highlights word embeddingsâ€™ contribution to sentiment analysis.  \n",
            "Folder name : My Drive > PDF > We first present the works of sentiment-encoded word embeddings. For sentiment analysis, directly \n",
            "Folder name : My Drive > PDF > applying regular word methods like CBOW or Skip-gram to learn word embeddings from context can \n",
            "Folder name : My Drive > PDF > encounter problems, because words with similar contexts but opposite sentiment polarities (e.g., \n",
            "Folder name : My Drive > PDF > â€œgoodâ€ or â€œbadâ€) may be mapped to nearby vectors in the embedding space. Therefore, sentiment-\n",
            "Folder name : My Drive > PDF > encoded word embedding methods have been proposed. Mass el al.102 learned word embeddings \n",
            "Folder name : My Drive > PDF > that can capture both semantic and sentiment information. Bespalov et al.103 showed that an n-gram \n",
            "Folder name : My Drive > PDF > model combined with latent representation would produce a more suitable embedding for \n",
            "Folder name : My Drive > PDF > sentiment classification. Labutov and Lipson104 re-embed existing word embeddings with logistic \n",
            "Folder name : My Drive > PDF > regression by regarding sentiment supervision of sentences as a regularization term.  \n",
            "Folder name : My Drive > PDF > Le and Mikolov35 proposed the concept of paragraph vector to first learn fixed-length representation \n",
            "Folder name : My Drive > PDF > for variable-length pieces of texts, including sentences, paragraphs and documents. They \n",
            "Folder name : My Drive > PDF > experimented on both sentence and document-level sentiment classification tasks and achieved \n",
            "Folder name : My Drive > PDF > performance gains, which demonstrates the merit of paragraph vectors in capturing semantics to \n",
            "Folder name : My Drive > PDF > help sentiment classification. Tang et al.105,106 presented models to learn Sentiment-specific Word \n",
            "Folder name : My Drive > PDF > Embeddings (SSWE), in which not only the semantic but also sentiment information is embedded in \n",
            "Folder name : My Drive > PDF > the learned word vectors. Wang and Xia107 developed a neural architecture to train a sentiment-\n",
            "Folder name : My Drive > PDF > bearing word embedding by integrating the sentiment supervision at both the document and word \n",
            "Folder name : My Drive > PDF > levels. Yu et al.108 adopted a refinement strategy to obtain joint semantic-sentiment bearing word \n",
            "Folder name : My Drive > PDF > vectors. \n",
            "Folder name : My Drive > PDF > Feature enrichment and multi-sense word embeddings are also investigated for sentiment analysis. \n",
            "Folder name : My Drive > PDF > Vo and Zhang69 studied aspect-based Twitter sentiment classification by making use of rich \n",
            "Folder name : My Drive > PDF > automatic features, which are additional features obtained using unsupervised learning techniques. \n",
            "Folder name : My Drive > PDF > Li and Jurafsky109 experimented with the utilization of multi-sense word embeddings on various NLP \n",
            "Folder name : My Drive > PDF > tasks. Experimental results show that while such embeddings do improve the performance of some \n",
            "Folder name : My Drive > PDF > tasks, they offer little help to sentiment classification tasks. Ren et al.110 proposed methods to learn \n",
            "Folder name : My Drive > PDF > topic-enriched multi-prototype word embeddings for Twitter sentiment classification. \n",
            "Folder name : My Drive > PDF > Multilinguistic word embeddings have also been applied to sentiment analysis. Zhou et al.111 \n",
            "Folder name : My Drive > PDF > reported a Bilingual Sentiment Word Embedding (BSWE) model for cross-language sentiment \n",
            "Folder name : My Drive > PDF > classification. It incorporates the sentiment information into English-Chinese bilingual embeddings \n",
            "Folder name : My Drive > PDF > by employing labeled corpora and their translation, instead of large-scale parallel corpora. Barnes et \n",
            "Folder name : My Drive > PDF > al.112 compared several types of bilingual word embeddings and neural machine translation \n",
            "Folder name : My Drive > PDF > techniques for cross-lingual aspect-based sentiment classification. \n",
            "Folder name : My Drive > PDF > Zhang et al.113 integrated word embeddings with matrix factorization for personalized review-based \n",
            "Folder name : My Drive > PDF > rating prediction. Specifically, the authors refine existing semantics-oriented word vectors (e.g., \n",
            "Folder name : My Drive > PDF > word2vec and GloVe) using sentiment lexicons. Sharma et al.114 proposed a semi-supervised \n",
            "Folder name : My Drive > PDF > technique to use sentiment bearing word embeddings for ranking sentiment intensity of adjectives. \n",
            "Folder name : My Drive > PDF > Word embedding techniques have also been utilized or improved to help address various sentiment \n",
            "Folder name : My Drive > PDF > analysis tasks in many other recent studies.55,62,87,89,95 \n",
            "Folder name : My Drive > PDF > SARCASM ANALYSIS \n",
            "Folder name : My Drive > PDF > Sarcasm is a form verbal irony and a closely related concept to sentiment analysis. Recently, there is \n",
            "Folder name : My Drive > PDF > a growing interest in NLP communities in sarcasm detection. Researchers have attempted to solve it \n",
            "Folder name : My Drive > PDF > using deep learning techniques due of their impressive success in many other NLP problems.  \n",
            "Folder name : My Drive > PDF > Zhang et al.115 constructed a deep neural network model for tweet sarcasm detection. Their network \n",
            "Folder name : My Drive > PDF > first uses a bidirectional GRU model to capture the syntactic and semantic information over tweets \n",
            "Folder name : My Drive > PDF > locally, and then uses a pooling neural network to extract contextual features automatically from \n",
            "Folder name : My Drive > PDF > history tweets for detecting sarcastic tweets.  \n",
            "Folder name : My Drive > PDF > Joshi et al.116 investigated word embeddings-based features for sarcasm detection. They \n",
            "Folder name : My Drive > PDF > experimented four past algorithms for sarcasm detection with augmented word embeddings \n",
            "Folder name : My Drive > PDF > features and showed promising results. \n",
            "Folder name : My Drive > PDF > Poria et al.117 developed a CNN-based model for sarcasm detection (sarcastic or non-sarcastic tweets \n",
            "Folder name : My Drive > PDF > classification), by jointly modelling pre-trained emotion, sentiment and personality features, along \n",
            "Folder name : My Drive > PDF > with the textual information in a tweet. \n",
            "Folder name : My Drive > PDF > Peled and Reichart118 proposed to interpret sarcasm tweets based on a RNN neural machine \n",
            "Folder name : My Drive > PDF > translation model.  \n",
            "Folder name : My Drive > PDF > Ghosh and Veale119 proposed a CNN and bidirectional LSTM hybrid for sarcasm detection in tweets, \n",
            "Folder name : My Drive > PDF > which models both linguistic and psychological contexts.  \n",
            "Folder name : My Drive > PDF > Mishra et al.66 utilized CNN to automatically extract cognitive features from the eye-movement (or \n",
            "Folder name : My Drive > PDF > gaze) data to enrich information for sarcasm detection. Word embeddings are also used for irony \n",
            "Folder name : My Drive > PDF > recognition in English tweets120 and for controversial words identification in debates.121 \n",
            "Folder name : My Drive > PDF > EMOTION ANALYSIS \n",
            "Folder name : My Drive > PDF > Emotions are the subjective feelings and thoughts of human beings. The primary emotions include \n",
            "Folder name : My Drive > PDF > love, joy, surprise, anger, sadness and fear. The concept of emotion is closely related to sentiment. \n",
            "Folder name : My Drive > PDF > For example, the strength of a sentiment can be linked to the intensity of certain emotion like joy \n",
            "Folder name : My Drive > PDF > and anger. Thus, many deep learning models are also applied to emotion analysis following the way \n",
            "Folder name : My Drive > PDF > in sentiment analysis. \n",
            "Folder name : My Drive > PDF > Wang et al. 122 built a bilingual attention network model for code-switched emotion prediction. A \n",
            "Folder name : My Drive > PDF > LSTM model is used to construct a document level representation of each post, and the attention \n",
            "Folder name : My Drive > PDF > mechanism is employed to capture the informative words from both the monolingual and bilingual \n",
            "Folder name : My Drive > PDF > contexts. \n",
            "Folder name : My Drive > PDF > Zhou et al. 123 proposed an emotional chatting machine to model the emotion influence in large-\n",
            "Folder name : My Drive > PDF > scale conversation generation based on GRU. The technique has also been applied in other papers. \n",
            "Folder name : My Drive > PDF > 39,72,115 \n",
            "Folder name : My Drive > PDF > Abdul-Mageed and Ungar124 first built a large dataset for emotion detection automatically by using \n",
            "Folder name : My Drive > PDF > distant supervision and then used a GRU network for fine-grained emotion detection.  \n",
            "Folder name : My Drive > PDF > Felbo et al. 125 used millions of emoji occurrences in social media for pretraining neural models in \n",
            "Folder name : My Drive > PDF > order to learn better representations of emotional contexts. \n",
            "Folder name : My Drive > PDF > A question-answering approach is proposed using a deep memory network for emotion cause \n",
            "Folder name : My Drive > PDF > extraction.126 Emotion cause extraction aims to identify the reasons behind a certain emotion \n",
            "Folder name : My Drive > PDF > expressed in text. \n",
            "Folder name : My Drive > PDF > MULTIMODAL DATA FOR SENTIMENT ANALYSIS \n",
            "Folder name : My Drive > PDF > Multimodal data, such as the data carrying textual, visual, and acoustic information, has been used \n",
            "Folder name : My Drive > PDF > to help sentiment analysis as it provides additional sentiment signals to the traditional text features. \n",
            "Folder name : My Drive > PDF > Since deep learning models can map inputs to some latent space for feature representation, the \n",
            "Folder name : My Drive > PDF > inputs from multimodal data can also be projected simultaneously to learn multimodal data fusion, \n",
            "Folder name : My Drive > PDF > for example, by using feature concatenation, joint latent space, or other more sophisticated fusion \n",
            "Folder name : My Drive > PDF > approaches. There is now a growing trend of using multimodal data with deep learning techniques. \n",
            "Folder name : My Drive > PDF > Poria et al.127 proposed a way of extracting features from short texts based on the activation values \n",
            "Folder name : My Drive > PDF > of an inner layer of CNN. The main novelty of the paper is the use of a deep CNN to extract features \n",
            "Folder name : My Drive > PDF > from text and the use of multiple kernel learning (MKL) to classify heterogeneous multimodal fused \n",
            "Folder name : My Drive > PDF > feature vectors. \n",
            "Folder name : My Drive > PDF > Bertero et al.128 described a CNN model for emotion and sentiment recognition in acoustic data from \n",
            "Folder name : My Drive > PDF > interactive dialog systems.  \n",
            "Folder name : My Drive > PDF > Fung et al.129 demonstrated a virtual interaction dialogue system that have incorporated sentiment, \n",
            "Folder name : My Drive > PDF > emotion and personality recognition capabilities trained by deep learning models.  \n",
            "Folder name : My Drive > PDF > Wang et al.130 reported a CNN structured deep network, named Deep Coupled Adjective and Noun \n",
            "Folder name : My Drive > PDF > (DCAN) neural network, for visual sentiment classification. The key idea of DCAN is to harness the \n",
            "Folder name : My Drive > PDF > adjective and noun text descriptions, treating them as two (weak) supervision signals to learn two \n",
            "Folder name : My Drive > PDF > intermediate sentiment representations. Those learned representations are then concatenated and \n",
            "Folder name : My Drive > PDF > used for sentiment classification. \n",
            "Folder name : My Drive > PDF > Yang et al.131 developed two algorithms based on a conditional probability neural network to analyse \n",
            "Folder name : My Drive > PDF > visual sentiment in images. \n",
            "Folder name : My Drive > PDF > Zhu et al.132 proposed a unified CNN-RNN model for visual emotion recognition. The architecture \n",
            "Folder name : My Drive > PDF > leverages CNN with multiple layers to extract different levels of features (e.g., colour, texture, object, \n",
            "Folder name : My Drive > PDF > etc.) within a multi-task learning framework. And a bidirectional RNN is proposed to integrate the \n",
            "Folder name : My Drive > PDF > learned features from different layers in the CNN model. \n",
            "Folder name : My Drive > PDF > You et al.133 adopted the attention mechanism for visual sentiment analysis, which can jointly \n",
            "Folder name : My Drive > PDF > discover the relevant local image regions and build a sentiment classifier on top of these local \n",
            "Folder name : My Drive > PDF > regions.  \n",
            "Folder name : My Drive > PDF > Poria et al.134 proposed some a deep learning model for multi-modal sentiment analysis and emotion \n",
            "Folder name : My Drive > PDF > recognition on video data. Particularly, a LSTM-based model is proposed for utterance-level \n",
            "Folder name : My Drive > PDF > sentiment analysis, which can capture contextual information from their surroundings in the same \n",
            "Folder name : My Drive > PDF > video.  \n",
            "Folder name : My Drive > PDF > Tripathi et al.135 used deep and CNN-based models for emotion classification on a multimodal \n",
            "Folder name : My Drive > PDF > dataset DEAP, which contains electroencephalogram and peripheral physiological and video signals.  \n",
            "Folder name : My Drive > PDF > Zadeh et al.136 formulated the problem of multimodal sentiment analysis as modelling intra-modality \n",
            "Folder name : My Drive > PDF > and inter-modality dynamics and introduced a new neural model named Tensor Fusion Network to \n",
            "Folder name : My Drive > PDF > tackle it.  \n",
            "Folder name : My Drive > PDF > Long et al.137 proposed an attention neural model trained with cognition grounded eye-tracking data \n",
            "Folder name : My Drive > PDF > for sentence-level sentiment classification. A Cognition Based Attention (CBA) layer is built for \n",
            "Folder name : My Drive > PDF > neural sentiment analysis. \n",
            "Folder name : My Drive > PDF > Wang et al. 138 proposed a Select-Additive Learning (SAL) approach to tackle the confounding factor \n",
            "Folder name : My Drive > PDF > problem in multimodal sentiment analysis, which removes the individual specific latent \n",
            "Folder name : My Drive > PDF > representations learned by neural networks (e.g., CNN). To achieve it, two learning phases are \n",
            "Folder name : My Drive > PDF > involved, namely, a selection phase for confounding factor identification and a removal phase for \n",
            "Folder name : My Drive > PDF > confounding factor removal. \n",
            "Folder name : My Drive > PDF > RESOURCE-POOR LANGUAGE AND MULTILINGUAL SENTIMENT ANALYSIS \n",
            "Folder name : My Drive > PDF > Recently, sentiment analysis in resource-poor languages (compared to English) has also achieved \n",
            "Folder name : My Drive > PDF > significant progress due to the use of deep learning models. Additionally, multilingual features also \n",
            "Folder name : My Drive > PDF > can help sentiment analysis just like multimodal data. In the same way, deep learning has been \n",
            "Folder name : My Drive > PDF > applied to the multilingual sentiment analysis setting. \n",
            "Folder name : My Drive > PDF > Akhtar et al.139 reported a CNN-based hybrid architecture for sentence and aspect level sentiment \n",
            "Folder name : My Drive > PDF > classification in a resource-poor language, Hindi.  \n",
            "Folder name : My Drive > PDF > Dahou et al.140 used word embeddings and a CNN-based model for Arabic sentiment classification at \n",
            "Folder name : My Drive > PDF > the sentence level.  \n",
            "Folder name : My Drive > PDF > Singhal and Bhattacharyya141 designed a solution for multilingual sentiment classification at \n",
            "Folder name : My Drive > PDF > review/sentence level and experimented with multiple languages, including Hindi, Marathi, Russian, \n",
            "Folder name : My Drive > PDF > Dutch, French, Spanish, Italian, German, and Portuguese. The authors applied machine translation \n",
            "Folder name : My Drive > PDF > tools to translate these languages into English and then used English word embeddings, polarities \n",
            "Folder name : My Drive > PDF > from a sentiment lexicon and a CNN model for classification.  \n",
            "Folder name : My Drive > PDF > Joshi et al.142 introduced a sub-word level representation in a LSTM architecture for sentiment \n",
            "Folder name : My Drive > PDF > classification of Hindi-English code-mixed sentences. \n",
            "Folder name : My Drive > PDF > OTHER RELATED TASKS \n",
            "Folder name : My Drive > PDF > There are also applications of deep learning in some other sentiment analysis related tasks.  \n",
            "Folder name : My Drive > PDF > Sentiment Intersubjectivity: Gui et al.143 tackled the intersubjectivity problem in sentiment analysis, \n",
            "Folder name : My Drive > PDF > where the problem is to study the gap between the surface form of a language and the \n",
            "Folder name : My Drive > PDF > corresponding abstract concepts, and incorporate the modelling of intersubjectivity into a proposed \n",
            "Folder name : My Drive > PDF > CNN. \n",
            "Folder name : My Drive > PDF > Lexicon Expansion: Wang et al.144 proposed a PU learning-based neural approach for opinion lexicon \n",
            "Folder name : My Drive > PDF > expansion. \n",
            "Folder name : My Drive > PDF > Financial Volatility Prediction: Rekabsaz et al.145 made volatility predictions using financial disclosure \n",
            "Folder name : My Drive > PDF > sentiment with word embedding-based information retrieval models, where word embeddings are \n",
            "Folder name : My Drive > PDF > used in similar word set expansion. \n",
            "Folder name : My Drive > PDF > Opinion Recommendation: Wang and Zhang146 introduced the task of opinion recommendation, \n",
            "Folder name : My Drive > PDF > which aims to generate a customized review score of a product that the particular user is likely to \n",
            "Folder name : My Drive > PDF > give, as well as a customized review that the user would have written for the target product if the \n",
            "Folder name : My Drive > PDF > user had reviewed the product. A multiple-attention memory network was proposed to tackle the \n",
            "Folder name : My Drive > PDF > problem, which considers usersâ€™ reviews, productâ€™s reviews, and usersâ€™ neighbours (similar users). \n",
            "Folder name : My Drive > PDF > Stance Detection: Augenstein et al.147 proposed a bidirectional LSTMs with a conditional encoding \n",
            "Folder name : My Drive > PDF > mechanism for stance detection in political twitter data. Du et al.148 designed a target-specific neural \n",
            "Folder name : My Drive > PDF > attention model for stance classification. \n",
            "Folder name : My Drive > PDF > CONCLUSION \n",
            "Folder name : My Drive > PDF > Applying deep learning to sentiment analysis has become a popular research topic lately. In this \n",
            "Folder name : My Drive > PDF > paper, we introduced various deep learning architectures and their applications in sentiment \n",
            "Folder name : My Drive > PDF > analysis. Many of these deep learning techniques have shown state-of-the-art results for various \n",
            "Folder name : My Drive > PDF > sentiment analysis tasks. With the advances of deep learning research and applications, we believe \n",
            "Folder name : My Drive > PDF > that there will be more exciting research of deep learning for sentiment analysis in the near future. \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > Acknowledgments \n",
            "Folder name : My Drive > PDF > Bing Liu and Shuai Wangâ€™s work was supported in part by National Science Foundation (NSF) under \n",
            "Folder name : My Drive > PDF > grant no. IIS1407927 and IIS-1650900, and by Huawei Technologies Co. Ltd with a research gift.  \n",
            "Folder name : My Drive > PDF > References \n",
            "Folder name : My Drive > PDF > [1] Liu B. Sentiment analysis: mining opinions, sentiments, and emotions. The Cambridge University Press, \n",
            "Folder name : My Drive > PDF > 2015.  \n",
            "Folder name : My Drive > PDF > [2] Liu B. Sentiment analysis and opinion mining (introduction and survey), Morgan & Claypool, May 2012. \n",
            "Folder name : My Drive > PDF > [3] Pang B and Lee L. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, \n",
            "Folder name : My Drive > PDF > 2008. 2(1â€“2): pp. 1â€“135. \n",
            "Folder name : My Drive > PDF > [4] Goodfellow I, Bengio Y, Courville A. Deep learning. The MIT Press. 2016. \n",
            "Folder name : My Drive > PDF > [5] Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural networks. In Proceedings of the International \n",
            "Folder name : My Drive > PDF > Conference on Artificial Intelligence and Statistics (AISTATS 2011), 2011. \n",
            "Folder name : My Drive > PDF > [6] Rumelhart D.E, Hinton G.E, Williams R.J. Learning representations by back-propagating errors. Cognitive \n",
            "Folder name : My Drive > PDF > modelling, 1988. \n",
            "Folder name : My Drive > PDF > [7] Collobert R, Weston J, Bottou L, Karlen M, Kavukcuoglu K, and Kuksa P. Natural language processing (almost) \n",
            "Folder name : My Drive > PDF > from scratch. Journal of Machine Learning Research, 2011. \n",
            "Folder name : My Drive > PDF > [8] Goldberg Y. A primer on neural network models for natural language processing. Journal of Artificial \n",
            "Folder name : My Drive > PDF > Intelligence Research, 2016. \n",
            "Folder name : My Drive > PDF > [9] Bengio Y, Courville A, Vincent P. Representation learning:  a review and new perspectives. IEEE Transactions \n",
            "Folder name : My Drive > PDF > on Pattern Analysis and Machine Intelligence, 2013.  \n",
            "Folder name : My Drive > PDF > [10] Lee H, Grosse R, Ranganath R, and Ng A.Y. Convolutional deep belief networks for scalable unsupervised \n",
            "Folder name : My Drive > PDF > learning of hierarchical representations. In Proceedings of the International Conference on Machine Learning \n",
            "Folder name : My Drive > PDF > (ICML 2009), 2009. \n",
            "Folder name : My Drive > PDF > [11] Bengio Y, Ducharme R, Vincent P, and Jauvin C. A neural probabilistic language model. Journal of Machine \n",
            "Folder name : My Drive > PDF > Learning Research, 2003. \n",
            "Folder name : My Drive > PDF > [12] Morin F, Bengio Y. Hierarchical probabilistic neural network language model. In Proceedings of the \n",
            "Folder name : My Drive > PDF > International Workshop on Artificial Intelligence and Statistics, 2005.  \n",
            "Folder name : My Drive > PDF > [13] Mikolov T, Chen K, Corrado G, and Dean J. Efficient estimation of word representations in vector space. In \n",
            "Folder name : My Drive > PDF > Proceedings of International Conference on Learning Representations (ICLR 2013), 2013. \n",
            "Folder name : My Drive > PDF > [14] Mikolov T, Sutskever I, Chen K, Corrado G, and Dean J. Distributed representations of words and phrases \n",
            "Folder name : My Drive > PDF > and their compositionality. In Proceedings of the Annual Conference on Advances in Neural Information \n",
            "Folder name : My Drive > PDF > Processing Systems (NIPS 2013), 2013. \n",
            "Folder name : My Drive > PDF > [15] Mnih A, Kavukcuoglu K. Learning word embeddings efficiently with noise-contrastive estimation. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Annual Conference on Advances in Neural Information Processing Systems (NIPS 2013), \n",
            "Folder name : My Drive > PDF > 2013. \n",
            "Folder name : My Drive > PDF > [16] Huang E.H, Socher R, Manning C.D. and Ng A.Y. Improving word representations via global context and \n",
            "Folder name : My Drive > PDF > multiple word prototypes. In Proceedings of the Annual Meeting of the Association for Computational \n",
            "Folder name : My Drive > PDF > Linguistics (ACL 2012), 2012. \n",
            "Folder name : My Drive > PDF > [17] Pennington J, Socher R, Manning C.D. GloVe: global vectors for word representation. In Proceedings of the \n",
            "Folder name : My Drive > PDF > Conference on Empirical Methods on Natural Language Processing (EMNLP 2014), 2014. \n",
            "Folder name : My Drive > PDF > [18] Bengio Y, Lamblin P, Popovici D, and Larochelle H. Greedy layer-wise training of deep networks. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Annual Conference on Advances in Neural Information Processing Systems (NIPS 2006), \n",
            "Folder name : My Drive > PDF > 2006. \n",
            "Folder name : My Drive > PDF > [19] Hinton G.E, Salakhutdinov R.R. Reducing the dimensionality of data with neural networks. Science, July \n",
            "Folder name : My Drive > PDF > 2006. \n",
            "Folder name : My Drive > PDF > [20] Vincent P, Larochelle H, Bengio Y, and Manzagol P-A. Extracting and composing robust features with \n",
            "Folder name : My Drive > PDF > denoising autoencoders. In Proceedings of the International Conference on Machine Learning (ICML 2008), \n",
            "Folder name : My Drive > PDF > 2008.  \n",
            "Folder name : My Drive > PDF > [21] Sermanet P, LeCun Y. Traffic sign recognition with multi-scale convolutional networks. In Proceedings of \n",
            "Folder name : My Drive > PDF > the International Joint Conference on Neural Networks (IJCNN 2011), 2011. \n",
            "Folder name : My Drive > PDF > [22] Elman J.L. Finding structure in time. Cognitive Science, 1990.  \n",
            "Folder name : My Drive > PDF > [23] Bengio Y, Simard P, Frasconi P. Learning long-term dependencies with gradient descent is difficult. IEEE \n",
            "Folder name : My Drive > PDF > Transactions on Neural Networks, 1994.  \n",
            "Folder name : My Drive > PDF > [24] Schuster M, Paliwal K.K. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, \n",
            "Folder name : My Drive > PDF > 1997. \n",
            "Folder name : My Drive > PDF > [25] Hochreiter S, Schmidhuber J. Long short-term memory. Neural Computation, 9(8): 1735-1780, 1997. \n",
            "Folder name : My Drive > PDF > [26] Tai K.S, Socher R, Manning C. D. Improved semantic representations from tree-structured long short-term \n",
            "Folder name : My Drive > PDF > memory networks. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL \n",
            "Folder name : My Drive > PDF > 2015), 2015. \n",
            "Folder name : My Drive > PDF > [27] Cho K, Bahdanau D, Bougares F, Schwenk H and Bengio Y. Learning phrase representations using RNN \n",
            "Folder name : My Drive > PDF > encoder-decoder for statistical machine translation. In Proceedings of the Conference on Empirical Methods in \n",
            "Folder name : My Drive > PDF > Natural Language Processing (EMNLP 2014), 2014. \n",
            "Folder name : My Drive > PDF > [28] Chung J, Gulcehre C, Cho K, Bengio Y. Empirical evaluation of gated recurrent neural networks on \n",
            "Folder name : My Drive > PDF > sequence modelling. arXiv preprint arXiv:1412.3555, 2014.  \n",
            "Folder name : My Drive > PDF > [29] Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate. arXiv \n",
            "Folder name : My Drive > PDF > preprint arXiv:1409.0473, 2014.   \n",
            "Folder name : My Drive > PDF > [30] Weston J, Chopra S, Bordes A. Memory networks. arXiv preprint arXiv:1410.3916. 2014. \n",
            "Folder name : My Drive > PDF > [31] Sukhbaatar S, Weston J, Fergus R. End-to-end memory networks. In Proceedings of the 29th Conference on \n",
            "Folder name : My Drive > PDF > Neural Information Processing Systems (NIPS 2015), 2015. \n",
            "Folder name : My Drive > PDF > [32] Graves A, Wayne G, Danihelka I. Neural Turing Machines. preprint arXiv:1410.5401. 2014.  \n",
            "Folder name : My Drive > PDF > [33] Qian Q, Tian B, Huang M, Liu Y, Zhu X and Zhu X. Learning tag embeddings and tag-specific composition \n",
            "Folder name : My Drive > PDF > functions in the recursive neural network. In Proceedings of the Annual Meeting of the Association for \n",
            "Folder name : My Drive > PDF > Computational Linguistics (ACL 2015), 2015. \n",
            "Folder name : My Drive > PDF > [34] Moraes R, Valiati J.F, Neto W.P. Document-level sentiment classification: an empirical comparison \n",
            "Folder name : My Drive > PDF > between SVM and ANN. Expert Systems with Applications. 2013.  \n",
            "Folder name : My Drive > PDF > [35] Le Q, Mikolov T. Distributed representations of sentences and documents. In Proceedings of the \n",
            "Folder name : My Drive > PDF > International Conference on Machine Learning (ICML 2014), 2014. \n",
            "Folder name : My Drive > PDF > [36] Glorot X, Bordes A, Bengio Y. Domain adaption for large-scale sentiment classification: a deep learning \n",
            "Folder name : My Drive > PDF > approach. In Proceedings of the International Conference on Machine Learning (ICML 2011), 2011. \n",
            "Folder name : My Drive > PDF > [37] Zhai S, Zhongfei (Mark) Zhang. Semisupervised autoencoder for sentiment analysis. In Proceedings of AAAI \n",
            "Folder name : My Drive > PDF > Conference on Artificial Intelligence (AAAI 2016), 2016. \n",
            "Folder name : My Drive > PDF > [38] Johnson R, Zhang T. Effective use of word order for text categorization with convolutional neural networks.  \n",
            "Folder name : My Drive > PDF > In Proceedings of the Conference of the North American Chapter of the Association for Computational \n",
            "Folder name : My Drive > PDF > Linguistics: Human Language Technologies (NAACL-HLT 2015), 2015. \n",
            "Folder name : My Drive > PDF > [39] Tang D, Qin B, Liu T. Document modelling with gated recurrent neural network for sentiment classification. \n",
            "Folder name : My Drive > PDF > In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2015), 2015.   \n",
            "Folder name : My Drive > PDF > [40] Tang D, Qin B, Liu T. Learning semantic representations of users and products for document level \n",
            "Folder name : My Drive > PDF > sentiment classification. In Proceedings of the Annual Meeting of the Association for Computational Linguistics \n",
            "Folder name : My Drive > PDF > (ACL 2015), 2015. \n",
            "Folder name : My Drive > PDF > [41] Chen H, Sun M, Tu C, Lin Y, and Liu Z. Neural sentiment classification with user and product attention. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), 2016. \n",
            "Folder name : My Drive > PDF > [42] Dou ZY. Capturing user and product Information for document level sentiment analysis with deep memory \n",
            "Folder name : My Drive > PDF > network. In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP \n",
            "Folder name : My Drive > PDF > 2017), 2017. \n",
            "Folder name : My Drive > PDF > [43] Xu J, Chen D, Qiu X, and Huang X. Cached long short-term memory neural networks for document-level \n",
            "Folder name : My Drive > PDF > sentiment classification. In Proceedings of the Conference on Empirical Methods in Natural Language \n",
            "Folder name : My Drive > PDF > Processing (EMNLP 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [44] Yang Z, Yang D, Dyer C, He X, Smola AJ, and Hovy EH. Hierarchical attention networks for document \n",
            "Folder name : My Drive > PDF > classification. In Proceedings of the Conference of the North American Chapter of the Association for \n",
            "Folder name : My Drive > PDF > Computational Linguistics: Human Language Technologies (NAACL-HLT 2016), 2016. \n",
            "Folder name : My Drive > PDF > [45] Yin Y, Song Y, Zhang M. Document-level multi-aspect sentiment classification as machine comprehension. \n",
            "Folder name : My Drive > PDF > In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2017), 2017.   \n",
            "Folder name : My Drive > PDF > [46] Zhou X, Wan X, Xiao J. Attention-based LSTM network for cross-lingual sentiment classification. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [47] Li Z, Zhang Y, Wei Y, Wu Y, and Yang Q. End-to-end adversarial memory network for cross-domain \n",
            "Folder name : My Drive > PDF > sentiment classification. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI \n",
            "Folder name : My Drive > PDF > 2017), 2017. \n",
            "Folder name : My Drive > PDF > [48] Wiebe J, Bruce R, and Oâ€™Hara T. Development and use of a gold standard data set for subjectivity \n",
            "Folder name : My Drive > PDF > classifications. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL \n",
            "Folder name : My Drive > PDF > 1999), 1999.  \n",
            "Folder name : My Drive > PDF > [49] Socher R, Pennington J, Huang E.H, Ng A.Y, and Manning C.D. Semi-supervised recursive autoencoders for \n",
            "Folder name : My Drive > PDF > predicting sentiment distributions. In Proceedings of the Conference on Empirical Methods in Natural \n",
            "Folder name : My Drive > PDF > Language Processing (EMNLP 2011), 2011.   \n",
            "Folder name : My Drive > PDF > [50] Socher R, Huval B, Manning C.D, and Ng A.Y. Semantic compositionality through recursive matrix-vector \n",
            "Folder name : My Drive > PDF > spaces. In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP 2012), \n",
            "Folder name : My Drive > PDF > 2012. \n",
            "Folder name : My Drive > PDF > [51] Socher R, Perelygin A, Wu J. Y, Chuang J, Manning C.D, Ng A. Y, and Potts C. Recursive deep models for \n",
            "Folder name : My Drive > PDF > semantic compositionality over a sentiment treebank. In Proceedings of the Conference on Empirical Methods \n",
            "Folder name : My Drive > PDF > on Natural Language Processing (EMNLP 2013), 2013. \n",
            "Folder name : My Drive > PDF > [52] Kalchbrenner N, Grefenstette E, Blunsom P. A convolutional neural network for modelling sentences. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2014), 2014. \n",
            "Folder name : My Drive > PDF > [53] Kim Y. Convolutional neural networks for sentence classification. In Proceedings of the Annual Meeting of \n",
            "Folder name : My Drive > PDF > the Association for Computational Linguistics (ACL 2014), 2014.                                                                                                                       \n",
            "Folder name : My Drive > PDF > [54] dos Santos, C. N., Gatti M. Deep convolutional neural networks for sentiment analysis for short texts. In \n",
            "Folder name : My Drive > PDF > Proceedings of the International Conference on Computational Linguistics (COLING 2014), 2014. \n",
            "Folder name : My Drive > PDF > [55] Wang X, Liu Y, Sun C, Wang B, and Wang X. Predicting polarities of tweets by composing word embeddings \n",
            "Folder name : My Drive > PDF > with long short-term memory. In Proceedings of the Annual Meeting of the Association for Computational \n",
            "Folder name : My Drive > PDF > Linguistics (ACL 2015), 2015. \n",
            "Folder name : My Drive > PDF > [56] Graves A, Schmidhuber J. Framewise phoneme classification with bidirectional LSTM and other neural \n",
            "Folder name : My Drive > PDF > network architectures. Neural Networks, 2005. \n",
            "Folder name : My Drive > PDF > [57] Wang J, Yu L-C, Lai R.K., and Zhang X. Dimensional sentiment analysis using a regional CNN-LSTM model.  \n",
            "Folder name : My Drive > PDF > In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2016), 2016. \n",
            "Folder name : My Drive > PDF > [58] Wang X, Jiang W, Luo Z. Combination of convolutional and recurrent neural network for sentiment \n",
            "Folder name : My Drive > PDF > analysis of short texts. In Proceedings of the International Conference on Computational Linguistics (COLING \n",
            "Folder name : My Drive > PDF > 2016), 2016. \n",
            "Folder name : My Drive > PDF > [59] Guggilla C, Miller T, Gurevych I. CNN-and LSTM-based claim classification in online user comments. In \n",
            "Folder name : My Drive > PDF > Proceedings of the International Conference on Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [60] Huang M, Qian Q, Zhu X. Encoding syntactic knowledge in neural networks for sentiment classification. \n",
            "Folder name : My Drive > PDF > ACM Transactions on Information Systems, 2017  \n",
            "Folder name : My Drive > PDF > [61] Akhtar MS, Kumar A, Ghosal D, Ekbal A, and Bhattacharyya P. A multilayer perceptron based ensemble \n",
            "Folder name : My Drive > PDF > technique for fine-grained financial sentiment analysis. In Proceedings of the Conference on Empirical Methods \n",
            "Folder name : My Drive > PDF > on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [62] Guan Z, Chen L, Zhao W, Zheng Y, Tan S, and Cai D. Weakly-supervised deep learning for customer review \n",
            "Folder name : My Drive > PDF > sentiment classification. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI \n",
            "Folder name : My Drive > PDF > 2016), 2016.  \n",
            "Folder name : My Drive > PDF > [63] Teng Z, Vo D-T, and Zhang Y. Context-sensitive lexicon features for neural sentiment analysis. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [64] Yu J, Jiang J. Learning sentence embeddings with auxiliary tasks for cross-domain sentiment classification. \n",
            "Folder name : My Drive > PDF > In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [65] Zhao Z, Lu H, Cai D, He X, Zhuang Y. Microblog sentiment classification via recurrent random walk network \n",
            "Folder name : My Drive > PDF > learning. In Proceedings of the Internal Joint Conference on Artificial Intelligence (IJCAI 2017), 2017. \n",
            "Folder name : My Drive > PDF > [66] Mishra A, Dey K, Bhattacharyya P. Learning cognitive features from gaze data for sentiment and sarcasm \n",
            "Folder name : My Drive > PDF > classification using convolutional neural network. In Proceedings of the Annual Meeting of the Association for \n",
            "Folder name : My Drive > PDF > Computational Linguistics (ACL 2017), 2017. \n",
            "Folder name : My Drive > PDF > [67] Qian Q, Huang M, Lei J, and Zhu X. Linguistically regularized LSTM for sentiment classification. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2017), 2017. \n",
            "Folder name : My Drive > PDF > [68] Dong L, Wei F, Tan C, Tang D, Zhou M, and Xu K. Adaptive recursive neural network for target-dependent \n",
            "Folder name : My Drive > PDF > Twitter sentiment classification. In Proceedings of the Annual Meeting of the Association for Computational \n",
            "Folder name : My Drive > PDF > Linguistics (ACL 2014), 2014.  \n",
            "Folder name : My Drive > PDF > [69] Vo D-T, Zhang Y. Target-dependent twitter sentiment classification with rich automatic features. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Internal Joint Conference on Artificial Intelligence (IJCAI 2015), 2015.  \n",
            "Folder name : My Drive > PDF > [70] Tang D, Qin B, Feng X, and Liu T. Effective LSTMs for target-dependent sentiment classification. In \n",
            "Folder name : My Drive > PDF > Proceedings of the International Conference on Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [71] Ruder S, Ghaffari P, Breslin J.G. A hierarchical model of reviews for aspect-based sentiment analysis. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP 2016), 2016. \n",
            "Folder name : My Drive > PDF > [72] Zhang M, Zhang Y, Vo D-T. Gated neural networks for targeted sentiment analysis. In Proceedings of AAAI \n",
            "Folder name : My Drive > PDF > Conference on Artificial Intelligence (AAAI 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [73] Wang Y, Huang M, Zhu X, and Zhao L. Attention-based LSTM for aspect-level sentiment classification. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [74] Yang M, Tu W, Wang J, Xu F, and Chen X. Attention-based LSTM for target-dependent sentiment \n",
            "Folder name : My Drive > PDF > classification.  In Proceedings of AAAI Conference on Artificial Intelligence (AAAI 2017), 2017. \n",
            "Folder name : My Drive > PDF > [75] Liu J, Zhang Y. Attention modeling for targeted sentiment. In Proceedings of the Conference of the \n",
            "Folder name : My Drive > PDF > European Chapter of the Association for Computational Linguistics (EACL 2017), 2017. \n",
            "Folder name : My Drive > PDF > [76] Tang D, Qin B, and Liu T. Aspect-level sentiment classification with deep memory network. arXiv preprint \n",
            "Folder name : My Drive > PDF > arXiv:1605.08900, 2016. \n",
            "Folder name : My Drive > PDF > [77] Lei T, Barzilay R, Jaakkola T. Rationalizing neural predictions. In Proceedings of the Conference on Empirical \n",
            "Folder name : My Drive > PDF > Methods on Natural Language Processing (EMNLP 2016), 2016. \n",
            "Folder name : My Drive > PDF > [78] Li C, Guo X, Mei Q. Deep memory networks for attitude Identification. In Proceedings of the ACM \n",
            "Folder name : My Drive > PDF > International Conference on Web Search and Data Mining (WSDM 2017), 2017. \n",
            "Folder name : My Drive > PDF > [79] Ma D, Li S, Zhang X, Wang H. Interactive attention networks for aspect-Level sentiment classification. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Internal Joint Conference on Artificial Intelligence (IJCAI 2017), 2017.  \n",
            "Folder name : My Drive > PDF > [80] Chen P, Sun Z, Bing L, and Yang W. Recurrent attention network on memory for aspect sentiment analysis. \n",
            "Folder name : My Drive > PDF > In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [81] Tay Y, Tuan LA, Hui SC. Dyadic memory networks for aspect-based sentiment analysis. In Proceedings of \n",
            "Folder name : My Drive > PDF > the International Conference on Information and Knowledge Management (CIKM 2017), 2017. \n",
            "Folder name : My Drive > PDF > [82] Katiyar A, Cardie C. Investigating LSTMs for joint extraction of opinion entities and relations. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2016), 2016. \n",
            "Folder name : My Drive > PDF > [83] Wang W, Pan SJ, Dahlmeier D, and Xiao X. Recursive neural conditional random fields for aspect-based \n",
            "Folder name : My Drive > PDF > sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing \n",
            "Folder name : My Drive > PDF > (EMNLP 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [84] Wang W, Pan SJ, Dahlmeier D, and Xiao X. Coupled multi-Layer attentions for co-extraction of aspect and \n",
            "Folder name : My Drive > PDF > opinion terms. In Proceedings of AAAI Conference on Artificial Intelligence (AAAI 2017), 2017. \n",
            "Folder name : My Drive > PDF > [85] Li X, Lam W. Deep multi-task learning for aspect term extraction with memory Interaction. In Proceedings \n",
            "Folder name : My Drive > PDF > of the Conference on Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [86] He R, Lee WS, Ng HT, and Dahlmeier D. An unsupervised neural attention model for aspect extraction. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2017), 2017. \n",
            "Folder name : My Drive > PDF > [87] Zhang M, Zhang Y, Vo D-T. Neural networks for open domain targeted sentiment. In Proceedings of the \n",
            "Folder name : My Drive > PDF > Conference on Empirical Methods in Natural Language Processing (EMNLP 2015), 2015.   \n",
            "Folder name : My Drive > PDF > [88] Zhou X, Wan X, Xiao J. Representation learning for aspect category detection in online reviews. In \n",
            "Folder name : My Drive > PDF > Proceeding of AAAI Conference on Artificial Intelligence (AAAI 2015), 2015. \n",
            "Folder name : My Drive > PDF > [89] Yin Y, Wei F, Dong L, Xu K, Zhang M, and Zhou M. Unsupervised word and dependency path embeddings \n",
            "Folder name : My Drive > PDF > for aspect term extraction. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI \n",
            "Folder name : My Drive > PDF > 2016), 2016. \n",
            "Folder name : My Drive > PDF > [90] Xiong S, Zhang Y, Ji D, and Lou Y. Distance metric learning for aspect phrase grouping. In Proceedings of \n",
            "Folder name : My Drive > PDF > the International Conference on Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [91] Poria S, Cambria E, Gelbukh A. Aspect extraction for opinion mining with a deep convolutional neural \n",
            "Folder name : My Drive > PDF > network. Journal of Knowledge-based Systems. 2016.  \n",
            "Folder name : My Drive > PDF > [92] Ying D, Yu J, Jiang J. Recurrent neural networks with auxiliary labels for cross-domain opinion target \n",
            "Folder name : My Drive > PDF > extraction. In Proceedings of AAAI Conference on Artificial Intelligence (AAAI 2017), 2017 \n",
            "Folder name : My Drive > PDF > [93] Irsoy O, Cardie C. Opinion mining with deep recurrent neural networks. In Proceedings of the Conference \n",
            "Folder name : My Drive > PDF > on Empirical Methods on Natural Language Processing (EMNLP 2014), 2014. \n",
            "Folder name : My Drive > PDF > [94] Yang B, Cardie C. Extracting opinion expressions with semi-markov conditional random fields. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2012), 2012.   \n",
            "Folder name : My Drive > PDF > [95] Liu P, Joty S, Meng H. Fine-grained opinion mining with recurrent neural networks and word embeddings. \n",
            "Folder name : My Drive > PDF > In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2015), 2015. \n",
            "Folder name : My Drive > PDF > [96] Irsoy O, Cardie C. Deep recursive neural networks for compositionality in language. In Proceedings of the \n",
            "Folder name : My Drive > PDF > Annual Conference on Advances in Neural Information Processing Systems (NIPS 2014), 2014. \n",
            "Folder name : My Drive > PDF > [97] Zhu X, Guo H, Sobhani P. Neural networks for integrating compositional and non-compositional sentiment \n",
            "Folder name : My Drive > PDF > in sentiment composition. In Proceedings of the Conference of the North American Chapter of the Association \n",
            "Folder name : My Drive > PDF > for Computational Linguistics: Human Language Technologies (NAACL-HLT 2015), 2015. \n",
            "Folder name : My Drive > PDF > [98] Yang B, Cardie C. Joint Inference for fine-grained opinion extraction. In Proceedings of the Annual Meeting \n",
            "Folder name : My Drive > PDF > of the Association for Computational Linguistics (ACL 2013), 2013. \n",
            "Folder name : My Drive > PDF > [99] Deng L, Wiebe J. Recognizing opinion sources based on a new categorization of opinion types. In \n",
            "Folder name : My Drive > PDF > Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI 2016), 2016. \n",
            "Folder name : My Drive > PDF > [100] Chen C, Wang Z, Lei Y, and Li W. Content-based influence modelling for opinion behaviour Prediction. In \n",
            "Folder name : My Drive > PDF > Proceedings of the International Conference on Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [101] Rashkin H, Bell E, Choi Y, and Volkova S. Multilingual connotation frames: a case study on social media \n",
            "Folder name : My Drive > PDF > for targeted sentiment analysis and forecast. In Proceedings of the Annual Meeting of the Association for \n",
            "Folder name : My Drive > PDF > Computational Linguistics (ACL 2017), 2017. \n",
            "Folder name : My Drive > PDF > [102] Mass A. L, Daly R. E, Pham P. T, Huang D, Ng A. Y. and Potts C. Learning word vectors for sentiment \n",
            "Folder name : My Drive > PDF > analysis. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2011), \n",
            "Folder name : My Drive > PDF > 2011.  \n",
            "Folder name : My Drive > PDF > [103] Bespalov D, Bai B, Qi Y, and Shokoufandeh A. Sentiment classification based on supervised latent n-gram \n",
            "Folder name : My Drive > PDF > analysis. In Proceedings of the International Conference on Information and Knowledge Management (CIKM \n",
            "Folder name : My Drive > PDF > 2011), 2011. \n",
            "Folder name : My Drive > PDF > [104] Labutov I, Lipson H. Re-embedding words. In Proceedings of the Annual Meeting of the Association for \n",
            "Folder name : My Drive > PDF > Computational Linguistics (ACL 2013), 2013. \n",
            "Folder name : My Drive > PDF > [105] Tang D, Wei F, Yang N, Zhou M, Liu T, and Qin B. Learning sentiment-specific word embedding for twitter \n",
            "Folder name : My Drive > PDF > sentiment classification. In Proceedings of the Annual Meeting of the Association for Computational Linguistics \n",
            "Folder name : My Drive > PDF > (ACL 2014), 2014. \n",
            "Folder name : My Drive > PDF > [106] Tang D, Wei F, Qin B, Yang N, Liu T, and Zhoug M. Sentiment embeddings with applications to sentiment \n",
            "Folder name : My Drive > PDF > analysis. IEEE Transactions on Knowledge and Data Engineering, 2016. \n",
            "Folder name : My Drive > PDF > [107] Wang L, Xia R. Sentiment Lexicon construction with representation Learning based on hierarchical \n",
            "Folder name : My Drive > PDF > sentiment Supervision. In Proceedings of the Conference on Empirical Methods on Natural Language \n",
            "Folder name : My Drive > PDF > Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [108] Yu LC, Wang J, Lai KR, and Zhang X. Refining word embeddings for sentiment analysis. In Proceedings of \n",
            "Folder name : My Drive > PDF > the Conference on Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [109] Li J, Jurafsky D. Do multi-sense embeddings improve natural language understanding? In Proceedings of \n",
            "Folder name : My Drive > PDF > the Conference on Empirical Methods in Natural Language Processing (EMNLP 2015), 2015. \n",
            "Folder name : My Drive > PDF > [110] Ren Y, Zhang Y, Zhang, M and Ji D. Improving Twitter sentiment classification using topic-enriched multi-\n",
            "Folder name : My Drive > PDF > prototype word embeddings. In Proceeding of AAAI Conference on Artificial Intelligence (AAAI 2016), 2016. \n",
            "Folder name : My Drive > PDF > [111] Zhou H, Chen L, Shi F, Huang D. Learning bilingual sentiment word embeddings for cross-language \n",
            "Folder name : My Drive > PDF > sentiment classification. In Proceedings of the Annual Meeting of the Association for Computational Linguistics \n",
            "Folder name : My Drive > PDF > (ACL 2015), 2015. \n",
            "Folder name : My Drive > PDF > [112] Barnes J, Lambert P, Badia T. Exploring distributional representations and machine translation for aspect-\n",
            "Folder name : My Drive > PDF > based cross-lingual sentiment classification. In Proceedings of the 27th International Conference on \n",
            "Folder name : My Drive > PDF > Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [113] Zhang W, Yuan Q, Han J, and Wang J. Collaborative multi-Level embedding learning from reviews for \n",
            "Folder name : My Drive > PDF > rating prediction. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI 2016), \n",
            "Folder name : My Drive > PDF > 2016. \n",
            "Folder name : My Drive > PDF > [114] Sharma R, Somani A, Kumar L, and Bhattacharyya P. Sentiment intensity ranking among adjectives using \n",
            "Folder name : My Drive > PDF > sentiment bearing word embeddings. In Proceedings of the Conference on Empirical Methods on Natural \n",
            "Folder name : My Drive > PDF > Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [115] Zhang M, Zhang Y, Fu G. Tweet sarcasm detection using deep neural network. In Proceedings of the \n",
            "Folder name : My Drive > PDF > International Conference on Computational Linguistics (COLING 2016), 2016.  \n",
            "Folder name : My Drive > PDF > [116] Joshi A, Tripathi V, Patel K, Bhattacharyya P, and Carman M. Are word embedding-based features useful \n",
            "Folder name : My Drive > PDF > for sarcasm detection? In Proceedings of the Conference on Empirical Methods on Natural Language \n",
            "Folder name : My Drive > PDF > Processing (EMNLP 2016), 2016. \n",
            "Folder name : My Drive > PDF > [117] Poria S, Cambria E, Hazarika D, and Vij P. A deeper look into sarcastic tweets using deep convolutional \n",
            "Folder name : My Drive > PDF > neural networks. In Proceedings of the International Conference on Computational Linguistics (COLING 2016), \n",
            "Folder name : My Drive > PDF > 2016. \n",
            "Folder name : My Drive > PDF > [118] Peled L, Reichart R. Sarcasm SIGN: Interpreting sarcasm with sentiment based monolingual machine \n",
            "Folder name : My Drive > PDF > translation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2017), \n",
            "Folder name : My Drive > PDF > 2017. \n",
            "Folder name : My Drive > PDF > [119] Ghosh A, Veale T. Magnets for sarcasm: making sarcasm detection timely, contextual and very personal. \n",
            "Folder name : My Drive > PDF > In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [120] Van Hee C, Lefever E, Hoste V. Monday mornings are my fave:)# not exploring the automatic recognition \n",
            "Folder name : My Drive > PDF > of irony in english tweets. In Proceedings of the International Conference on Computational Linguistics (COLING \n",
            "Folder name : My Drive > PDF > 2016), 2016. \n",
            "Folder name : My Drive > PDF > [121] Chen WF, Lin FY, Ku LW. WordForce: visualizing controversial words in debates. In Proceedings of the \n",
            "Folder name : My Drive > PDF > Conference on Empirical Methods in Natural Language Processing (EMNLP 2016), 2016. \n",
            "Folder name : My Drive > PDF > [122] Wang Z, Zhang Y, Lee S, Li S, and Zhou G. A bilingual attention network for code-switched emotion \n",
            "Folder name : My Drive > PDF > prediction. In Proceedings of the International Conference on Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [123] Zhou H, Huang M, Zhang T, Zhu X and Liu B. Emotional chatting machine: emotional conversation \n",
            "Folder name : My Drive > PDF > generation with internal and external memory.  arXiv preprint. arXiv:1704.01074, 2017. \n",
            "Folder name : My Drive > PDF > [124] Abdul-Mageed M, Ungar L. EmoNet: fine-grained emotion detection with gated recurrent neural \n",
            "Folder name : My Drive > PDF > networks. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2017), \n",
            "Folder name : My Drive > PDF > 2017. \n",
            "Folder name : My Drive > PDF > [125] Felbo B, Mislove A, SÃ¸gaard A, Rahwan I, and Lehmann S. Using millions of emoji occurrences to learn \n",
            "Folder name : My Drive > PDF > any-domain representations for detecting sentiment, emotion and sarcasm. In Proceedings of the Conference \n",
            "Folder name : My Drive > PDF > on Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [126] Gui L, Hu J, He Y, Xu R, Lu Q, and Du J. A question answering approach to emotion cause extraction. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [127] Poria S, Cambria E, Gelbukh A. Deep convolutional neural text features and multiple kernel learning for \n",
            "Folder name : My Drive > PDF > utterance-level multimodal sentiment analysis. In Proceedings of the Conference on Empirical Methods on \n",
            "Folder name : My Drive > PDF > Natural Language Processing (EMNLP 2015), 2015. \n",
            "Folder name : My Drive > PDF > [128] Bertero D, Siddique FB, Wu CS, Wan Y, Chan R.H, and Fung P. Real-time speech emotion and sentiment \n",
            "Folder name : My Drive > PDF > recognition for interactive dialogue systems. In Proceedings of the Conference on Empirical Methods in Natural \n",
            "Folder name : My Drive > PDF > Language Processing (EMNLP 2016), 2016. \n",
            "Folder name : My Drive > PDF > [129] Fung P, Dey A, Siddique FB, Lin R, Yang Y, Bertero D, Wan Y, Chan RH, and Wu CS. Zara: a virtual \n",
            "Folder name : My Drive > PDF > interactive dialogue system incorporating emotion, sentiment and personality recognition. In Proceedings of \n",
            "Folder name : My Drive > PDF > the International Conference on Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [130] Wang J, Fu J, Xu Y, and Mei T. Beyond object recognition: visual sentiment analysis with deep coupled \n",
            "Folder name : My Drive > PDF > adjective and noun neural networks. In Proceedings of the Internal Joint Conference on Artificial Intelligence \n",
            "Folder name : My Drive > PDF > (IJCAI 2016), 2016. \n",
            "Folder name : My Drive > PDF > [131] Yang J, Sun M, Sun X. Learning visual sentiment distributions via augmented conditional probability \n",
            "Folder name : My Drive > PDF > neural network. In Proceedings of AAAI Conference on Artificial Intelligence (AAAI 2017), 2017. \n",
            "Folder name : My Drive > PDF > [132] Zhu X, Li L, Zhang W, Rao T, Xu M, Huang Q, and Xu D. Dependency exploitation: a unified CNN-RNN \n",
            "Folder name : My Drive > PDF > approach for visual emotion recognition. In Proceedings of the Internal Joint Conference on Artificial \n",
            "Folder name : My Drive > PDF > Intelligence (IJCAI 2017), 2017. \n",
            "Folder name : My Drive > PDF > [133] You Q, Jin H, Luo J. Visual sentiment analysis by attending on local image regions. In Proceedings of AAAI \n",
            "Folder name : My Drive > PDF > Conference on Artificial Intelligence (AAAI 2017), 2017. \n",
            "Folder name : My Drive > PDF > [134] Poria S, Cambria E, Hazarika D, Majumder N, Zadeh A, and Morency LP. Context-dependent sentiment \n",
            "Folder name : My Drive > PDF > analysis in user-generated videos. In Proceedings of the Annual Meeting of the Association for Computational \n",
            "Folder name : My Drive > PDF > Linguistics (ACL 2017), 2017. \n",
            "Folder name : My Drive > PDF > [135] Tripathi S, Acharya S, Sharma RD, Mittal S, and Bhattacharya S. Using deep and convolutional neural \n",
            "Folder name : My Drive > PDF > networks for accurate emotion classification on DEAP dataset. In Proceedings of AAAI Conference on Artificial \n",
            "Folder name : My Drive > PDF > Intelligence (AAAI 2017), 2017. \n",
            "Folder name : My Drive > PDF > [136] Zadeh A, Chen M, Poria S, Cambria E, and Morency LP. Tensor fusion network for multimodal sentiment \n",
            "Folder name : My Drive > PDF > analysis. In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP \n",
            "Folder name : My Drive > PDF > 2017), 2017. \n",
            "Folder name : My Drive > PDF > [137] Long Y, Qin L, Xiang R, Li M, and Huang CR. A cognition based attention model for sentiment analysis. In \n",
            "Folder name : My Drive > PDF > Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [138] Wang H, Meghawat A, Morency LP, and Xing E.X.  Select-additive learning: improving generalization in \n",
            "Folder name : My Drive > PDF > multimodal sentiment analysis. In Proceedings of the International Conference on Multimedia and Expo (ICME \n",
            "Folder name : My Drive > PDF > 2017), 2017. \n",
            "Folder name : My Drive > PDF > [139] Akhtar MS, Kumar A, Ekbal A, and Bhattacharyya P. A hybrid deep learning architecture for sentiment \n",
            "Folder name : My Drive > PDF > analysis. In Proceedings of the International Conference on Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [140] Dahou A, Xiong S, Zhou J, Haddoud MH, and Duan P. Word embeddings and convolutional neural \n",
            "Folder name : My Drive > PDF > network for Arabic sentiment classification. In Proceedings of the International Conference on Computational \n",
            "Folder name : My Drive > PDF > Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [141] Singhal P, Bhattacharyya P. Borrow a little from your rich cousin: using embeddings and polarities of \n",
            "Folder name : My Drive > PDF > english words for multilingual sentiment classification. In Proceedings of the International Conference on \n",
            "Folder name : My Drive > PDF > Computational Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [142] Joshi A, Prabhu A, Shrivastava M, and Varma V. Towards sub-word level compositions for sentiment \n",
            "Folder name : My Drive > PDF > analysis of Hindi-English code mixed text. In Proceedings of the International Conference on Computational \n",
            "Folder name : My Drive > PDF > Linguistics (COLING 2016), 2016. \n",
            "Folder name : My Drive > PDF > [143] Gui L, Xu R, He Y, Lu Q, and Wei Z. Intersubjectivity and sentiment: from language to knowledge. In \n",
            "Folder name : My Drive > PDF > Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI 2016), 2016. \n",
            "Folder name : My Drive > PDF > [144] Wang Y, Zhang Y, Liu B. Sentiment lexicon expansion based on neural PU Learning, double dictionary \n",
            "Folder name : My Drive > PDF > lookup, and polarity association. In Proceedings of the Conference on Empirical Methods on Natural Language \n",
            "Folder name : My Drive > PDF > Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [145] Rekabsaz N, Lupu M, Baklanov A, Hanbury A, DÃ¼r A, and Anderson L. Volatility prediction using financial \n",
            "Folder name : My Drive > PDF > disclosures sentiments with word embedding-based IR models. In Proceedings of the Annual Meeting of the \n",
            "Folder name : My Drive > PDF > Association for Computational Linguistics (ACL 2017), 2017. \n",
            "Folder name : My Drive > PDF > [146] Wang Z, Zhang Y. Opinion recommendation using a neural model. In Proceedings of the Conference on \n",
            "Folder name : My Drive > PDF > Empirical Methods on Natural Language Processing (EMNLP 2017), 2017. \n",
            "Folder name : My Drive > PDF > [147] Augenstein I, RocktÃ¤schel T, Vlachos A, Bontcheva K. Stance detection with bidirectional conditional \n",
            "Folder name : My Drive > PDF > encoding. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP \n",
            "Folder name : My Drive > PDF > 2016), 2016.   \n",
            "Folder name : My Drive > PDF > [148] Du J, Xu R, He Y, Gui L. Stance classification with target-specific neural attention networks. In Proceedings \n",
            "Folder name : My Drive > PDF > of the Internal Joint Conference on Artificial Intelligence (IJCAI 2017), 2017. \n",
            "Folder name : My Drive > PDF >  \n",
            "Folder name : My Drive > PDF > \n",
            "========================================\n",
            "Folder Name: DOCS https://drive.google.com/drive/folders/1-1mp1Zkj5zBPtEGoMwIazRFaUTebjwjA\n",
            "File Name: Experiment No.3.docx https://drive.google.com/file/d/1FyLyv6LOpCwtRvxpMXlocgvhcMg73oU1\n",
            "DOCX Text Content:\n",
            "LAB Manual\n",
            "PART A\n",
            "(PART A : TO BE REFFERED BY STUDENTS)\n",
            "Experiment No.03\n",
            "A.1 Aim:   Apply pre-processing on given dataset using scikit-learn package to transform raw features into representations suitable for machine learning model.\n",
            "A.2 Prerequisite:\n",
            "Python Programming.\n",
            "Students should go through the prerequisite documents if any, provided by faculty before attending lab.\n",
            "\n",
            "A.3 Outcome: \n",
            "          After successful completion of this experiment students will be able to:\n",
            "Standardize the data.\n",
            "Encode categorical features.\n",
            "Apply nonlinear transformations on data\n",
            "Reduce, expand or generate feature representations.\n",
            "A.4 Theory\n",
            "Preprocessing refers to the transformations applied to our data before feeding it to the algorithm. Data Preprocessing is a technique that is used to convert the raw data into a clean data set. In other words, whenever the data is gathered from different sources it is collected in raw format which is not feasible for the analysis. For achieving better results from the applied model in Machine Learning projects the format of the data has to be in a proper manner.\n",
            "Scikit-learn provides a library of transformers, which may clean, reduce, expand or generate feature representations.\n",
            "Standardization of dataset\n",
            "Data standardization is about making sure that data is internally consistent; that is, each data type has the same content and format. Standardized values are useful for tracking data that isnâ€™t easy to compare otherwise. StandardizationÂ of datasets is aÂ common requirement for many machine learning estimatorsÂ implemented in scikit-learn.  Feature Scaling or Standardization is a step of Data Pre Processing which is applied to independent variables or features of data. It basically helps to normalise the data within a particular range. Sometimes, it also helps in speeding up the calculations in an algorithm. There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.\n",
            "Standardization\n",
            "The result of standardization (or Z-score normalization) is that the features will be rescaled so that theyâ€™ll have the properties of a standard normal distribution with Î¼=0 and Ïƒ=1 where Î¼ is the mean (average) and Ïƒ is the standard deviation from the mean; standard scores (also called z scores) of the samples are calculated as follows: z= (xâˆ’Î¼Ïƒ) Standardizing the features so that they are centered around 0 with a standard deviation of 1 is not only important if we are comparing measurements that have different units, but it is also a general requirement for many machine learning algorithms.\n",
            "Sample code:\n",
            "Example 1\n",
            "from sklearn import preprocessing\n",
            "import numpy as np\n",
            "X_train = np.array([[ 1., -1.,  2.],[ 2.,  0.,  0.], [ 0.,  1., -1.]])\n",
            "scaler = preprocessing.StandardScaler().fit(X_train)\n",
            "scaler\n",
            "StandardScaler()\n",
            "Print(scaler.mean_)\n",
            ">>>array([1. ..., 0. ..., 0.33...])\n",
            "\n",
            "Print(scaler.scale_)\n",
            ">>>array([0.81..., 0.81..., 1.24...])\n",
            "\n",
            "X_scaled = scaler.transform(X_train)\n",
            "X_scaled\n",
            ">>>array([[ 0.  ..., -1.22...,  1.33...],\n",
            "       [ 1.22...,  0.  ..., -0.26...],\n",
            "       [-1.22...,  1.22..., -1.06...]])\n",
            "In below code snippet, â€˜dfâ€™ stands for dataframe and colm1, colm2 etc. stands for specific columns in the dataframe. \n",
            "Example 2\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "scaler=StandardScaler()\n",
            "new_df=pd.DataFrame(scaler.fit_transform(df[['colm1','colm2']]),columns=[['colm1','colm2']])\n",
            "print(new_df.head())\n",
            "\n",
            "We can use fit_transform method to apply standardization or fit() and transform() methods separately.\n",
            "1.Fit():Â Method calculates the parameters Î¼ and Ïƒ and saves them as internal objects.\n",
            "2.Transform():Â Method using these calculated parameters apply the transformation to a particular dataset.\n",
            "3.Fit_transform():Â joins the fit() and transform() method for transformation of dataset.\n",
            "Min-max scaling\n",
            "In this approach, the data is scaled to a fixed range - usually 0 to 1. The cost of having this bounded range - in contrast to standardization - is that we will end up with smaller standard deviations, which can suppress the effect of outliers.\n",
            "A Min-Max scaling is typically done via the following equation: Xnorm=(Xâˆ’Xmin)/ (Xmaxâˆ’Xmin).\n",
            "Example:\n",
            "from sklearn.preprocessing import MinMaxScaler\n",
            "min_max=MinMaxScaler()\n",
            "new_df=pd.DataFrame(min_max.fit_transform(df[['colm1','colm2']]),columns=[['colm1','colm2']])\n",
            "print(new_df.head())\n",
            "\n",
            "Encoding categorical data\n",
            "Often features are not given as continuous values but categorical. For example a person could have  featuresÂ [\"male\",Â \"female\"],Â [\"fromÂ Europe\",Â \"fromÂ US\",Â \"fromÂ Asia\"],Â [\"usesÂ Firefox\",Â \"usesÂ Chrome\",Â \"usesÂ Safari\",Â \"usesÂ InternetÂ Explorer\"]. Such features can be efficiently coded as integers for instanceÂ [\"male\",Â \"fromÂ US\",Â \"usesÂ InternetÂ Explorer\"]Â could be expressed asÂ [0,Â 1,Â 3]Â whileÂ [\"female\",Â \"fromÂ Asia\",Â \"usesÂ Chrome\"]Â would beÂ [1,Â 2,Â 1]. Typically, any data attribute which is categorical in nature represents discrete values which belong to a specific finite set of categories or classes.Â To convert categorical features to such integer codes, we can use theÂ OrdinalEncoder. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1)\n",
            "enc = preprocessing.OrdinalEncoder()\n",
            ">>> X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
            ">>> enc.fit(X)\n",
            "OrdinalEncoder()\n",
            ">>> enc.transform([['female', 'from US', 'uses Safari']])\n",
            "array([[0., 1., 1.]])\n",
            "\n",
            "Another possibility to convert categorical features to features that can be used with scikit-learn estimators is to use a one-of-K, also known as one-hot or dummy encoding. This type of encoding can be obtained with theÂ OneHotEncoder, which transforms each categorical feature withÂ n_categoriesÂ possible values intoÂ n_categoriesÂ binary features, with one of them 1, and all others 0. While one-hot encoding solves the problem of unequal weights given to categories within a feature, it is not very useful when there are many categories, as that will result in formation of as many new columns, which can result in the curse of dimensionality.\n",
            "enc = preprocessing.OneHotEncoder()\n",
            "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
            "enc.fit(X)\n",
            "OneHotEncoder()\n",
            "enc.transform([['female', 'from US', 'uses Safari'],['male', 'from Europe', 'uses Safari']]).toarray()\n",
            ">>> array([[1., 0., 0., 1., 0., 1.],\n",
            "       [0., 1., 1., 0., 0., 1.]])\n",
            "\n",
            "If there is a possibility that the training data might have missing categorical features, it can often be better to specifyÂ handle_unknown='ignore'Â instead of setting theÂ categoriesÂ manually as above. WhenÂ handle_unknown='ignore'Â is specified and unknown categories are encountered during transform, no error will be raised but the resulting one-hot encoded columns for this feature will be all zeros (handle_unknown='ignore'Â is only supported for one-hot encoding)\n",
            "OneHotEncoderÂ supports categorical features with missing values by considering the missing values as an additional category\n",
            "Variable transformation and variable creation\n",
            "Two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations (order of the number is preserved) of the features and thus preserve the rank of the values along each feature.\n",
            "Power transforms are a family of parametric transformations that aim to map data from any distribution to as close to a Gaussian distribution in order to stabilize variance and minimize skewness. In many modeling scenarios, normality of the features in a dataset is desirable. Power Transforms currently provides two such power transformations, the Yeo-Johnson transform and the Box-Cox transform. Box-Cox can only be applied to strictly positive data.\n",
            "pt = preprocessing.PowerTransformer(method='box-cox', standardize=False)\n",
            "X_lognormal = np.random.RandomState(616).lognormal(size=(3, 3))\n",
            "X_lognormal\n",
            ">>>array([[1.28..., 1.18..., 0.84...],\n",
            "       [0.94..., 1.60..., 0.38...],\n",
            "       [1.35..., 0.21..., 1.09...]])\n",
            "pt.fit_transform(X_lognormal)\n",
            ">>>array([[ 0.49...,  0.17..., -0.15...],\n",
            "       [-0.05...,  0.58..., -0.57...],\n",
            "       [ 0.69..., -0.84...,  0.10...]])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Generating features:\n",
            "Often itâ€™s useful to add complexity to the model by considering nonlinear features of the input data. A simple and common method to use is polynomial features, which can get featuresâ€™ high-order and interaction terms. It is implemented inÂ PolynomialFeatures:\n",
            "import numpy as np\n",
            "from sklearn.preprocessing import PolynomialFeatures\n",
            "X = np.arange(6).reshape(3, 2)\n",
            "X\n",
            ">>>array([[0, 1],\n",
            "       [2, 3],\n",
            "       [4, 5]])\n",
            "poly = PolynomialFeatures(2)\n",
            "poly.fit_transform(X)\n",
            ">>>array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
            "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
            "       [ 1.,  4.,  5., 16., 20., 25.]])\n",
            "\n",
            "The features of X have been transformed fromÂ (X1,X2)Â toÂ (1, X1, X2, X12, X1X2, X22)\n",
            "For more details refer: https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "A.5 Task:\n",
            "1. Select dataset with (.csv file)  of sufficiently large size (>300 rows). It should contain columns with different data types.\n",
            "2. Normalize the data.\n",
            "3. Encode categorical features in your data.\n",
            "4. Check if skewness is there in features. (using hist command plot histogram)\n",
            "5. Transform skewed features into normally distributed features using transformation.\n",
            "6. Use feature engineering wherever necessary in your dataset.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "PART B\n",
            "(PART B : TO BE COMPLETED BY STUDENTS)\n",
            "(Students must submit the soft copy as per following segments within two hours of the practical. The soft copy must be uploaded on the Blackboard or emailed to the concerned lab in charge faculties at the end of the practical in case there is no Black board access available)\n",
            "\n",
            "\n",
            "B.1 Software Code written by student:  \n",
            "        (Paste your code completed during the 2 hours of practical in the lab here)\n",
            "B.2 Input and Output: \n",
            " (Paste your program input and output in following format, If there is error then paste the specific error in the output part. In case of error with due permission of the faculty extension can be given to submit the error free code with output in due course of time. Students will be graded accordingly.)\n",
            "B.3 Observations and learning:\n",
            "(Students are expected to comment on the output obtained with clear observations and learning for each task/ sub part assigned)\n",
            "B.4 Conclusion: \n",
            "(Students must write the conclusion as per the attainment of individual outcome listed above and learning/observation noted in section B.3)\n",
            "B.5 Question of Curiosity\n",
            "1. What is the simplest way to one hot encode the data if you are not using scikit learn?\n",
            "2. What are ordinal and nominal categorical variables?\n",
            "3. Why we need to generate new features in given dataset?\n",
            "\n",
            "========================================\n",
            "\n",
            "173710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set OpenAI API Key\n",
        "This code cell sets the OpenAI API key as an environment variable, which is required for authentication.\n",
        "\n",
        "Replace the placeholder with your actual OpenAI API key."
      ],
      "metadata": {
        "id": "tPa-wAPmD2Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"*****\" # write your own"
      ],
      "metadata": {
        "id": "pjKbQhREJSy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating OpenAI Text Embeddings\n",
        "\n",
        "This code cell initializes OpenAI text embeddings using the \"text-embedding-ada-002\" model.\n",
        "\n",
        "It also specifies a maximum number of retries for API requests.\n",
        "\n",
        "Replace the model name and adjust the number of retries as needed for your use case."
      ],
      "metadata": {
        "id": "nXrghU-kEGVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Embeddings\n",
        "import openai\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\",max_retries = 5) # Maximum number of retries"
      ],
      "metadata": {
        "id": "k5ICT93pH1tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking Documents for Text Analysis\n",
        "\n",
        "This code cell defines a function to split a large text document into smaller chunks for text analysis.\n",
        "\n",
        "It uses the RecursiveCharacterTextSplitter with specified chunk size and overlap parameters.\n",
        "\n",
        "Replace the chunk_size and chunk_overlap values to customize the chunking process as needed.\n"
      ],
      "metadata": {
        "id": "UeUHAGI3Eeem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking documents\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_docs(all_text_content,chunk_size=2100,chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_text(all_text_content)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(all_text_content)\n",
        "print(len(docs))"
      ],
      "metadata": {
        "id": "WC097yUU9DAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a33e59b-1361-47a2-e517-da4065e33657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Pinecone and Create an Index\n",
        "\n",
        "This code cell initializes Pinecone with your API key and specifies the environment.\n",
        "\n",
        "It also sets up an index named \"trial\" for use with Pinecone.\n",
        "\n",
        "Replace the API key and environment as needed based on your Pinecone configuration.\n"
      ],
      "metadata": {
        "id": "nrpVhVoyFMMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=\"***********************\",  # find at app.pinecone.io ,WRITE YOUR OWN\n",
        "    environment=\"asia-southeast1-gcp-free\"  # next to api key in console,WRITE YOUR OWN\n",
        ")\n",
        "\n",
        "index_name = \"trial\""
      ],
      "metadata": {
        "id": "1NlvmacAA0hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store Pinecone Index with Text Embeddings\n"
      ],
      "metadata": {
        "id": "iv7e6BaDFioP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = Pinecone.from_texts(docs, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "XunGbZueH-LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize ChatOpenAI Language Model\n",
        "\n",
        " This code cell initializes a language model for chat-based interactions using the 'ChatOpenAI' class.\n",
        "\n",
        " You can specify the desired model name (e.g., \"gpt-3.5-turbo\" or \"gpt-4\").\n",
        "\n",
        " Ensure you have the required library or package (in this case, 'langchain') installed before running this cell.\n",
        "\n",
        " Model Options:\n",
        " - \"text-davinci-003\" (Davinci model)\n",
        " - \"gpt-3.5-turbo\" (GPT-3.5 Turbo model)\n",
        " - \"gpt-4\" (GPT-4 model)"
      ],
      "metadata": {
        "id": "tQwfIeAXF79C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "# model_name = \"text-davinci-003\"\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "# model_name = \"gpt-4\"\n",
        "llm = ChatOpenAI(model_name=model_name)"
      ],
      "metadata": {
        "id": "IWf52DfSIiLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Question Answering with RetrievalQA\n",
        "\n",
        "This code cell sets up a Question Answering (QA) system using the 'RetrievalQA' class.\n",
        "\n",
        "It integrates your language model ('llm') and a Pinecone index ('docsearch') for document retrieval.\n",
        "\n",
        "Make sure you have loaded the Pinecone index and initialized the language model before running this cell.\n"
      ],
      "metadata": {
        "id": "Gj1axHSLGL6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "docsearch = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
        "\n",
        "# Create RetrievalQA object\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())\n"
      ],
      "metadata": {
        "id": "UluD61Z2IaaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Querying the Question Answering System"
      ],
      "metadata": {
        "id": "VnFA3RScGXDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"generate a detailed summary of LCV Ensembled Bagging model\"\n",
        "result = qa.run(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYfRVwCMLMxg",
        "outputId": "143b013b-700b-42d5-a770-432d0d8d0069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The LCV Ensembled Bagging model is a technique used to improve the performance and accuracy of machine learning algorithms. It involves using two or more homogeneous models to predict a single outcome. In the case of the LCV Ensembled Bagging model, it was used for detecting plants with disease.\n",
            "\n",
            "Initially, the model was able to detect 7 out of 10 plants in a frame, resulting in around 70% accuracy. However, it was unable to perfectly distinguish between the scores. To address this issue, a bagging technique was applied, where two detection models were used in a single inference. This improved the performance of the model, allowing it to detect all 10 plants in a frame, achieving 100% accuracy for plant detection.\n",
            "\n",
            "Despite the improvement in plant detection, the model still struggled with distinguishing between scores. To further enhance its capabilities, a classification model was added after the detection process. This allowed the model to clearly classify between scores, improving its overall performance.\n",
            "\n",
            "The LCV Ensembled Bagging model went through several versions, including V1.1, V2.0, and V2.1. Each version incorporated different techniques and models to enhance the performance and accuracy of the model. The specific details and results of each version were not mentioned in the provided context.\n",
            "\n",
            "Overall, the LCV Ensembled Bagging model proved to be effective in detecting plants with disease, achieving high accuracy. However, further improvements were made to address the issue of distinguishing between scores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"State the strategies for fixing failing tests\"\n",
        "result = qa.run(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TICjWEppLTa1",
        "outputId": "bbb96348-3070-433f-e62d-a812aea9fc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The strategies for fixing failing tests include:\n",
            "\n",
            "1. Changing hyper-parameters: Adjusting the settings or parameters of the test to minimize flakiness.\n",
            "2. Updating assertion bounds: Modifying the acceptable range of values used in the test for comparing the end-result.\n",
            "3. Refactoring the assertion or test: Modifying the assertion statement or the test itself to improve its reliability.\n",
            "4. Fixing code under test: Debugging and addressing any bugs or issues in the code that may be causing the test failures.\n",
            "5. Manual investigation: For tests that cannot be automatically fixed, manually investigating and determining alternative fixes or sending bug reports to developers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"A new Phenotyping Documentation file is there, in which folder should it be moved? \"\n",
        "result = qa.run(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZVwwSXsLbGd",
        "outputId": "ca9b3747-9466-4b90-dda0-04a7558248d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new Phenotyping Documentation file should be moved to the \"My Drive > Test > PDF\" folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\" \"\n",
        "result = qa.run(query)what is the Folder name of Phenotyping Master Documentation (1).pdf?\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "garPLH1HLax-",
        "outputId": "059d5ea4-3f4d-4498-c280-f38f2891cb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder name of \"Phenotyping Master Documentation (1).pdf\" is \"My Drive > Test > PDF\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"A new Python documentation file is there, in which folder moved to?  \"\n",
        "result = qa.run(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjicxRssLaZ1",
        "outputId": "225701ed-4a90-4e1c-db13-ee9461481b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new Python documentation file is located in the \"My Drive > Test > DOCS\" folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query= \"generate a detailed summary of LCV Ensembled bagging model (V1.1) from documents\"\n",
        "result = qa.run(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJRt9iG9L2tx",
        "outputId": "d283f2b4-bb63-4639-a345-f6ab380bf900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The LCV Ensembled bagging model (V1.1) is a model that was used to detect plants with diseases. It was able to detect 7 out of 10 plants in a frame, with an accuracy of around 70%. However, the model was unable to perfectly distinguish between scores. The bagging technique, which is an ensemble learning technique, was used to improve the performance and accuracy of the model. By using 2 or more homogeneous models to predict a single outcome, the bagging technique helped to increase the performance of the model, resulting in the detection of all 10 plants in a frame with 100% accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **--------------- Start to move the files to folder --------------**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WM17jOZQN2bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "XUIv_e2ORHNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Replace 'YOUR_API_VERSION' with the desired API version (e.g., 'v3').\n",
        "drive_service = build('drive', 'v3')"
      ],
      "metadata": {
        "id": "JK1OCULoRAWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List Files in the Root Directory of Google Drive\n"
      ],
      "metadata": {
        "id": "mjS8sPTgG6rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = drive_service.files().list(q=\"'root' in parents\", pageSize=50).execute()\n",
        "items = results.get('files', [])\n",
        "\n",
        "if not items:\n",
        "    print('No files or folders found in the root directory.')\n",
        "else:\n",
        "    print('Files directly in the root directory:')\n",
        "    for item in items:\n",
        "        if item['mimeType'] != 'application/vnd.google-apps.folder':\n",
        "            # It's a file, not within a folder\n",
        "            print(f\"File: {item['name']} ({item['mimeType']})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ALkkO2BP_Cv",
        "outputId": "d6e2ab8d-b6a6-4b78-ce57-e531a17267a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files directly in the root directory:\n",
            "File: Week7_Industry Mentor Log Book.docx (application/vnd.openxmlformats-officedocument.wordprocessingml.document)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List File Names in the Root Directory of Google Drive in list"
      ],
      "metadata": {
        "id": "iGnUKqw4Hns7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = drive_service.files().list(q=\"'root' in parents\", pageSize=20).execute()\n",
        "items = results.get('files', [])\n",
        "\n",
        "file_name = []\n",
        "\n",
        "if not items:\n",
        "    file_name.append('No files or folders found in the root directory.')\n",
        "else:\n",
        "    file_name.append('Files directly in the root directory:')\n",
        "    for item in items:\n",
        "        if item['mimeType'] != 'application/vnd.google-apps.folder':\n",
        "            # It's a file, not within a folder\n",
        "            file_name.append(f\"File: {item['name']} ({item['mimeType']})\")\n",
        "\n",
        "print(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBPbenc1P6En",
        "outputId": "35ee17cb-abf3-455a-cc0c-b3d8ce32e297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Files directly in the root directory:', 'File: Week7_Industry Mentor Log Book.docx (application/vnd.openxmlformats-officedocument.wordprocessingml.document)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggest Folders for Files in Google Drive and Extract Content (Chat-based QA)\n",
        "\n",
        "This code cell suggests folders in Google Drive for each file in the root directory.\n",
        "\n",
        "It utilizes a Chat-based Question Answering (QA) system to make folder suggestions based on file names.\n",
        "\n",
        "If the user chooses to move a file, it can be moved to the suggested folder.\n",
        "\n",
        "Additionally, it extracts content from various file types, including Google Docs, PDFs, plain text, DOCX, and more.\n",
        "\n",
        " Make sure to configure your Google Drive API service, Pinecone index, and language model ('llm').\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YalyblNJJEwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from googleapiclient.discovery import build\n",
        "import os\n",
        "import re\n",
        "from langchain.prompts import PromptTemplate\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from docx import Document\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import fitz\n",
        "\n",
        "def suggest_folders_for_files(drive_service, index_name, llm):\n",
        "    # List files in Google Drive\n",
        "    results = drive_service.files().list(q=\"'root' in parents\", pageSize=20).execute()\n",
        "    items = results.get('files', [])\n",
        "\n",
        "    if not items:\n",
        "        print('No files or folders found in the root directory.')\n",
        "        return\n",
        "\n",
        "    # Initialize Pinecone index\n",
        "    docsearch = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
        "\n",
        "    template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "    Don't try to create a new URL, just suggest a URL from the context.\n",
        "    {context}\n",
        "    Question: {question}\n",
        "    Helpful Answer:\"\"\"\n",
        "\n",
        "    # Initialize a variable to store all the file contexts\n",
        "    all_file_contexts = \"\"\n",
        "\n",
        "    # Set to store original text file names (to avoid processing multiple times)\n",
        "    original_text_file_names = set()\n",
        "\n",
        "    for item in items:\n",
        "        if item['mimeType'] != 'application/vnd.google-apps.folder':\n",
        "            # It's a file, not within a folder\n",
        "            file_id = item['id']\n",
        "            file_name = item['name']\n",
        "\n",
        "            # Define your question using the file_name\n",
        "            question = f\"Suggest a Folder name and its URL for the file '{file_name}'\"\n",
        "\n",
        "            QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "\n",
        "            # Use the existing 'llm' parameter instead of redefining it\n",
        "            qa_chain = RetrievalQA.from_chain_type(\n",
        "                llm,\n",
        "                retriever=docsearch.as_retriever(),\n",
        "                chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        "            )\n",
        "\n",
        "            # Run the question through the QA system\n",
        "            result = qa_chain({\"query\": question})\n",
        "\n",
        "            # Print the result for this file\n",
        "            print(f\"File: {file_name}\")\n",
        "            print(f\"Suggested Folder: {result['result']}\")\n",
        "\n",
        "            # Ask the user whether to move the file to the suggested folder\n",
        "            move_file = input(\"Do you want to move this file to the suggested folder? (yes/no): \").strip().lower()\n",
        "            if move_file == 'yes':\n",
        "                # Store the file's context before moving it\n",
        "                file_context = f\"File: {file_name}\\nSuggested Folder: {result['result']}\\n\"\n",
        "\n",
        "                # Accumulate the context in the 'all_file_contexts' variable\n",
        "                all_file_contexts += file_context\n",
        "\n",
        "                # Move the file to the suggested folder\n",
        "                match = re.search(r'folders/([^/\"]+)', result['result'])\n",
        "                if match:\n",
        "                    folder_id = match.group(1)\n",
        "                    print(folder_id)\n",
        "                else:\n",
        "                    print(\"No match found.\")\n",
        "                move_file_to_folder(drive_service, file_id, folder_id)\n",
        "                print(f\"Moved '{file_name}' to folder '{result['result']}'\\n\")\n",
        "\n",
        "                # Retrieve and print the content of the file\n",
        "                file_content = get_file_content(drive_service, file_id, file_name, result['result'], original_text_file_names)\n",
        "                all_file_contexts += file_content\n",
        "\n",
        "            else:\n",
        "                print(f\"Skipping '{file_name}'...\\n\")\n",
        "\n",
        "    # After processing all files, you can access the accumulated file contexts in 'all_file_contexts'\n",
        "    return all_file_contexts\n",
        "\n",
        "def move_file_to_folder(drive_service, file_id, folder_id):\n",
        "    # Move the file to the specified folder\n",
        "    try:\n",
        "        file = drive_service.files().get(fileId=file_id, fields='parents').execute()\n",
        "        previous_parents = \",\".join(file.get('parents'))\n",
        "        file = drive_service.files().update(fileId=file_id, addParents=folder_id, removeParents=previous_parents).execute()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while moving the file: {str(e)}\")\n",
        "\n",
        "def get_file_content(drive_service, file_id, file_name, folder_path, original_text_file_names):\n",
        "    try:\n",
        "        file = drive_service.files().get(fileId=file_id).execute()\n",
        "        mime_type = file['mimeType']\n",
        "\n",
        "        # Initialize a variable to store the file content\n",
        "        file_content = \"\"\n",
        "\n",
        "        if mime_type == 'application/vnd.google-apps.document':\n",
        "            # Export Google Docs content as plain text\n",
        "            request = drive_service.files().export_media(fileId=file_id, mimeType='text/plain')\n",
        "            text_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(text_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            text_content = text_fh.getvalue().decode('utf-8')\n",
        "\n",
        "            # Add folder path to each line of the Google Docs content\n",
        "            text_lines = text_content.split('\\n')\n",
        "            text_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in text_lines])\n",
        "\n",
        "            file_content += f\"Folder Name: {folder_path}\\n\"\n",
        "            file_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "            file_content += \"Google Docs Content:\\n\"\n",
        "            file_content += text_content_with_path + \"\\n\"\n",
        "            file_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        elif mime_type == 'application/pdf':\n",
        "            # Download the PDF content\n",
        "            request = drive_service.files().get_media(fileId=file_id)\n",
        "            pdf_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(pdf_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            # Check if the PDF contains text (use PyMuPDF for this)\n",
        "            pdf_content = pdf_fh.getvalue()\n",
        "            pdf_document = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
        "\n",
        "            # Initialize a variable to store the extracted text\n",
        "            extracted_text = \"\"\n",
        "\n",
        "            for page_num in range(pdf_document.page_count):\n",
        "                page = pdf_document.load_page(page_num)\n",
        "                page_text = page.get_text()\n",
        "                extracted_text += page_text\n",
        "\n",
        "            if extracted_text.strip():\n",
        "                # Append the extracted text for the PDF file\n",
        "                pdf_text_lines = extracted_text.split('\\n')\n",
        "                pdf_text_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in pdf_text_lines])\n",
        "                file_content += f\"Folder Name: {folder_path}\\n\"\n",
        "                file_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "                file_content += \"PDF Text Content:\\n\"\n",
        "                file_content += pdf_text_content_with_path + \"\\n\"\n",
        "                file_content += \"=\" * 40 + \"\\n\"\n",
        "            else:\n",
        "                # If the PDF does not contain text, attempt OCR\n",
        "                file_content += f\"Folder Name: {folder_path}\\n\"\n",
        "                file_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "                file_content += \"Performing OCR on scanned PDF...\\n\"\n",
        "\n",
        "                # Initialize a variable to store the OCR result\n",
        "                ocr_result = \"\"\n",
        "\n",
        "                for page_num in range(pdf_document.page_count):\n",
        "                    page = pdf_document.load_page(page_num)\n",
        "                    img = page.get_pixmap()\n",
        "                    img_bytes = img.samples\n",
        "                    img_text = pytesseract.image_to_string(Image.frombytes(\"RGB\", [img.width, img.height], img_bytes))\n",
        "                    ocr_result += img_text\n",
        "\n",
        "                ocr_text_lines = ocr_result.split('\\n')\n",
        "                ocr_text_content_with_path = \"\\n\".join([f\"{folder_path} > {line}\" for line in ocr_text_lines])\n",
        "                file_content += f\"OCR Result:\\n\"\n",
        "                file_content += ocr_text_content_with_path + \"\\n\"\n",
        "                file_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        elif mime_type == 'text/plain':\n",
        "            # Check if it's a text file and not processed before\n",
        "            if file_name.endswith('.txt') and file_name not in original_text_file_names:\n",
        "                # Download and append plain text content\n",
        "                request = drive_service.files().get_media(fileId=file['id'])\n",
        "                text_fh = io.BytesIO()\n",
        "                downloader = MediaIoBaseDownload(text_fh, request)\n",
        "                done = False\n",
        "                while done is False:\n",
        "                    status, done = downloader.next_chunk()\n",
        "\n",
        "                text_content = text_fh.getvalue().decode('utf-8')\n",
        "                text_lines = text_content.split('\\n')\n",
        "                text_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in text_lines])\n",
        "\n",
        "                file_content += f\"Folder Name: {folder_path}\\n\"\n",
        "                file_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "                file_content += \"Text File Content:\\n\"\n",
        "                file_content += text_content_with_path + \"\\n\"\n",
        "                file_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "                # Add the file name (without .txt extension) to the set of original text file names\n",
        "                original_text_file_names.add(file_name)\n",
        "\n",
        "        elif mime_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':\n",
        "            # Download the .docx content\n",
        "            request = drive_service.files().get_media(fileId=file['id'])\n",
        "            docx_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(docx_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            docx_content = docx_fh.getvalue()\n",
        "            document = Document(io.BytesIO(docx_content))\n",
        "\n",
        "            extracted_text = []\n",
        "\n",
        "            for paragraph in document.paragraphs:\n",
        "                extracted_text.append(paragraph.text)\n",
        "\n",
        "            file_content += f\"Folder Name: {folder_path}\\n\"\n",
        "            file_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "            file_content += \"DOCX Text Content:\\n\"\n",
        "            file_content += \"\\n\".join(extracted_text) + \"\\n\"\n",
        "            file_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        elif file_name.endswith('.py'):\n",
        "            # Download and process Python file content\n",
        "            request = drive_service.files().get_media(fileId=file['id'])\n",
        "            python_fh = io.BytesIO()\n",
        "            downloader = MediaIoBaseDownload(python_fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "            python_content = python_fh.getvalue().decode('utf-8')\n",
        "            python_lines = python_content.split('\\n')\n",
        "            python_content_with_path = \"\\n\".join([f\"Folder name : {folder_path} > {line}\" for line in python_lines])\n",
        "            file_content += f\"Folder Name: {folder_path}\\n\"\n",
        "            file_content += f\"File Name: {file_name} https://drive.google.com/file/d/{file_id}\\n\"\n",
        "\n",
        "            file_content += \"Python File Content:\\n\"\n",
        "            file_content += python_content_with_path + \"\\n\"\n",
        "            file_content += \"=\" * 40 + \"\\n\"\n",
        "\n",
        "        # Add more MIME type processing here\n",
        "\n",
        "        return file_content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while getting the file content: {str(e)}\")\n",
        "        return \"Error getting file content.\"\n",
        "\n",
        "# Usage example:\n",
        "# Replace these placeholders with actual values and configure your Google Drive API service\n",
        "# drive_service = build('drive', 'v3', ...)\n",
        "# index_name = 'your_pinecone_index_name'\n",
        "# llm = 'your_llm_model_name'\n",
        "\n",
        "# Call the function and store the accumulated file contexts\n",
        "all_file_contexts = suggest_folders_for_files(drive_service, index_name, llm)\n",
        "\n",
        "# Print all the files' content which were moved\n",
        "print(\"All File Contents for Moved Files:\")\n",
        "print(all_file_contexts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svCx4-o-VYKL",
        "outputId": "4554a92c-f5b2-4d89-c6a3-dabf7b9bf25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: Week7_Industry Mentor Log Book.docx\n",
            "Suggested Folder: Folder Name: WEEKLY_REPORTS \n",
            "URL: https://drive.google.com/drive/folders/1xFY4AdtqN4BXVLaIFrqTtH9Qc3EuCCoK\n",
            "Do you want to move this file to the suggested folder? (yes/no): yes\n",
            "1xFY4AdtqN4BXVLaIFrqTtH9Qc3EuCCoK\n",
            "Moved 'Week7_Industry Mentor Log Book.docx' to folder 'Folder Name: WEEKLY_REPORTS \n",
            "URL: https://drive.google.com/drive/folders/1xFY4AdtqN4BXVLaIFrqTtH9Qc3EuCCoK'\n",
            "\n",
            "All File Contents for Moved Files:\n",
            "File: Week7_Industry Mentor Log Book.docx\n",
            "Suggested Folder: Folder Name: WEEKLY_REPORTS \n",
            "URL: https://drive.google.com/drive/folders/1xFY4AdtqN4BXVLaIFrqTtH9Qc3EuCCoK\n",
            "Folder Name: Folder Name: WEEKLY_REPORTS \n",
            "URL: https://drive.google.com/drive/folders/1xFY4AdtqN4BXVLaIFrqTtH9Qc3EuCCoK\n",
            "File Name: Week7_Industry Mentor Log Book.docx https://drive.google.com/file/d/1fmjLmE8_MN_E2XlK1jaqlPBCHei07mGI\n",
            "DOCX Text Content:\n",
            "SVKMâ€™s NMIMS University \n",
            "Mukesh Patel School of Technology Management & Engineering \n",
            "Department of Computer Engineering \n",
            "B Tech. Integrated  \n",
            " \n",
            "Industry Internship Fortnightly Report \n",
            " \n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "Summary of Learnings: \n",
            "Throughout this project, I worked on separate tasks related to both Google Drive API and DynamoDB in AWS. For Google Drive API, I faced challenges in obtaining credentials and encountered issues while trying to change file ownership. However, I managed to create functions for file creation and updates, successfully displaying files on Google Drive.\n",
            "On the other hand, in the AWS environment, I encountered errors while running the Lambda function with parameters and had to debug the code to make it run successfully without arguments. Additionally, I researched how to add parameters in Lambda but faced limitations due to the AWS CLI.\n",
            "Throughout the project, I maintained proper documentation, including log books, installation instructions, and code explanations. Despite facing challenges, I successfully completed various tasks, demonstrating my abilities in both AWS and Google Drive API integration.\n",
            "\n",
            " \n",
            "Number of Days Present in the Week: 10                   Number of Days Absent in the Week:  0\n",
            "\n",
            "\n",
            "Signature of the Student \n",
            "\n",
            "\n",
            "Grades (Refer table 1 for marks distribution and level of achievement) \n",
            " \n",
            " \n",
            "Signature of Industry Mentor with date: \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\n",
            " \n",
            "Table 1: Marks distribution and level of achievement \n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "========================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAME PROCESS FOR STORING THE TEXT IN PINECONE"
      ],
      "metadata": {
        "id": "wMpBzGhJJXY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Embeddings for moved files\n",
        "import openai\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\",max_retries = 5)"
      ],
      "metadata": {
        "id": "qJigdGSOc-QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking documents for the moved files.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_docs(all_file_contexts,chunk_size=2000,chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_text(all_file_contexts)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(all_file_contexts)\n",
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcMKgaCYc-4i",
        "outputId": "0af440bc-c7fd-489e-95b1-35b14cd1ff53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STORED ALL THE MOVED FILE TEXT IN PINECONE\n",
        "index = Pinecone.from_texts(docs, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "uj8WO41OdCrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}